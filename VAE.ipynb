{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variational Autoencoder (VAE): \"non-linear PCA\"\n",
    "\n",
    "## VAE Resources I'm using\n",
    "\n",
    "- `https://www.tensorflow.org/tutorials/generative/cvae`\n",
    "- `https://www.tensorflow.org/probability/examples/Probabilistic_Layers_VAE`\n",
    "- `https://github.com/tensorflow/probability/blob/master/tensorflow_probability/examples/vae.py`\n",
    "\n",
    "## VAE Resources I'm not using here, but found easily\n",
    "- `https://keras.io/examples/generative/vae/`\n",
    "- `https://www.tensorflow.org/guide/keras/custom_layers_and_models#putting_it_all_together_an_end-to-end_example`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some Standard Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST digits\n",
    "- I initially started with a tutorial using the `keras` style here, i.e., not TFDS\n",
    "    - but we're going to end up convertig this to TFDS, so we could have just started with that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 1s 0us/step\n"
     ]
    }
   ],
   "source": [
    "# https://www.tensorflow.org/tutorials/generative/cvae\n",
    "(train_images, train_labels), (test_images, test_labels) = datasets.mnist.load_data()\n",
    "\n",
    "# https://www.tensorflow.org/probability/examples/Probabilistic_Layers_VAE\n",
    "if 0:\n",
    "    import tensorflow_datasets as tfds\n",
    "    datasets, datasets_info = tfds.load(name='mnist', with_info=True,\n",
    "                                        as_supervised=False) # this would give us (x,x) as opposed to (x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images.shape, test_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "plt.imshow(train_images[i,], cmap=plt.cm.binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images[0,:10,:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- This original tutorial I was looking at did it's transform of the data all up front"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.tensorflow.org/tutorials/generative/cvae\n",
    "\n",
    "if 0:\n",
    "    def preprocess_images(images):\n",
    "        images = images.reshape((images.shape[0], 28, 28, 1)) / 255.\n",
    "        return np.where(images > .5, 1.0, 0.0).astype('float32')\n",
    "\n",
    "    train_images_bernoulli = preprocess_images(train_images)\n",
    "    test_images_bernoulli = preprocess_images(test_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We'll instead incorporate this into the TFDS iterator and process it on the fly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # turn into a tf Dataset\n",
    "\n",
    "dataset = {}\n",
    "dataset['train'] = tf.data.Dataset.from_tensor_slices(train_images)\n",
    "dataset['test'] = tf.data.Dataset.from_tensor_slices(test_images)\n",
    "\n",
    "next(iter(dataset['train'])).numpy()[:10,:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **We'll set it up as (x,x), not (x,y)**\n",
    "- Binarizing lets make the image a grid of bernoulli outcomes\n",
    "    - By preprocessing they'll vary each time so we get **data augmentation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.tensorflow.org/probability/examples/Probabilistic_Layers_VAE\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "def _preprocess(sample):\n",
    "                           #tf.float32 is important!\n",
    "    image = tf.cast(sample, tf.float32) / 255.  # Scale to unit interval. \n",
    "    \n",
    "    # https://www.tensorflow.org/api_docs/python/tf/reshape\n",
    "    image = tf.reshape(image, [28, 28, 1])\n",
    "    \n",
    "    # Randomly binarize [Each Time Each Batch!]\n",
    "    image = image > tf.random.uniform(tf.shape(image))   \n",
    "    return image, image    # (x,y) is actually (x,x)!\n",
    "\n",
    "train_dataset = (dataset['train']\n",
    "                 .map(_preprocess)\n",
    "                 .batch(batch_size)\n",
    "                 .prefetch(tf.data.experimental.AUTOTUNE)\n",
    "                 .shuffle(int(10e3)))\n",
    "eval_dataset = (dataset['test']\n",
    "                .map(_preprocess)\n",
    "                .batch(batch_size)\n",
    "                .prefetch(tf.data.experimental.AUTOTUNE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- So now we're back to a TF Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- And here you can see that the random binarization\n",
    "  is different each time the data comes through as a batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# different each time since\n",
    "# map is applied at run time\n",
    "\n",
    "tmp=iter(train_dataset)\n",
    "sm = 0\n",
    "for i in tmp:\n",
    "    sm += i[0].numpy().sum() \n",
    "sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# different each time since\n",
    "# map is applied at run time\n",
    "\n",
    "tmp=iter(train_dataset)\n",
    "sm = 0\n",
    "for i in tmp:\n",
    "    sm += i[0].numpy().sum() \n",
    "sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variational AutoEncoder (VAE)\n",
    "\n",
    "$\\tilde x = I(mvn(f_{\\mu,\\sigma}(x)))$\n",
    "\n",
    "- $\\tilde x$: reconstructed image\n",
    "- $x$: input image\n",
    "- $f_{\\mu,\\sigma}$: image embedder\n",
    "- $mvn$: multivariate normal distribution\n",
    "- $I$: image reconstructor\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoder\n",
    "\n",
    "$\\tilde x = I(mvn($<font style='color:red'>$f_{\\mu,\\sigma}(x)$</font>$))$\n",
    "\n",
    "- $\\tilde x$: reconstructed image\n",
    "- $x$: input image\n",
    "- <font style='color:red'> $f_{\\mu,\\sigma}$: image embedder</font>\n",
    "- $mvn$: multivariate normal distribution\n",
    "- $I$: image reconstructor\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_images.shape)\n",
    "\n",
    "print(list(train_images.shape[1:])+[1])\n",
    "\n",
    "train_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.tensorflow.org/tutorials/generative/cvae\n",
    "# https://www.tensorflow.org/probability/examples/Probabilistic_Layers_VAE\n",
    "\n",
    "from tensorflow.keras import Input\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, InputLayer, Flatten, Dense, Lambda\n",
    "\n",
    "square_kernel_size = 5 #3\n",
    "x_y_stride_offset = 2\n",
    "base_filter_count = 32\n",
    "\n",
    "encoder = Sequential([#Input(shape=list(train_images.shape[1:])+[1]),\n",
    "                      InputLayer(input_shape=list(train_images.shape[1:])+[1],\n",
    "                                 name='input'),\n",
    "                      Lambda(lambda x: tf.cast(x, tf.float32) - 0.5),\n",
    "    \n",
    "                      Conv2D(filters=base_filter_count, kernel_size=square_kernel_size, \n",
    "                             strides=1, padding='valid', activation=tf.nn.leaky_relu),\n",
    "    \n",
    "                      Conv2D(filters=base_filter_count, kernel_size=square_kernel_size, \n",
    "                             strides=x_y_stride_offset, padding='same', activation=tf.nn.leaky_relu),\n",
    "    \n",
    "                      Conv2D(filters=2*base_filter_count, kernel_size=square_kernel_size, \n",
    "                             strides=1, padding='valid', activation=tf.nn.leaky_relu),\n",
    "    \n",
    "                      Conv2D(filters=2*base_filter_count, kernel_size=square_kernel_size, \n",
    "                             strides=x_y_stride_offset, padding='same', activation=tf.nn.leaky_relu),\n",
    "    \n",
    "                      Conv2D(filters=4*base_filter_count, kernel_size=4, \n",
    "                             strides=1, padding='valid', activation=tf.nn.leaky_relu),\n",
    "                      Flatten()],\n",
    "                     name='encoder')\n",
    "\n",
    "print(encoder.input_shape)\n",
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter Count Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 32 5x5[3x3] kernels, each with an offset, applied to a single image channel\n",
    "channels = 1\n",
    "filters = 32\n",
    "params = 0\n",
    "for i in range(filters):\n",
    "    params += channels*square_kernel_size*square_kernel_size + 1\n",
    "print(params)\n",
    "\n",
    "# for each of 32 image channels, 64 5x5[3x3] kernels, with one offset for each image channel\n",
    "channels = 32\n",
    "filters = 64\n",
    "params = 0\n",
    "for i in range(filters):\n",
    "    params += channels*square_kernel_size*square_kernel_size + 1\n",
    "print(params)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Strided Convolutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_y_stride_offset=2\n",
    "square_kernel_size=5\n",
    "\n",
    "for i_x in range(12):\n",
    "    for i_y in range(12):\n",
    "        x_i_left = x_y_stride_offset*i_x\n",
    "        x_i_right = x_i_left+square_kernel_size\n",
    "        y_i_top = x_y_stride_offset*i_y\n",
    "        y_i_bottom = y_i_top+square_kernel_size\n",
    "        print(\"l: \"+str(x_i_left)+\", r: \"+str(x_i_right)+\", t: \"+str(y_i_top)+\", b:\"+str(y_i_bottom))\n",
    "        \n",
    "# https://stackoverflow.com/questions/37674306/what-is-the-difference-between-same-and-valid-padding-in-tf-nn-max-pool-of-t        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorFlow Probability\n",
    "\n",
    "$\\tilde x = I($ <font style='color:red'>$mvn(f_{\\mu,\\sigma}(x))$</font> $)$\n",
    "\n",
    "- $\\tilde x$: reconstructed image\n",
    "- $x$: input image\n",
    "- <font style='color:red'> $f_{\\mu,\\sigma}$: image embedder </font>\n",
    "- <font style='color:red'> $mvn$: multivariate normal distribution </font>\n",
    "- $I$: image reconstructor\n",
    "\n",
    "- $mvn$: multivariate normal distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow-probability\n",
      "  Downloading tensorflow_probability-0.12.1-py2.py3-none-any.whl (4.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 4.8 MB 3.1 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: decorator in /Users/gck8gd/opt/anaconda3/envs/deep_learning_6018/lib/python3.8/site-packages (from tensorflow-probability) (4.4.2)\n",
      "Requirement already satisfied, skipping upgrade: dm-tree in /Users/gck8gd/opt/anaconda3/envs/deep_learning_6018/lib/python3.8/site-packages (from tensorflow-probability) (0.1.5)\n",
      "Requirement already satisfied, skipping upgrade: cloudpickle>=1.3 in /Users/gck8gd/opt/anaconda3/envs/deep_learning_6018/lib/python3.8/site-packages (from tensorflow-probability) (1.6.0)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.13.3 in /Users/gck8gd/opt/anaconda3/envs/deep_learning_6018/lib/python3.8/site-packages (from tensorflow-probability) (1.19.2)\n",
      "Requirement already satisfied, skipping upgrade: gast>=0.3.2 in /Users/gck8gd/opt/anaconda3/envs/deep_learning_6018/lib/python3.8/site-packages (from tensorflow-probability) (0.3.3)\n",
      "Requirement already satisfied, skipping upgrade: six>=1.10.0 in /Users/gck8gd/opt/anaconda3/envs/deep_learning_6018/lib/python3.8/site-packages (from tensorflow-probability) (1.15.0)\n",
      "Installing collected packages: tensorflow-probability\n",
      "  Attempting uninstall: tensorflow-probability\n",
      "    Found existing installation: tensorflow-probability 0.11.1\n",
      "    Uninstalling tensorflow-probability-0.11.1:\n",
      "      Successfully uninstalled tensorflow-probability-0.11.1\n",
      "Successfully installed tensorflow-probability-0.12.1\n"
     ]
    }
   ],
   "source": [
    "! pip install --upgrade tensorflow-probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.tensorflow.org/probability/examples/Probabilistic_Layers_VAE\n",
    "\n",
    "# Super Key!\n",
    "import tensorflow_probability as tfp\n",
    "\n",
    "# https://blog.tensorflow.org/2019/03/regression-with-probabilistic-layers-in.html\n",
    "# https://www.tensorflow.org/probability/api_docs/python/tfp/layers\n",
    "tfpl = tfp.layers\n",
    "tfd = tfp.distributions\n",
    "\n",
    "# Important!\n",
    "latent_dimension = 3\n",
    "\n",
    "\n",
    "# https://www.tensorflow.org/probability/api_docs/python/tfp/layers/IndependentNormal\n",
    "#tfd.Independent(tfd.Normal(loc=tf.zeros(latent_dimension), scale=1))\n",
    "#tfd.Independent(tfd.Normal(loc=tf.zeros(latent_dimension), scale=1),\n",
    "#                           reinterpreted_batch_ndims=1)\n",
    "#prior = tfd.Independent(tfd.Normal(loc=tf.zeros(latent_dimension), scale=1),\n",
    "#                        reinterpreted_batch_ndims=1)\n",
    "# https://www.tensorflow.org/probability/api_docs/python/tfp/layers/MultivariateNormalTriL\n",
    "\n",
    "# slight upgrade from i.i.d. normal prior specification (above) to MVN\n",
    "prior = tfd.MultivariateNormalDiag(loc=tf.zeros(latent_dimension), scale_diag=tf.ones(latent_dimension))#tf.eye(latent_dimension))\n",
    "# prior TO BE DISCUSSED SHORTLY\n",
    "# along with notes such as this:\n",
    "# https://github.com/tensorflow/probability/blob/master/tensorflow_probability/examples/vae.py\n",
    "# and as discussed from line 62 in the `vae.py` link above\n",
    "# mu and sigma in f_mu,sigma can just change to accomodate different MNV(mu_0, sigma_0)\n",
    "# so we just use MVN(0,1) for the \"prior\"\n",
    "\n",
    "\n",
    "#mvn = Sequential([InputLayer(input_shape=encoder.output.shape[1:]),\n",
    "#                  Dense(tfpl.IndependentNormal.params_size(latent_dimension), activation=None),\n",
    "#                  tfpl.IndependentNormal(latent_dimension,\n",
    "#                       activity_regularizer=tfpl.KLDivergenceRegularizer(prior))],\n",
    "#                name='mvn')\n",
    "\n",
    "# slight upgrade from i.i.d. normal prior specification (above) to MVN\n",
    "mvn = Sequential([InputLayer(input_shape=encoder.output.shape[1:]),\n",
    "                  Dense(tfpl.MultivariateNormalTriL.params_size(latent_dimension), activation=None),\n",
    "                  tfpl.MultivariateNormalTriL(latent_dimension, \n",
    "                       activity_regularizer=tfpl.KLDivergenceRegularizer(prior, weight=None,\n",
    "                                                                         use_exact_kl=False))],\n",
    "                name='mvn')\n",
    "# as noted here: https://www.tensorflow.org/tutorials/generative/cvae#define_the_loss_function_and_the_optimizer\n",
    "# \"In practice, we optimize the single sample Monte Carlo estimate of this expectation\"\n",
    "\n",
    "print(mvn.input.shape)\n",
    "mvn.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter Counting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2304 hidden nodes\n",
    "# 1 bias offset coefficient term weight\n",
    "# 9 paramters (3 means, 6 covariance parameters) for 3d independent multivariate normal distribution\n",
    "(128+1)*9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Distributional Components\n",
    "\n",
    "Often discussed with *Bayesian* terminology, e.g., as here: `https://github.com/tensorflow/probability/blob/master/tensorflow_probability/examples/vae.py`\n",
    "\n",
    "- Image Distribution: $X \\sim p_X$\n",
    "    - the marginal data distribution\n",
    "- Conditional Encoder Distribution: $Z|X \\sim q_{Z|X}$\n",
    "    - the \"posterior\"?\n",
    "- Conditional Decoder Distribution: $\\tilde X \\sim p_{\\tilde X|Z}$\n",
    "    - the \"likelihood\"?\n",
    "- Encoder Prior/Marginal Distribution: $Z \\sim p_{Z}$\n",
    "    - the \"prior\"?\n",
    "    \n",
    "<font style=\"color:blue\">But this is not actually typical *Bayes* where we're given the **data** $x$, **likelihood** $f(x|z)$, and the **prior** $\\pi(z)$ and use *Bayes Theorem* to derive the **posterior** $\\pi(z|x)$... **i.e., $z$ characterizes everything we don't know**</font>\n",
    "\n",
    "\n",
    "<font style=\"color:red\">With VAEs, ***instead***, we learn \n",
    "the **decoder** \"likelihood\" $p_{\\tilde X|Z}(x| Z)$,\n",
    "the **encoder** \"posterior\" $q(Z|x)$,\n",
    "and make the *latent (marginal)* **encoding distribution** $p(Z)$ \"prior\"\n",
    "match the \"posterior\" $q(Z|x)$ (or, effectively/more accurately, *vice-versa*).</font>\n",
    "\n",
    "<br>\n",
    "\n",
    "<font style=\"color:green\">\n",
    "Note: that last part about \"prior\" matching the \"posterior\" feels more accurate if the prior is, e.g., a mixture model.\n",
    "</font>\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "<font style=\"color:blue\"> Anyway, in VAEs, $Z$ is just the embedding variable... but what we're actually learning is ***EVERYTHING*** for **EVERY possible** $X=x$ [not just $\\pi(\\textbf{z}|x)$]: </font>\n",
    "\n",
    "<br>\n",
    "<font style=\"color:blue\">$$p_{\\tilde X|Z}(x| Z), \\;q(Z|x), \\text{ and } p(Z)$$.</font>\n",
    "\n",
    "*So this is more like nonparametric Bayes.*  I don't actually like the terminology because it suggests it's just about the latent embedding $Z$... \n",
    "\n",
    "*But it's [BOTH] much more than that...* and also less than that..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# since we're specifying p(Z)\n",
    "# we could experiment with specifying a mixture distribution for that (the \"prior\")\n",
    "# Not pursuing this implementation right now\n",
    "\n",
    "# https://www.tensorflow.org/probability/api_docs/python/tfp/distributions/MixtureSameFamily\n",
    "# https://www.tensorflow.org/probability/api_docs/python/tfp/layers/MixtureNormal\n",
    "# https://www.tensorflow.org/probability/api_docs/python/tfp/distributions/MultivariateNormalTriL\n",
    "\n",
    "if 0:\n",
    "    number_components = 25\n",
    "    latent_dimension = 3\n",
    "\n",
    "    locs = tf.Variable(np.zeros([number_components, latent_dimension], dtype=np.float32), \n",
    "                       name=\"locs\", trainable=True)\n",
    "    mixture_logits = tf.Variable(np.zeros([number_components], dtype=np.float32),\n",
    "                                 name=\"mixture_logits\", trainable=True)\n",
    "\n",
    "    # https://www.tensorflow.org/probability/examples/Learnable_Distributions_Zoo#mixture_of_multivariate_normal_full_cov\n",
    "    #scale_trils = [tfp.util.TransformedVariable(tf.eye(3, dtype=tf.float32),\n",
    "    #                                                     tfp.bijectors.FillScaleTriL(),\n",
    "    #                                                     name='comp_'+str(i)+'_TriL') for i in range(number_components)] \n",
    "    #tf.stack(\n",
    "\n",
    "\n",
    "    scale_trils=tfp.util.TransformedVariable(\n",
    "                tf.eye(latent_dimension, batch_shape=[number_components]),\n",
    "                bijector=tfp.bijectors.FillScaleTriL(),\n",
    "                name='scale_trils')\n",
    "\n",
    "    pr = tfd.MixtureSameFamily(\n",
    "         components_distribution=\n",
    "         tfd.MultivariateNormalTriL(loc=locs, scale_tril=scale_trils),\n",
    "         mixture_distribution=tfd.Categorical(logits=mixture_logits),\n",
    "         name=\"prior\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Evidence Lower BOund (ELBO)\n",
    "\n",
    "The standard way this is presented goes like this:\n",
    "- `https://github.com/tensorflow/probability/blob/master/tensorflow_probability/examples/vae.py`\n",
    "- `https://en.wikipedia.org/wiki/Jensen%27s_inequality`\n",
    "- `https://en.wikipedia.org/wiki/Kullback–Leibler_divergence`\n",
    "\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\log p(x) & = {} \\log \\int p(x|z) p(z) dz \\\\\n",
    "& = {} \\log \\int \\frac{p(x|z) p(z)}{\\textbf{q(z|x)}} \\textbf{q(z|x)} dz \\\\\n",
    "& = {} \\log \\textrm{E}_{\\textbf{Z}\\sim \\textbf{q(Z|x)}}\\left[\\frac{p(x|Z) p(Z)}{q(Z|x)}\\right] \\\\\n",
    "& \\underset{so \\; Jensen's}{\\overset{\\log concave}{\\geq}} {}\n",
    " \\textrm{E}_{Z\\sim q(Z|x)}\\left[\\textbf{log} \\frac{p(x|Z) p(Z)}{q(Z|x)}\\right] \n",
    " \\quad \\longleftarrow \\quad \\equiv {} \n",
    " -\\textrm{KL}[ \\; q(Z|x) \\; || \\; p(x|Z)p(Z)\\; ] \\\\\n",
    " & \\;\\;\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad= {} -\\textrm{KL}[ \\; q(Z|x) \\; || \\; p(x,Z)\\; ] \\\\\n",
    "& \\underset{\\sum \\textrm{of the} \\log \\;}{\\overset{\\log \\textrm{of the} \\prod \\;}{=}} {} \\textrm{E}_{Z\\sim q(Z|x)}\\left[\\log p(x|Z) + \\log \\frac{p(Z)}{q(Z|x)}\\right] \\\\ \n",
    "& = {} \\textrm{E}_{Z\\sim q(Z|x)}\\left[\\log p(x|Z) \\right] + \\textrm{E}_{Z\\sim q(Z|x)}\\left[\\log \\frac{p(Z)}{q(Z|x)}\\right] \\\\ \n",
    "& \\equiv {} \\textrm{E}_{Z\\sim q(Z|x)}\\left[\\log p(x|Z) \\right] - \\textrm{KL}[ \\; q(Z|x) \\; || \\; p(Z)\\; ]\\\\\n",
    "& = {} \\textrm{E[Reconstruction log-likelihood]} - \\textrm{KL}[ \\; q(Z|x) \\; || \\; p(Z)\\; ]\\end{align*}\n",
    "$$\n",
    "\n",
    "- The bigger this is the better our model for $x$, $p(x)$ (since $p(x)$ $\\geq$ `this`)\n",
    "- since KL is $\\geq 0$ we make $q(Z|x)$ as close to $p(Z)$ as possible\n",
    "    - and maximize $p_{\\tilde X|Z}(x| Z)$ (i.e., $\\textrm{E[Reconstruction log-likelihood]}$)\n",
    "\n",
    "\n",
    "# But it can also be derived this way...\n",
    "\n",
    "- from which you can more clearly see that even $q(z|x)$ is not estimating $p(z|x)$ and hence further deviating from a Bayesian analysis...\n",
    "- ...though we already knew that since $q(z|x)$ is trying to look like $p(z)$... which is not how a posterior distribution works... Anyway:\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\log p(x) & = {} \\int \\log p(x) q(z|x) dz \\\\\n",
    "& = {} \\int \\log \\frac{p(x|z) p(z)}{p(z|x)} q(z|x) dz \\\\\n",
    "& = {} \\int q(z|x) \\left( \\textbf{log} \\frac{\\textbf{p(x|z) p(z)}}{\\textbf{p(z|x)}} \\right) dz \\\\\n",
    "& = {} \\int q(z|x) \\left( \\log \\frac{p(x|z) p(z)}{\\textbf{q(z|x)}}\\frac{\\textbf{q(z|x)}}{p(z|x)} \\right) dz \\\\\n",
    "& = {} \\int q(z|x) \\left( \\log \\frac{p(x|z) p(z)}{q(z|x)} \\textbf{ +} \\log \\frac{q(z|x)}{p(z|x)} \\right) dz \\\\\n",
    "& = {} \\int q(z|x) \\log \\frac{p(x|z) p(z)}{q(z|x)} dz + \\int q(z|x) \\log \\frac{q(z|x)}{p(z|x)} dz \\\\\n",
    "& \\equiv {} -\\textrm{KL}[\\; q(Z|x) \\; || \\; p(x|Z) p(Z) \\;] - \\textrm{KL}[\\; q(Z|x) \\; || \\; p(Z|x) \\;] \\\\\n",
    "& \\geq {} - \\textrm{KL}[\\; q(Z|x) \\; || \\; p(x|Z) p(Z) \\;] \\quad \\text{$since$ KL $\\geq 0$} \\\\\n",
    "& = {} \\int q(z|x) \\log \\frac{p(x|z) p(z)}{q(z|x)} dz \\\\\n",
    "& = {} \\int q(z|x) \\log p(x|z) dz + \\int q(z|x) \\log \\frac{p(z)}{q(z|x)} dz \\\\\n",
    "& \\equiv {} \\textrm{E}_{Z\\sim q(Z|x)}\\left[\\log p(x|Z) \\right] - \\textrm{KL}[\\; q(Z|x) \\; || \\; p(Z) \\;] \\\\ \n",
    "& = {} \\textrm{E[Reconstruction log-likelihood]} - \\textrm{KL}[ \\; q(Z|x) \\; || \\; p(Z)\\; ]\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "- and we've arrived at the same place as we did above\n",
    "\n",
    "**So what we're doing is making a good model for $x$, $p(x)$.**\n",
    "- We're not actually trying to learn posterior distributions for the latent variables $Z$, $p(Z|x)$;\n",
    "- still, we did end up creating the \"decoder\" $p_{\\tilde X|Z}(x| Z)$\n",
    "- and as well creating $p(Z)$, which we can use to feed into that $p_{\\tilde X|Z}(x| Z)$ \"decoder\"\n",
    "    - and creating  a map $q(Z|x)$ into that space, which is how inform estimation of $p(Z)$ [if needed]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decoder\n",
    "\n",
    "$\\tilde x = $<font style='color:red'>$I$</font>$(mvn(f_{\\mu,\\sigma}(x)))$\n",
    "\n",
    "- $\\tilde x$: reconstructed image\n",
    "- $x$: input image\n",
    "- $f_{\\mu,\\sigma}$: image embedder\n",
    "- $mvn$: multivariate normal distribution\n",
    "- <font style='color:red'>$I$: image reconstructor</font>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.tensorflow.org/tutorials/generative/cvae\n",
    "# https://www.tensorflow.org/probability/examples/Probabilistic_Layers_VAE\n",
    "\n",
    "from tensorflow.keras.layers import Reshape, Conv2DTranspose\n",
    "\n",
    "decoder = Sequential([InputLayer(input_shape=(latent_dimension,)),\n",
    "                      Dense(units=7*7*32, activation='relu'),\n",
    "                      Reshape(target_shape=(7, 7, 32)),\n",
    "                      Conv2DTranspose(filters=64, kernel_size=square_kernel_size, \n",
    "                                      strides=x_y_stride_offset, padding='same', activation='relu'),\n",
    "                      Conv2DTranspose(filters=32, kernel_size=square_kernel_size, \n",
    "                                      strides=x_y_stride_offset, padding='same', activation='relu'),\n",
    "                      Conv2DTranspose(filters=1, kernel_size=square_kernel_size, \n",
    "                                      strides=1, padding='same', activation=None)],\n",
    "                     name='decoder')\n",
    "\n",
    "decoder.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# `Conv2DTranspose` versus `Conv2D`\n",
    "`https://keras.io/api/layers/convolution_layers/convolution2d_transpose/`\n",
    "\n",
    "\n",
    "- The need for transposed convolutions generally arises from \n",
    "    - the desire to use a transformation going in the opposite direction of a normal convolution, \n",
    "        - i.e., from ~~something that has **the shape of**~~ <u>*the output*</u> of some convolution \n",
    "        - to ~~something that has the **shape of**~~ <u>*its input*</u>  \n",
    "    - **while maintaining a connectivity pattern that is compatible with the \"original\" convolution.**\n",
    "\n",
    "\n",
    "\n",
    "# So, it maintains same connectivity patterns, just in the opposite direction\n",
    "- `https://datascience.stackexchange.com/questions/6107/what-are-deconvolutional-layers`\n",
    "- `https://github.com/vdumoulin/conv_arithmetic`\n",
    "\n",
    "\n",
    "| |4x4 Image w/ 3x3 Convolutional Kernel|5x5 Padded Image w/ 3x3 2-stride Convolutional Kernel|\n",
    "|-|:-:|:-:|\n",
    "|Forward Convolution: Blue $\\rightarrow$ Green | <img src=https://github.com/vdumoulin/conv_arithmetic/raw/master/gif/no_padding_no_strides.gif style=\"transform:rotate(180deg);\"> | <img src=https://github.com/vdumoulin/conv_arithmetic/raw/master/gif/padding_strides.gif style=\"transform:rotate(180deg);\"> |\n",
    "|Standard Convolution|$4x4 \\rightarrow 1x16 \\cdot 16x4 = 1x4 \\rightarrow 2x2$| $7x7 \\rightarrow 1x49 \\cdot 49x9 = 1x9 \\rightarrow 3x3$ |\n",
    "|Transposed Convolution|$4x4 \\leftarrow 1x16 \\cdot 16x4$ <font style=\"color:red\">$\\cdot 4x16$</font> $= [1x4 \\leftarrow 2x2]$ <font style=\"color:red\">$\\cdot 4x16$</font> | $7x7 \\leftarrow 1x49 \\cdot 49x9$ <font style=\"color:red\">$\\cdot 9x49$</font> $= [1x9 \\leftarrow 3x3]$ <font style=\"color:red\">$\\cdot 9x49$</font> |\n",
    "|\"Reverse\" Convolution: Blue $\\rightarrow$ Green| ![](https://i.stack.imgur.com/YyCu2.gif) | ![](https://i.stack.imgur.com/f2RiP.gif) | \n",
    "\n",
    "# `Conv2DTranspose`  doesn't actually do the convolutional sliding\n",
    "- it just sets up the transpose multiplication specification, corresponding the forward convolution parameterization\n",
    "- which is computationally much more efficient than operationalizing the implied convolution computations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/61110188/how-to-display-a-gif-in-jupyter-notebook-using-google-colab\n",
    "#from IPython.display import Image\n",
    "#Image(open('VAE/f2RiP.gif','rb').read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss\n",
    "\n",
    "$\\tilde x = I(mvn(f_{\\mu,\\sigma}(x)))$\n",
    "\n",
    "- <font style='color:red'>$\\tilde x$: reconstructed image</font>\n",
    "- <font style='color:red'>$x$: input image</font>\n",
    "- $f_{\\mu,\\sigma}$: image embedder\n",
    "- $mvn$: multivariate normal distribution\n",
    "- $I$: image reconstructor\n",
    "\n",
    "Each pixel (\"randomly\" on/off by our processing treatment above) will be predicted as a Bernoulli random variable:\n",
    "\n",
    "$$ \\huge Bernoulli(x, \\tilde x) = \\prod_{i,j} \\left(\\frac{1}{1+e^{-\\tilde x_{ij}}}\\right)^{x_{ij}}$$\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\tilde x = {} & \\log \\left(\\frac{p}{1-p}\\right)\\\\\n",
    "e^{\\tilde x} = {} &  \\frac{p}{1-p} \\\\\n",
    "e^{\\tilde x}-pe^{\\tilde x} = & {} p\\\\\n",
    "e^{\\tilde x} = {} & p + pe^{\\tilde x}\\\\\n",
    "e^{\\tilde x} = {} & p \\left(1+ e^{\\tilde x}\\right)\\\\\n",
    "e^{\\tilde x} = {} & p \\\\\n",
    "\\frac{e^{\\tilde x}}{1+ e^{\\tilde x}}  = {} & p \\\\\n",
    "\\frac{1}{1+ e^{-\\tilde x}}  = {} & p\n",
    "\\end{align*}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "likelihood = Sequential([InputLayer(input_shape=decoder.output.shape[1:]),\n",
    "                         Flatten(), # need to have a flat layer leading into tfpl\n",
    "# input is assumed to be logits, so `convert_to_tensor_fn` is just a reshape pass through\n",
    "                         tfpl.IndependentBernoulli(event_shape=list(train_images.shape[1:])+[1], \n",
    "                                                   convert_to_tensor_fn=tfd.Bernoulli.logits)],\n",
    "                       name='likelihood')\n",
    "# https://www.tensorflow.org/probability/api_docs/python/tfp/layers/IndependentBernoulli\n",
    "# https://github.com/tensorflow/tensorflow/issues/42589\n",
    "\n",
    "likelihood.summary() \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorFlow Probility Layers\n",
    "- Output Distributions!\n",
    "    - which can be instantiated as tensors\n",
    "    - or, just used as distributions!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "negloglik = lambda x, rv_tilde_x: -rv_tilde_x.log_prob(x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can but seemlessly used for gradient calculations\n",
    "\n",
    "if 0:\n",
    "    opt = tf.optimizers.Adam(learning_rate=1e-3)\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss = negloglik(var, x)\n",
    "      gradients = tape.gradient(loss, model.trainable_variables)\n",
    "      opt.apply_gradients(zip(gradients, model.trainable_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Model \n",
    "vae = Model(inputs=encoder.input,\n",
    "                outputs=likelihood(decoder(mvn(encoder(encoder.input)))))\n",
    "\n",
    "vae.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "vae.compile(optimizer=tf.optimizers.Adam(learning_rate=1e-3),\n",
    "            loss=negloglik) # assumes (y,y-hat) will be passed\n",
    "\n",
    "# train_dataset (x,y) is (x,x)\n",
    "# x in (x,y) is used to create tilde-x=y-hat\n",
    "# y in (x,y) is x\n",
    "# passes (y,y-hat)==(x,tilde-x) to loss function\n",
    "# tilde-x is a distribution\n",
    "hist = vae.fit(train_dataset, epochs=3,\n",
    "               validation_data=eval_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_image = next(iter(train_dataset))[0][0,...,0]\n",
    "plt.imshow(~current_image, cmap=plt.cm.binary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "fig,ax = plt.subplots(2,2)\n",
    "ax=ax.flatten()\n",
    "for i in range(4):\n",
    "    current_image_reconstruction = vae(current_image[np.newaxis,...,np.newaxis]).sample()\n",
    "    ax[i].imshow(1-current_image_reconstruction[0,...,0], cmap=plt.cm.binary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_image_reconstruction_ave = vae(current_image[np.newaxis,...]).mean()\n",
    "plt.imshow(1-current_image_reconstruction_ave[0,...,0], cmap=plt.cm.binary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "randomly_generated_image = likelihood(decoder(prior.sample(1))).mean()\n",
    "plt.imshow(randomly_generated_image[0,...,0], cmap=plt.cm.binary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://plotly.com/python/3d-scatter-plots/\n",
    "\n",
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "\n",
    "fig = px.scatter_3d()\n",
    "\n",
    "means = []\n",
    "for i in range(10):\n",
    "    embedding = mvn(encoder((train_images[train_labels==i,...,np.newaxis][:100,...]/255.).round(0))).mean().numpy()\n",
    "    means += [np.mean(embedding, axis=0)]\n",
    "    df = pd.DataFrame(embedding, columns=list('xyz'))\n",
    "    df['c'] = i\n",
    "    if i < 10:\n",
    "        fig.add_scatter3d(x=df.x, y=df.y, z=df.z, mode='markers', name=str(i))\n",
    "        \n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1,10, figsize=(30,30))\n",
    "ax = ax.flatten()\n",
    "for i in range(10):\n",
    "    ax[i].imshow(likelihood(decoder(means[i][np.newaxis,...])).mode()[0,...,0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
