{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n",
    "- TF Data API\n",
    "- TFRecord format\n",
    "- ~~standard Keras preprocessing layers~~\n",
    "- custom preprocessing layers\n",
    "- ~~TFDS~~\n",
    "- ~~tf.Transform~~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standard Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF Dataset API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=int32, numpy=array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=int32)>"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = tf.range(10)\n",
    "# a tensor\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- What data will be in here? \n",
    "- What data frormat will this have?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TensorSliceDataset shapes: (), types: tf.int32>"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Hint:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(0, shape=(), dtype=int32)\n",
      "tf.Tensor(1, shape=(), dtype=int32)\n",
      "tf.Tensor(2, shape=(), dtype=int32)\n",
      "tf.Tensor(3, shape=(), dtype=int32)\n",
      "tf.Tensor(4, shape=(), dtype=int32)\n",
      "tf.Tensor(5, shape=(), dtype=int32)\n",
      "tf.Tensor(6, shape=(), dtype=int32)\n",
      "tf.Tensor(7, shape=(), dtype=int32)\n",
      "tf.Tensor(8, shape=(), dtype=int32)\n",
      "tf.Tensor(9, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "for item in dataset:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([0 1 2 3 4 5 6], shape=(7,), dtype=int32)\n",
      "tf.Tensor([7 8 9 0 1 2 3], shape=(7,), dtype=int32)\n",
      "tf.Tensor([4 5 6 7 8 9 0], shape=(7,), dtype=int32)\n",
      "tf.Tensor([1 2 3 4 5 6 7], shape=(7,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# here's some cool functionality\n",
    "dataset = dataset.repeat(3).batch(7, drop_remainder=True)\n",
    "for item in dataset:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices(X)\n",
    "dataset = dataset.repeat(2).batch(4, drop_remainder=True).map(lambda x: x * 2, num_parallel_calls=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- What will this be?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ParallelMapDataset shapes: (4,), types: tf.int32>"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Answer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([0 2 4 6], shape=(4,), dtype=int32)\n",
      "tf.Tensor([ 8 10 12 14], shape=(4,), dtype=int32)\n",
      "tf.Tensor([16 18  0  2], shape=(4,), dtype=int32)\n",
      "tf.Tensor([ 4  6  8 10], shape=(4,), dtype=int32)\n",
      "tf.Tensor([12 14 16 18], shape=(4,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "for item in dataset:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.unbatch()\n",
    "# dataset = dataset.apply(tf.data.experimental.unbatch())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- What will this be?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(0, shape=(), dtype=int32)\n",
      "tf.Tensor(2, shape=(), dtype=int32)\n",
      "tf.Tensor(4, shape=(), dtype=int32)\n",
      "tf.Tensor(6, shape=(), dtype=int32)\n",
      "tf.Tensor(8, shape=(), dtype=int32)\n",
      "tf.Tensor(10, shape=(), dtype=int32)\n",
      "tf.Tensor(12, shape=(), dtype=int32)\n",
      "tf.Tensor(14, shape=(), dtype=int32)\n",
      "tf.Tensor(16, shape=(), dtype=int32)\n",
      "tf.Tensor(18, shape=(), dtype=int32)\n",
      "tf.Tensor(0, shape=(), dtype=int32)\n",
      "tf.Tensor(2, shape=(), dtype=int32)\n",
      "tf.Tensor(4, shape=(), dtype=int32)\n",
      "tf.Tensor(6, shape=(), dtype=int32)\n",
      "tf.Tensor(8, shape=(), dtype=int32)\n",
      "tf.Tensor(10, shape=(), dtype=int32)\n",
      "tf.Tensor(12, shape=(), dtype=int32)\n",
      "tf.Tensor(14, shape=(), dtype=int32)\n",
      "tf.Tensor(16, shape=(), dtype=int32)\n",
      "tf.Tensor(18, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "for item in dataset:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.filter(lambda x: x < 10).batch(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- What will this be?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([0 2 4 6 8], shape=(5,), dtype=int32)\n",
      "tf.Tensor([0 2 4 6 8], shape=(5,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "for item in dataset:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Which of these will produce only the top line above?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([0 2 4 6 8], shape=(5,), dtype=int32)\n",
      "tf.Tensor([0 2 4 6 8], shape=(5,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# for item in dataset.take(1):\n",
    "for item in dataset.take(5):\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([0 2 3], shape=(3,), dtype=int64)\n",
      "tf.Tensor([1 4 0], shape=(3,), dtype=int64)\n",
      "tf.Tensor([2 3 4], shape=(3,), dtype=int64)\n",
      "tf.Tensor([1 0 1], shape=(3,), dtype=int64)\n",
      "tf.Tensor([3 4 2], shape=(3,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "dataset = tf.data.Dataset.range(5).repeat(3) # 0 to 4, three times\n",
    "dataset = dataset.shuffle(buffer_size=10000).batch(3) # `shuffle` has `seed` paramater, e.g., \"seed=42\"\n",
    "\n",
    "for item in dataset:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- How is `suffle` above with `buffer_size=2` working?\n",
    "- (Hint #1: *batch is the last method applied*)\n",
    "- (Hint #2: *watch where 0 and 4 can land*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 609,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([0 3 1 4 2 8 7 5 9 6], shape=(10,), dtype=int64)\n",
      "tf.Tensor([0 3 1 4 2 8 7 5 9 6], shape=(10,), dtype=int64)\n",
      "tf.Tensor([0 3 1 4 2 8 7 5 9 6], shape=(10,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "dataset = tf.data.Dataset.range(10).shuffle(buffer_size=5, reshuffle_each_iteration=False)\n",
    "dataset = dataset.repeat(3).batch(10)\n",
    "for item in dataset:\n",
    "    print(item)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **WATCH OUT! Don't do the \"shuffle-then-repeat\" order above!**\n",
    "\n",
    "If you're not shuffling, the same order will be repeated at each epoch, and the model may end up being biased (e.g., due to some spurious patterns present by chance in the source dataâ€™s order).\n",
    "\n",
    "Here some things to think about!\n",
    "\n",
    "1. linux `shuf` can shuffle an original file\n",
    "2. if the original file is big\n",
    "    1. split the source data into multiple files\n",
    "    2. read them in a random order during training\n",
    "        - or even better: pick multiple files randomly and read them simultaneously, interleaving their records\n",
    "3. always have `tf.data.Dataset.shuffle` \"on\" \n",
    "\n",
    "This will help limit the potential for some weird \"order bias\" to affect things\n",
    "\n",
    "## Demo: here's how we can do this in just a few lines of code\n",
    "- **Going to use just use the pre-run from earlier today as the downloads were a bit flaky**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/50236117/scraping-ssl-certificate-verify-failed-error-for-http-en-wikipedia-org\n",
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.dcc.fc.up.pt/~ltorgo/Regression/cal_housing.tgz\n",
      "442368/441963 [==============================] - 3s 8us/step\n"
     ]
    }
   ],
   "source": [
    "# https://github.com/scikit-learn/scikit-learn/blob/0fb307bf3/sklearn/datasets/_california_housing.py#L53\n",
    "# The original data can be found at:\n",
    "# https://www.dcc.fc.up.pt/~ltorgo/Regression/cal_housing.tgz\n",
    "\n",
    "# https://www.tensorflow.org/api_docs/python/tf/keras/utils/get_file\n",
    "train_dataset_url = \"https://www.dcc.fc.up.pt/~ltorgo/Regression/cal_housing.tgz\"\n",
    "path = \"/Users/gck8gd/Documents/courses/SYS_6016_DeepLearning/L11/\"\n",
    "file = \"calihousie.csv\"\n",
    "train_dataset_fp = tf.keras.utils.get_file(fname=path+file, origin=train_dataset_url, untar=True, extract=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Note: the above only worked after a kernel restart and a few tries...?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calihousie.csv.tar.gz\r\n"
     ]
    }
   ],
   "source": [
    "path = '/Users/gck8gd/Documents/courses/SYS_6016_DeepLearning/L11/'\n",
    "! ls {path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calihousie.csv.tar\r\n"
     ]
    }
   ],
   "source": [
    "! gunzip {path}calihousie.csv.tar.gz \n",
    "! ls {path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/gck8gd/Documents/courses/SYS_6016_DeepLearning/L11/\r\n"
     ]
    }
   ],
   "source": [
    "! echo {path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x CaliforniaHousing/cal_housing.data\r\n",
      "x CaliforniaHousing/cal_housing.domain\r\n"
     ]
    }
   ],
   "source": [
    "# https://askubuntu.com/questions/45349/how-to-extract-files-to-another-directory-using-tar-command\n",
    "! tar -xvf {path}calihousie.csv.tar -C {path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mCaliforniaHousing\u001b[m\u001b[m  calihousie.csv.tar\r\n"
     ]
    }
   ],
   "source": [
    "! ls {path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   20640 /Users/gck8gd/Documents/courses/SYS_6016_DeepLearning/L11/CaliforniaHousing/cal_housing.data\r\n"
     ]
    }
   ],
   "source": [
    "! wc -l  {path}CaliforniaHousing/cal_housing.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Everything below is just for functionality demonstration purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "! tail -4096 {path}CaliforniaHousing/cal_housing.data > tmp\n",
    "! mv tmp {path}CaliforniaHousing/cal_housing.data.test\n",
    "! head -16544 {path}CaliforniaHousing/cal_housing.data > tmp\n",
    "! mv tmp {path}CaliforniaHousing/cal_housing.data.train\n",
    "! tail -4096 {path}CaliforniaHousing/cal_housing.data.train > tmp\n",
    "! mv tmp {path}CaliforniaHousing/cal_housing.data.vali\n",
    "! head -12448 {path}CaliforniaHousing/cal_housing.data > tmp\n",
    "! mv tmp {path}CaliforniaHousing/cal_housing.data.train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20640"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test + rest\n",
    "4096+16544"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16544"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rest + validation\n",
    "12448+4096"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1024.0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test and validation can be split into 4 sets of 1024\n",
    "2**12/4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here we're going to pretend we had 6 \"very large\" separated data files, again for demonstration purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cal_housing.data       cal_housing.data.4     cal_housing.data.train\r\n",
      "cal_housing.data.1     cal_housing.data.5     cal_housing.data.vali\r\n",
      "cal_housing.data.2     cal_housing.data.6     cal_housing.domain\r\n",
      "cal_housing.data.3     cal_housing.data.test\r\n"
     ]
    }
   ],
   "source": [
    "# https://blog.jpalardy.com/posts/how-to-shuffle-and-sample-on-the-command-line/\n",
    "# brew install coreutils\n",
    "! gshuf {path}CaliforniaHousing/cal_housing.data.train > {path}CaliforniaHousing/cal_housing.data.1\n",
    "! gshuf {path}CaliforniaHousing/cal_housing.data.train > {path}CaliforniaHousing/cal_housing.data.2\n",
    "! gshuf {path}CaliforniaHousing/cal_housing.data.train > {path}CaliforniaHousing/cal_housing.data.3\n",
    "! gshuf {path}CaliforniaHousing/cal_housing.data.train > {path}CaliforniaHousing/cal_housing.data.4\n",
    "! gshuf {path}CaliforniaHousing/cal_housing.data.train > {path}CaliforniaHousing/cal_housing.data.5\n",
    "! gshuf {path}CaliforniaHousing/cal_housing.data.train > {path}CaliforniaHousing/cal_housing.data.6\n",
    "! ls {path}CaliforniaHousing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/19031144/how-to-split-one-text-file-into-multiple-txt-files\n",
    "! split -l 1024 {path}CaliforniaHousing/cal_housing.data.test {path}CaliforniaHousing/cal_housing.data.test.\n",
    "! split -l 1024 {path}CaliforniaHousing/cal_housing.data.vali {path}CaliforniaHousing/cal_housing.data.vali."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cal_housing.data         cal_housing.data.test    cal_housing.data.vali.aa\r\n",
      "cal_housing.data.1       cal_housing.data.test.aa cal_housing.data.vali.ab\r\n",
      "cal_housing.data.2       cal_housing.data.test.ab cal_housing.data.vali.ac\r\n",
      "cal_housing.data.3       cal_housing.data.test.ac cal_housing.data.vali.ad\r\n",
      "cal_housing.data.4       cal_housing.data.test.ad cal_housing.domain\r\n",
      "cal_housing.data.5       cal_housing.data.train\r\n",
      "cal_housing.data.6       cal_housing.data.vali\r\n"
     ]
    }
   ],
   "source": [
    "! ls {path}CaliforniaHousing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RAN THIS IN THE TERMINAL\n",
    "\n",
    "- It is too challenging to make complex bash work through a notebook\n",
    "- E.g., https://stackoverflow.com/questions/34972035/awk-print-with-pipes-not-working-ipython-in-jupyter-notebook\n",
    "- and the one-liners get *very* long: https://www.cyberciti.biz/faq/linux-unix-bash-for-loop-one-line-command/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SO THIS WAS NOT RUN HERE: IT WAS RUN IN THE TERMINAL\n",
    "\n",
    "# https://stackoverflow.com/questions/9506810/add-column-to-end-of-csv-file-using-awk-in-bash-script\n",
    "# https://www.cyberciti.biz/faq/bash-for-loop/\n",
    "\n",
    "path=/Users/gck8gd/Documents/courses/SYS_6016_DeepLearning/L11/\n",
    "for i in 1 2 3 4 5 6\n",
    "do \n",
    "   cat \"$path\"CaliforniaHousing/cal_housing.data.\"$i\" | awk -v i=$i -v OFS=, '{print i, $0}' > tmp\n",
    "   mv tmp \"$path\"CaliforniaHousing/cal_housing.data.\"$i\"\n",
    "done    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1,-118.450000,34.210000,30.000000,2331.000000,733.000000,2172.000000,707.000000,2.188800,195600.000000\r\n",
      "1,-118.160000,34.600000,5.000000,7294.000000,1139.000000,3123.000000,930.000000,4.990400,154100.000000\r\n",
      "1,-118.370000,34.190000,41.000000,2924.000000,867.000000,2751.000000,836.000000,2.100000,171600.000000\r\n",
      "1,-117.820000,33.900000,25.000000,1137.000000,170.000000,524.000000,164.000000,7.574400,259300.000000\r\n",
      "1,-120.020000,39.240000,24.000000,1602.000000,426.000000,751.000000,257.000000,1.760900,99300.000000\r\n",
      "1,-118.050000,33.860000,16.000000,2676.000000,391.000000,1377.000000,395.000000,6.551300,350400.000000\r\n",
      "1,-121.920000,36.570000,42.000000,3944.000000,738.000000,1374.000000,598.000000,4.174000,394400.000000\r\n",
      "1,-118.150000,34.210000,34.000000,2765.000000,515.000000,1422.000000,438.000000,5.472700,238900.000000\r\n",
      "1,-117.800000,33.900000,22.000000,3760.000000,482.000000,1485.000000,461.000000,7.853700,354900.000000\r\n",
      "1,-115.600000,33.040000,31.000000,314.000000,61.000000,152.000000,56.000000,3.347200,91700.000000\r\n"
     ]
    }
   ],
   "source": [
    "! head {path}CaliforniaHousing/cal_housing.data.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2,-118.140000,34.090000,20.000000,3447.000000,1007.000000,2622.000000,934.000000,2.918000,208700.000000\r\n",
      "2,-118.340000,33.830000,34.000000,1761.000000,329.000000,965.000000,329.000000,5.399000,358500.000000\r\n",
      "2,-122.030000,37.530000,18.000000,1746.000000,437.000000,1268.000000,404.000000,3.256000,183300.000000\r\n",
      "2,-121.280000,38.750000,52.000000,493.000000,89.000000,189.000000,94.000000,2.108000,83800.000000\r\n",
      "2,-119.640000,36.820000,14.000000,4872.000000,656.000000,2085.000000,617.000000,5.673900,173800.000000\r\n",
      "2,-118.150000,33.770000,39.000000,2428.000000,634.000000,1312.000000,612.000000,2.721200,266300.000000\r\n",
      "2,-119.450000,35.160000,34.000000,3437.000000,696.000000,1783.000000,608.000000,2.391200,52900.000000\r\n",
      "2,-118.220000,34.660000,17.000000,3810.000000,662.000000,1867.000000,586.000000,4.900000,152400.000000\r\n",
      "2,-118.090000,33.890000,42.000000,991.000000,215.000000,717.000000,219.000000,4.092600,164400.000000\r\n",
      "2,-118.470000,34.000000,38.000000,1235.000000,390.000000,891.000000,376.000000,2.714300,287500.000000\r\n"
     ]
    }
   ],
   "source": [
    "! head {path}CaliforniaHousing/cal_housing.data.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Starting up live coding again**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/gck8gd/Documents/courses/SYS_6016_DeepLearning/L11/CaliforniaHousing/cal_housing.data.[0-9]'"
      ]
     },
     "execution_count": 380,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = '/Users/gck8gd/Documents/courses/SYS_6016_DeepLearning/L11/'\n",
    "# watch out! this won't work!\n",
    "#train_filepaths = path+'CaliforniaHousing/cal_housing.data.*'\n",
    "train_filepaths = path+'CaliforniaHousing/cal_housing.data.[0-9]'\n",
    "train_filepaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [],
   "source": [
    "vali_filepaths = path+'CaliforniaHousing/cal_housing.data.vali.*'\n",
    "test_filepaths = path+'CaliforniaHousing/cal_housing.data.test.*'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(b'/Users/gck8gd/Documents/courses/SYS_6016_DeepLearning/L11/CaliforniaHousing/cal_housing.data.2', shape=(), dtype=string)\n",
      "tf.Tensor(b'/Users/gck8gd/Documents/courses/SYS_6016_DeepLearning/L11/CaliforniaHousing/cal_housing.data.1', shape=(), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "filepath_dataset = tf.data.Dataset.list_files(train_filepaths)#, seed=42)\n",
    "for item in filepath_dataset.take(2):\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(b'/Users/gck8gd/Documents/courses/SYS_6016_DeepLearning/L11/CaliforniaHousing/cal_housing.data.4', shape=(), dtype=string)\n",
      "tf.Tensor(b'/Users/gck8gd/Documents/courses/SYS_6016_DeepLearning/L11/CaliforniaHousing/cal_housing.data.2', shape=(), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "for item in filepath_dataset.take(2):\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- How many more times can I run the above?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(b'/Users/gck8gd/Documents/courses/SYS_6016_DeepLearning/L11/CaliforniaHousing/cal_housing.data.3', shape=(), dtype=string)\n",
      "tf.Tensor(b'/Users/gck8gd/Documents/courses/SYS_6016_DeepLearning/L11/CaliforniaHousing/cal_housing.data.6', shape=(), dtype=string)\n",
      "tf.Tensor(b'/Users/gck8gd/Documents/courses/SYS_6016_DeepLearning/L11/CaliforniaHousing/cal_housing.data.1', shape=(), dtype=string)\n",
      "tf.Tensor(b'/Users/gck8gd/Documents/courses/SYS_6016_DeepLearning/L11/CaliforniaHousing/cal_housing.data.4', shape=(), dtype=string)\n",
      "tf.Tensor(b'/Users/gck8gd/Documents/courses/SYS_6016_DeepLearning/L11/CaliforniaHousing/cal_housing.data.5', shape=(), dtype=string)\n",
      "tf.Tensor(b'/Users/gck8gd/Documents/courses/SYS_6016_DeepLearning/L11/CaliforniaHousing/cal_housing.data.2', shape=(), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "for item in filepath_dataset:\n",
    "    print(item)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_readers = 3\n",
    "dataset = filepath_dataset.interleave(\n",
    "    lambda filepath: tf.data.TextLineDataset(filepath), # add `.skip(1)`, if header present\n",
    "    cycle_length=n_readers,\n",
    "    num_parallel_calls=1)#tf.data.experimental.AUTOTUNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'6,-117.790000,33.690000,16.000000,3067.000000,396.000000,1275.000000,372.000000,8.738500,340000.000000'\n",
      "b'2,-118.140000,34.090000,20.000000,3447.000000,1007.000000,2622.000000,934.000000,2.918000,208700.000000'\n",
      "b'5,-117.750000,34.070000,52.000000,2550.000000,586.000000,1246.000000,576.000000,1.600600,146200.000000'\n",
      "b'6,-118.200000,33.970000,43.000000,825.000000,212.000000,820.000000,184.000000,1.889700,174300.000000'\n",
      "b'2,-118.340000,33.830000,34.000000,1761.000000,329.000000,965.000000,329.000000,5.399000,358500.000000'\n",
      "b'5,-117.350000,33.690000,11.000000,1229.000000,236.000000,581.000000,190.000000,3.102000,111300.000000'\n",
      "b'6,-119.120000,35.390000,13.000000,1264.000000,202.000000,552.000000,187.000000,4.590300,94300.000000'\n",
      "b'2,-122.030000,37.530000,18.000000,1746.000000,437.000000,1268.000000,404.000000,3.256000,183300.000000'\n",
      "b'5,-118.390000,34.190000,41.000000,2000.000000,485.000000,1439.000000,461.000000,3.049100,192000.000000'\n",
      "b'6,-118.310000,33.750000,36.000000,2715.000000,474.000000,1303.000000,457.000000,4.604200,357300.000000'\n",
      ".\n",
      ".\n",
      ".\n",
      "\n",
      "b'3,-118.180000,34.040000,42.000000,1670.000000,434.000000,1997.000000,452.000000,2.788000,150500.000000'\n",
      "b'1,-118.450000,34.210000,30.000000,2331.000000,733.000000,2172.000000,707.000000,2.188800,195600.000000'\n",
      "b'4,-118.150000,33.920000,28.000000,1038.000000,252.000000,912.000000,245.000000,2.587500,161200.000000'\n",
      "b'3,-118.190000,34.110000,40.000000,1266.000000,348.000000,1032.000000,315.000000,2.166700,150000.000000'\n",
      "b'1,-118.160000,34.600000,5.000000,7294.000000,1139.000000,3123.000000,930.000000,4.990400,154100.000000'\n",
      "b'4,-117.800000,33.690000,13.000000,1161.000000,289.000000,630.000000,296.000000,3.343800,333300.000000'\n",
      "b'3,-118.230000,33.920000,24.000000,1555.000000,406.000000,1665.000000,361.000000,1.643700,98800.000000'\n",
      "b'1,-118.370000,34.190000,41.000000,2924.000000,867.000000,2751.000000,836.000000,2.100000,171600.000000'\n",
      "b'4,-121.550000,39.440000,31.000000,1434.000000,283.000000,811.000000,289.000000,1.772700,49000.000000'\n"
     ]
    }
   ],
   "source": [
    "i=0\n",
    "\n",
    "# taking enough to get through the first 3 files\n",
    "for item in dataset.take(3*12448+10):\n",
    "    \n",
    "    # printing out the first 10 and the next 10 after we get through the first three files\n",
    "    if i<10 or i>3*12448:\n",
    "        print(item.numpy())\n",
    "    if i==10:\n",
    "        print('.\\n.\\n.\\n')\n",
    "\n",
    "    i+=1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- So what's the scheme here?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_mean, X_std = [...] # mean and scale of each feature in the training set\n",
    "n_inputs = 8 # we've added the file indicator\n",
    "\n",
    "def preprocess(line):\n",
    "    \n",
    "    defs = [0.] * n_inputs + [tf.constant([], dtype=tf.float32)] # making it a tensor\n",
    "    fields = tf.io.decode_csv(line, select_cols=list(range(1,10)), record_defaults=defs) # list of tensor objects\n",
    "                                                                                         # sans file indicator column\n",
    "    x = tf.stack(fields[:-1]) # stack them into a feature vector (tensor datatype)\n",
    "    y = tf.stack(fields[-1:]) # create the corresponding output dimensions\n",
    "    #return (x - X_mean) / X_std, y\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(8,), dtype=float32, numpy=\n",
       " array([-117.94  ,   34.15  ,   33.    ,  859.    ,  144.    ,  421.    ,\n",
       "         138.    ,    4.4821], dtype=float32)>,\n",
       " <tf.Tensor: shape=(1,), dtype=float32, numpy=array([220100.], dtype=float32)>)"
      ]
     },
     "execution_count": 414,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess(b'1, -117.940000,34.150000,33.000000,859.000000,144.000000,421.000000,138.000000,4.482100,220100.000000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_dataset = dataset.map(preprocess, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 1\n",
    "t = [0]\n",
    "for row in final_dataset.shuffle(1).repeat(1).batch(1):\n",
    "    t += row[0]\n",
    "    i += 1\n",
    "\n",
    "m = t/i\n",
    "s = [0]\n",
    "for row in final_dataset.shuffle(1).repeat(1).batch(1):\n",
    "    s += (row[0]-m)**2\n",
    "\n",
    "s = (s/(i-1))**(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 8), dtype=float32, numpy=\n",
       "array([[-119.18004  ,   35.26199  ,   29.80463  , 2566.094    ,\n",
       "         532.48895  , 1424.7582   ,  493.85574  ,    3.8675482]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 417,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 8), dtype=float32, numpy=\n",
       "array([[3.1233069e-01, 2.6048949e-01, 6.6820947e-03, 2.0612947e-07,\n",
       "        5.4441530e-06, 7.9547368e-07, 6.6604612e-06, 2.6287237e-01]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 418,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_mean, X_std = m,s # mean and scale of each feature in the training set\n",
    "\n",
    "def preprocess(line):\n",
    "    defs = [0.] * n_inputs + [tf.constant([], dtype=tf.float32)]\n",
    "    fields = tf.io.decode_csv(line, select_cols=list(range(1,10)), record_defaults=defs)\n",
    "    x = tf.stack(fields[:-1])\n",
    "    y = tf.stack(fields[-1:])\n",
    "    return (x - X_mean) / X_std, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def csv_reader_dataset(filepaths, n_readers=2, n_read_threads=tf.data.experimental.AUTOTUNE,\n",
    "                       shuffle_buffer_size=10000, repeat=1, \n",
    "                       n_parse_threads=tf.data.experimental.AUTOTUNE,\n",
    "                       batch_size=32):\n",
    "    \n",
    "    # building the interleaved data set just as we did above\n",
    "    dataset = tf.data.Dataset.list_files(filepaths)\n",
    "    dataset = dataset.interleave(lambda filepath: tf.data.TextLineDataset(filepath),\n",
    "                                 cycle_length=n_readers, \n",
    "                                 num_parallel_calls=n_read_threads)\n",
    "                                 # so that's the first row of arguments\n",
    "                                     \n",
    "    # now we have a rolling window, and we repeat that data set some number of duplications \n",
    "    dataset = dataset.shuffle(shuffle_buffer_size).repeat(repeat)\n",
    "    # `reshuffle_each_iteration=True` is the default in `shuffle`, so each repeat order will vary\n",
    "    \n",
    "    # and when the data comes out, we standarize it, and this may be threaded\n",
    "    dataset = dataset.map(preprocess, num_parallel_calls=n_parse_threads)\n",
    "    \n",
    "    # finally we set the batch, and possibly get the next batch ready \n",
    "    # while the current batch is proocessing through the NN\n",
    "    return dataset.batch(batch_size).prefetch(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note:\n",
    "\n",
    "- If you have enough RAM, you might not want to re-preprocess at each epoch\n",
    "- There is a `.cache()` method for TF Datasets that avoids this\n",
    "- while still shuffling, repeating, batching, and prefetching distinctly at each epoch\n",
    "\n",
    "*Of course, you can always pre-preprocess...*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are some other potentially useful data processing capabilities that might do just the trick for what you need in any given circumnstance:\n",
    "- `concatenate()`\n",
    "- `zip()`\n",
    "- `window()`\n",
    "- `reduce()`\n",
    "- `shard()`\n",
    "- `flat_map()` \n",
    "- `padded_batch()`\n",
    "- `from_generator()`\n",
    "- `from_tensors()`\n",
    "- `tf.data.experimental`\n",
    "    - `CsvDataset`\n",
    "    - `make_csv_dataset()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Going to skip this for now -- the basic idea should be clear\n",
    "- however because only the *train_filepaths* have the extra file indicator column we added, we would need to define the correct csv_reader_dataset2 to use on the *test_filepaths* and *vali_filepaths* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = csv_reader_dataset(train_filepaths)\n",
    "validation_dataset = csv_reader_dataset2(vali_filepaths)\n",
    "test_dataset = csv_reader_dataset2(test_filepaths)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "4771/4771 [==============================] - 75s 16ms/step - loss: 205509.9688 - val_loss: 180268.1562\n",
      "Epoch 2/3\n",
      "4771/4771 [==============================] - 77s 16ms/step - loss: 198368.3281 - val_loss: 169853.0625\n",
      "Epoch 3/3\n",
      "4771/4771 [==============================] - 79s 17ms/step - loss: 184238.6562 - val_loss: 152307.3906\n"
     ]
    }
   ],
   "source": [
    "# instead of adding preprocessing in the map, you could also add it as a layer here\n",
    "# the \"Hands-On ML\" textbook walks through a couple ways to that:\n",
    "# - Lambda layer\n",
    "# - Custom layer\n",
    "# - `tf.keras.layers.Normalization`\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "  tf.keras.Input(shape=(1,8,)),\n",
    "  tf.keras.layers.Dense(1024),\n",
    "  tf.keras.layers.BatchNormalization(), \n",
    "  tf.keras.layers.ReLU(),\n",
    "  tf.keras.layers.Dense(512),\n",
    "  tf.keras.layers.BatchNormalization(), \n",
    "  tf.keras.layers.ReLU(),\n",
    "  tf.keras.layers.Dense(256),\n",
    "  tf.keras.layers.BatchNormalization(), \n",
    "  tf.keras.layers.ReLU(),\n",
    "  tf.keras.layers.Dense(128),\n",
    "  tf.keras.layers.BatchNormalization(), \n",
    "  tf.keras.layers.ReLU(),\n",
    "  tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "\n",
    "model.compile(optimizer='rmsprop', loss=tf.keras.losses.MAE)\n",
    "# https://stackoverflow.com/questions/41908379/keras-plot-training-validation-and-test-set-accuracy\n",
    "history = model.fit(train_dataset, epochs=3, validation_data=validation_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f90ee5e1820>]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#history.history.keys()\n",
    "plt.plot(history.history['loss'],label='loss')\n",
    "plt.plot(history.history['val_loss'],label='val_loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4771/4771 [==============================] - 6s 1ms/step - loss: 174910.2344\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "174910.234375"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model.evaluate(train_dataset)\n",
    "model.evaluate(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([36999.676, 36773.45 , 37088.066], dtype=float32)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_set = test_dataset.take(1).map(lambda X, y: X) # take returns a batch\n",
    "model.predict(new_set)[:3,0,0] # a dataset containing new instances\n",
    "# just looking at first 3 of the new instances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TFRecord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.io.TFRecordWriter(\"my_data.tfrecord\") as f:\n",
    "    f.write(b\"This is the first record\")\n",
    "    f.write(b\"And this is the second record\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepaths = [\"my_data.tfrecord\"]\n",
    "dataset = tf.data.TFRecordDataset(filepaths)\n",
    "for item in dataset:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! head my_data.tfrecord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "options = tf.io.TFRecordOptions(compression_type=\"GZIP\")\n",
    "with tf.io.TFRecordWriter(\"my_compressed.tfrecord\", options) as f:\n",
    "    f.write(b\"This is the first record\")\n",
    "    f.write(b\"And this is the second record\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! head my_compressed.tfrecord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.TFRecordDataset([\"my_compressed.tfrecord\"])\n",
    "#dataset = tf.data.TFRecordDataset([\"my_compressed.tfrecord\"],\n",
    "#                                  compression_type=\"GZIP\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in dataset.take(2):\n",
    "    print(item.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- So it knows how to read itself"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's return to the previous data set we were looking at:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = csv_reader_dataset(train_filepaths)\n",
    "\n",
    "for item in train_dataset.take(1):\n",
    "    print(item)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We're going to package it up in a TFRecord form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.train import BytesList, FloatList, Int64List\n",
    "from tensorflow.train import Feature, Features, Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calihouse_example = Example(\n",
    "    features=Features(\n",
    "        feature={\n",
    "# Example from textbook looked something like this:    \n",
    "#             \"name\": Feature(bytes_list=BytesList(value=[b\"Alice\"])),\n",
    "#             \"id\": Feature(int64_list=Int64List(value=[123])),\n",
    "#             \"emails\": Feature(bytes_list=BytesList(value=[b\"a@b.com\", b\"c@d.com\"]))\n",
    "            \"longitude\": Feature(float_list=FloatList(value=[item[0][0,0,0].numpy()])),\n",
    "            \"latitude\": Feature(float_list=FloatList(value=[item[0][0,0,1].numpy()])),\n",
    "            \"housingMedianAge\": Feature(float_list=FloatList(value=[item[0][0,0,2].numpy()])),\n",
    "            \"totalRooms\": Feature(float_list=FloatList(value=[item[0][0,0,3].numpy()])),\n",
    "            \"totalBedrooms\": Feature(float_list=FloatList(value=[item[0][0,0,4].numpy()])),\n",
    "            \"population\": Feature(float_list=FloatList(value=[item[0][0,0,5].numpy()])),\n",
    "            \"households\": Feature(float_list=FloatList(value=[item[0][0,0,6].numpy()])),\n",
    "            \"medianIncome\": Feature(float_list=FloatList(value=[item[0][0,0,7].numpy()])),\n",
    "            \"medianHouseValue\": Feature(float_list=FloatList(value=[item[1][0].numpy()]))\n",
    "        }))\n",
    "\n",
    "calihouse_example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Now we write it out to a file as a `TFRecord`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.io.TFRecordWriter(\"calihousie.tfrecord\") as f:\n",
    "    f.write(calihouse_example.SerializeToString())\n",
    "    f.write(calihouse_example.SerializeToString())    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! head calihousie.tfrecord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.TFRecordDataset([\"calihousie.tfrecord\"])\n",
    "for item in dataset.take(2):\n",
    "    print(item)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example = Example()\n",
    "for i,item in enumerate(dataset.take(2)):\n",
    "    print(i)\n",
    "    example.ParseFromString(item.numpy())\n",
    "    print(example)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_description = {\n",
    "            \"longitude\": tf.io.FixedLenFeature([], tf.float32, default_value=0),\n",
    "            \"latitude\": tf.io.FixedLenFeature([], tf.float32, default_value=0),\n",
    "            \"housingMedianAge\": tf.io.FixedLenFeature([], tf.float32, default_value=0),\n",
    "            \"totalRooms\": tf.io.FixedLenFeature([], tf.float32, default_value=0),\n",
    "            \"totalBedrooms\": tf.io.FixedLenFeature([], tf.float32, default_value=0),\n",
    "            \"population\": tf.io.FixedLenFeature([], tf.float32, default_value=0),\n",
    "            \"households\": tf.io.FixedLenFeature([], tf.float32, default_value=0),\n",
    "            \"medianIncome\": tf.io.FixedLenFeature([], tf.float32, default_value=0),\n",
    "            \"medianHouseValue\": tf.io.VarLenFeature(tf.float32)\n",
    "}\n",
    "# https://stackoverflow.com/questions/41921746/tensorflow-varlenfeature-vs-fixedlenfeature\n",
    "\n",
    "for serialized_example in tf.data.TFRecordDataset([\"calihousie.tfrecord\"]):\n",
    "    parsed_example = tf.io.parse_single_example(serialized_example,\n",
    "                                                feature_description)\n",
    "    \n",
    "parsed_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_example['households']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_example['medianHouseValue']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_example['medianHouseValue'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.sparse.to_dense(parsed_example[\"medianHouseValue\"], default_value=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Some data will be variable, and not just like different sized images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here is how batching is done:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for serialized_examples in tf.data.TFRecordDataset([\"calihousie.tfrecord\"]).batch(2):\n",
    "    parsed_examples = tf.io.parse_example(serialized_examples,\n",
    "                                          feature_description)\n",
    "parsed_examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data storage for images:\n",
    "- `Feature(bytes_list=BytesList(value=tf.io.encode_jpeg()))`?\n",
    "    - `tf.io.decode_jpeg()`\n",
    "    - `tf.io.decode_image()`\n",
    "\n",
    "### Data storage for sequences; i.e., \"lists of lists\" stuff:\n",
    "- `SequenceExample`\n",
    "    - `tf.io.parse_single_sequence_example()`\n",
    "    - `tf.io.parse_sequence_example()`\n",
    "    - `tf.RaggedTensor.from_sparse()`\n",
    "\n",
    "*Some code lifted from the notebook provided with the chapter:*\n",
    "```\n",
    "parsed_context, parsed_feature_lists = tf.io.parse_single_sequence_example(serialized_sequence_example,\n",
    "                                                                           context_feature_descriptions,\n",
    "                                                                           sequence_feature_descriptions)\n",
    "parsed_content = tf.RaggedTensor.from_sparse(parsed_feature_lists[\"content\"])\n",
    "```\n",
    "\n",
    "### And you can store tensors themselves\n",
    "\n",
    "- `Feature(bytes_list=BytesList(value=tf.io.serialize_tensor()))`?\n",
    "    - `tf.io.parse_tensor()` \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Places where you can get some data\n",
    "https://learning.oreilly.com/library/view/Hands-On+Machine+Learning+with+Scikit-Learn,+Keras,+and+TensorFlow,+2nd+Edition/9781492032632/ch02.html#project_chapter\n",
    "\n",
    "\n",
    "[TFDS](https://homl.info/tfds)\n",
    "\n",
    "[UC Irvine Machine Learning Repository](http://archive.ics.uci.edu/ml/)\n",
    "\n",
    "[Kaggle datasets](https://www.kaggle.com/datasets)\n",
    "\n",
    "[Amazonâ€™s AWS datasets](https://registry.opendata.aws/)\n",
    "\n",
    "\n",
    "[Data Portals](http://dataportals.org/)\n",
    "\n",
    "[OpenDataMonitor](http://opendatamonitor.eu/)\n",
    "\n",
    "[Quandl](http://quandl.com/)\n",
    "\n",
    "[Wikipediaâ€™s list of Machine Learning datasets](https://homl.info/9)\n",
    "\n",
    "[Quora.com](https://homl.info/10)\n",
    "\n",
    "[The datasets subreddit](https://www.reddit.com/r/datasets)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: failed with initial frozen solve. Retrying with flexible solve.\n",
      "Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source.\n",
      "Collecting package metadata (repodata.json): done\n",
      "Solving environment: failed with initial frozen solve. Retrying with flexible solve.\n",
      "Solving environment: - \n",
      "Found conflicts! Looking for incompatible packages.\n",
      "This can take several minutes.  Press CTRL-C to abort.\n",
      "                                                                               failed\n",
      "\n",
      "UnsatisfiableError: The following specifications were found to be incompatible with each other:\n",
      "\n",
      "Output in format: Requested package -> Available versions\n",
      "\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "# https://anaconda.org/anaconda/tensorflow-datasets\n",
    "! yes y | conda install -c anaconda tensorflow-datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow-datasets\n",
      "  Downloading tensorflow_datasets-4.1.0-py3-none-any.whl (3.6 MB)\n",
      "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3.6 MB 503 kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: attrs>=18.1.0 in /Users/gck8gd/opt/anaconda3/envs/deep_learning_6018/lib/python3.8/site-packages (from tensorflow-datasets) (20.2.0)\n",
      "Collecting promise\n",
      "  Downloading promise-2.3.tar.gz (19 kB)\n",
      "Requirement already satisfied: numpy in /Users/gck8gd/opt/anaconda3/envs/deep_learning_6018/lib/python3.8/site-packages (from tensorflow-datasets) (1.18.5)\n",
      "Requirement already satisfied: termcolor in /Users/gck8gd/opt/anaconda3/envs/deep_learning_6018/lib/python3.8/site-packages (from tensorflow-datasets) (1.1.0)\n",
      "Requirement already satisfied: absl-py in /Users/gck8gd/opt/anaconda3/envs/deep_learning_6018/lib/python3.8/site-packages (from tensorflow-datasets) (0.10.0)\n",
      "Collecting tqdm\n",
      "  Downloading tqdm-4.51.0-py2.py3-none-any.whl (70 kB)\n",
      "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 70 kB 671 kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: protobuf>=3.6.1 in /Users/gck8gd/opt/anaconda3/envs/deep_learning_6018/lib/python3.8/site-packages (from tensorflow-datasets) (3.13.0)\n",
      "Collecting future\n",
      "  Downloading future-0.18.2.tar.gz (829 kB)\n",
      "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 829 kB 634 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting dill\n",
      "  Downloading dill-0.3.3-py2.py3-none-any.whl (81 kB)\n",
      "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 81 kB 667 kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: requests>=2.19.0 in /Users/gck8gd/opt/anaconda3/envs/deep_learning_6018/lib/python3.8/site-packages (from tensorflow-datasets) (2.24.0)\n",
      "Collecting tensorflow-metadata\n",
      "  Downloading tensorflow_metadata-0.25.0-py3-none-any.whl (44 kB)\n",
      "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 44 kB 735 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting importlib-resources; python_version < \"3.9\"\n",
      "  Downloading importlib_resources-3.3.0-py2.py3-none-any.whl (26 kB)\n",
      "Requirement already satisfied: six in /Users/gck8gd/opt/anaconda3/envs/deep_learning_6018/lib/python3.8/site-packages (from tensorflow-datasets) (1.15.0)\n",
      "Requirement already satisfied: setuptools in /Users/gck8gd/opt/anaconda3/envs/deep_learning_6018/lib/python3.8/site-packages (from protobuf>=3.6.1->tensorflow-datasets) (49.6.0.post20200925)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /Users/gck8gd/opt/anaconda3/envs/deep_learning_6018/lib/python3.8/site-packages (from requests>=2.19.0->tensorflow-datasets) (1.25.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /Users/gck8gd/opt/anaconda3/envs/deep_learning_6018/lib/python3.8/site-packages (from requests>=2.19.0->tensorflow-datasets) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /Users/gck8gd/opt/anaconda3/envs/deep_learning_6018/lib/python3.8/site-packages (from requests>=2.19.0->tensorflow-datasets) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/gck8gd/opt/anaconda3/envs/deep_learning_6018/lib/python3.8/site-packages (from requests>=2.19.0->tensorflow-datasets) (2020.6.20)\n",
      "Collecting googleapis-common-protos<2,>=1.52.0\n",
      "  Downloading googleapis_common_protos-1.52.0-py2.py3-none-any.whl (100 kB)\n",
      "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100 kB 674 kB/s ta 0:00:01\n",
      "\u001b[?25hBuilding wheels for collected packages: promise, future\n",
      "  Building wheel for promise (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for promise: filename=promise-2.3-py3-none-any.whl size=21494 sha256=16e450f0a7fda57ac402ea2ae3b5b07286d8567d30b6c7df01b0432579fdba59\n",
      "  Stored in directory: /Users/gck8gd/Library/Caches/pip/wheels/54/aa/01/724885182f93150035a2a91bce34a12877e8067a97baaf5dc8\n",
      "  Building wheel for future (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for future: filename=future-0.18.2-py3-none-any.whl size=491059 sha256=d5fa90510e04a58d8d8f7c6091ac9df93c90c4bef3766386292f801c97418089\n",
      "  Stored in directory: /Users/gck8gd/Library/Caches/pip/wheels/8e/70/28/3d6ccd6e315f65f245da085482a2e1c7d14b90b30f239e2cf4\n",
      "Successfully built promise future\n",
      "Installing collected packages: promise, tqdm, future, dill, googleapis-common-protos, tensorflow-metadata, importlib-resources, tensorflow-datasets\n",
      "Successfully installed dill-0.3.3 future-0.18.2 googleapis-common-protos-1.52.0 importlib-resources-3.3.0 promise-2.3 tensorflow-datasets-4.1.0 tensorflow-metadata-0.25.0 tqdm-4.51.0\n"
     ]
    }
   ],
   "source": [
    "# https://www.tensorflow.org/datasets/overview\n",
    "! pip install tensorflow-datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 4.8.5\n",
      "  latest version: 4.9.2\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base -c defaults conda\n",
      "\n",
      "\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /Users/gck8gd/opt/anaconda3/envs/deep_learning_6018\n",
      "\n",
      "  added / updated specs:\n",
      "    - ipywidgets\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    ca-certificates-2020.11.8  |       h033912b_0         145 KB  conda-forge\n",
      "    certifi-2020.11.8          |   py38h50d1736_0         150 KB  conda-forge\n",
      "    ipywidgets-7.5.1           |     pyh9f0ad1d_1         101 KB  conda-forge\n",
      "    openssl-1.1.1h             |       haf1e3a3_0         1.9 MB  conda-forge\n",
      "    widgetsnbextension-3.5.1   |   py38h32f6830_4         1.8 MB  conda-forge\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:         4.1 MB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  ipywidgets         conda-forge/noarch::ipywidgets-7.5.1-pyh9f0ad1d_1\n",
      "  widgetsnbextension conda-forge/osx-64::widgetsnbextension-3.5.1-py38h32f6830_4\n",
      "\n",
      "The following packages will be UPDATED:\n",
      "\n",
      "  ca-certificates    pkgs/main::ca-certificates-2020.10.14~ --> conda-forge::ca-certificates-2020.11.8-h033912b_0\n",
      "  certifi            pkgs/main/noarch::certifi-2020.6.20-p~ --> conda-forge/osx-64::certifi-2020.11.8-py38h50d1736_0\n",
      "\n",
      "The following packages will be SUPERSEDED by a higher-priority channel:\n",
      "\n",
      "  openssl                                         pkgs/main --> conda-forge\n",
      "\n",
      "\n",
      "Proceed ([y]/n)? \n",
      "\n",
      "Downloading and Extracting Packages\n",
      "openssl-1.1.1h       | 1.9 MB    | ##################################### | 100% \n",
      "widgetsnbextension-3 | 1.8 MB    | ##################################### | 100% \n",
      "certifi-2020.11.8    | 150 KB    | ##################################### | 100% \n",
      "ca-certificates-2020 | 145 KB    | ##################################### | 100% \n",
      "ipywidgets-7.5.1     | 101 KB    | ##################################### | 100% \n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: - Enabling notebook extension jupyter-js-widgets/extension...\n",
      "      - Validating: \u001b[32mOK\u001b[0m\n",
      "\n",
      "done\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "# https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
    "! yes y | conda install -c conda-forge ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enabling notebook extension jupyter-js-widgets/extension...\r\n",
      "      - Validating: \u001b[32mOK\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "# https://stackoverflow.com/questions/57343134/jupyter-notebooks-not-displaying-progress-bars\n",
    "# ` brew install node`\n",
    "! jupyter nbextension enable --py widgetsnbextension\n",
    "# did not have to complete this:\n",
    "#! yes y | jupyter labextension install @jupyter-widgets/jupyterlab-manager\n",
    "# but note that I did need to follow this direction:\n",
    "# 'It should work now after refreshing the Jupyter browser tab.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['train', 'validation'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "# ! rm -r /Users/gck8gd/tensorflow_datasets/bool_q\n",
    "dataset = tfds.load(name=\"bool_q\", shuffle_files=True)#, batch_size=32, as_supervised=True)\n",
    "dataset.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "as_supervised=True but bool_q does not support a supervised (input, label) structure.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-98deef1903d3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# mnist_train = mnist_train.shuffle(10000).batch(32).prefetch(1).map(lambda items: (items[\"image\"], items[\"label\"]))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtfds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"bool_q\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle_files\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_supervised\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/envs/deep_learning_6018/lib/python3.8/site-packages/tensorflow_datasets/core/load.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(name, split, data_dir, batch_size, shuffle_files, download, as_supervised, decoders, read_config, with_info, builder_kwargs, download_and_prepare_kwargs, as_dataset_kwargs, try_gcs)\u001b[0m\n\u001b[1;32m    354\u001b[0m   \u001b[0mas_dataset_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"read_config\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mread_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 356\u001b[0;31m   \u001b[0mds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mas_dataset_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    357\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mwith_info\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/deep_learning_6018/lib/python3.8/site-packages/tensorflow_datasets/core/dataset_builder.py\u001b[0m in \u001b[0;36mas_dataset\u001b[0;34m(self, split, batch_size, shuffle_files, decoders, read_config, as_supervised)\u001b[0m\n\u001b[1;32m    550\u001b[0m         \u001b[0mas_supervised\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_supervised\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m     )\n\u001b[0;32m--> 552\u001b[0;31m     \u001b[0mdatasets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_nested\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuild_single_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_tuple\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    553\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/deep_learning_6018/lib/python3.8/site-packages/tensorflow_datasets/core/utils/py_utils.py\u001b[0m in \u001b[0;36mmap_nested\u001b[0;34m(function, data_struct, dict_only, map_tuple)\u001b[0m\n\u001b[1;32m    165\u001b[0m   \u001b[0;31m# Could add support for more exotic data_struct, like OrderedDict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_struct\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 167\u001b[0;31m     return {\n\u001b[0m\u001b[1;32m    168\u001b[0m         \u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmap_nested\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict_only\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_tuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_struct\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/deep_learning_6018/lib/python3.8/site-packages/tensorflow_datasets/core/utils/py_utils.py\u001b[0m in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    166\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_struct\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m     return {\n\u001b[0;32m--> 168\u001b[0;31m         \u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmap_nested\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict_only\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_tuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    169\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_struct\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m     }\n",
      "\u001b[0;32m~/opt/anaconda3/envs/deep_learning_6018/lib/python3.8/site-packages/tensorflow_datasets/core/utils/py_utils.py\u001b[0m in \u001b[0;36mmap_nested\u001b[0;34m(function, data_struct, dict_only, map_tuple)\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m   \u001b[0;31m# Singleton\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 183\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_struct\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/deep_learning_6018/lib/python3.8/site-packages/tensorflow_datasets/core/dataset_builder.py\u001b[0m in \u001b[0;36m_build_single_dataset\u001b[0;34m(self, split, shuffle_files, batch_size, decoders, read_config, as_supervised)\u001b[0m\n\u001b[1;32m    589\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mas_supervised\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msupervised_keys\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 591\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m    592\u001b[0m             \u001b[0;34m\"as_supervised=True but %s does not support a supervised \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m             \"(input, label) structure.\" % self.name)\n",
      "\u001b[0;31mValueError\u001b[0m: as_supervised=True but bool_q does not support a supervised (input, label) structure."
     ]
    }
   ],
   "source": [
    "dataset = tfds.load(name=\"bool_q\", shuffle_files=True, batch_size=32, as_supervised=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'answer': <tf.Tensor: shape=(), dtype=bool, numpy=False>,\n",
       " 'passage': <tf.Tensor: shape=(), dtype=string, numpy=b\"Sony has licensed Digital8 technology to at least one other firm (Hitachi), which marketed a few models for a while; but as of October 2005 only Sony sells Digital8 consumer equipment. Digital8's main rival is the consumer MiniDV format, which uses narrower tape and a correspondingly smaller cassette shell. Since both technologies share the same logical audio/video format, Digital8 can theoretically equal MiniDV or even DVCAM in A/V performance. But as of 2005, Digital8 has been relegated to the entry-level camcorder market, where price, not performance, is the driving factor. Meanwhile, MiniDV is the de facto standard of the domestic digital tape camcorder market.\">,\n",
       " 'question': <tf.Tensor: shape=(), dtype=string, numpy=b'are mini dv tapes the same as 8mm'>,\n",
       " 'title': <tf.Tensor: shape=(), dtype=string, numpy=b'8 mm video format'>}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(dataset['validation'].take(1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['answer', 'passage', 'question', 'title'])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(dataset['validation'].take(1))).keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=string, numpy=b'Death from laughter is a rare form of death, usually resulting from cardiac arrest or asphyxiation, caused by a fit of laughter. Instances of death by laughter have been recorded from the times of ancient Greece to the modern day.'>"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(dataset['validation'].take(1)))['passage']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.tensorflow.org/api_docs/python/tf/keras/layers/experimental/preprocessing/TextVectorization\n",
    "#https://towardsdatascience.com/you-should-try-the-new-tensorflows-textvectorization-layer-a80b3c6b00ee \n",
    "tf.keras.layers.experimental.preprocessing.TextVectorization?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "TextVectorization = tf.keras.layers.experimental.preprocessing.TextVectorization\n",
    "\n",
    "vectorize_layer = TextVectorization(\n",
    "    max_tokens=500,\n",
    "    standardize='lower_and_strip_punctuation',\n",
    "    split='whitespace',\n",
    "    output_mode='int')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3270"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://stackoverflow.com/questions/50737192/tf-data-dataset-how-to-get-the-dataset-size-number-of-elements-in-a-epoch\n",
    "tf.data.experimental.cardinality(dataset['validation']).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorize_layer.adapt?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorize_layer.adapt(dataset['validation'].map(lambda items: items['passage']).batch(64), reset_state=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['_TF_MODULE_IGNORED_PROPERTIES',\n",
       " '__call__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getstate__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__metaclass__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__setstate__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_activity_regularizer',\n",
       " '_add_state_variable',\n",
       " '_add_trackable',\n",
       " '_add_variable_with_custom_getter',\n",
       " '_assert_same_type',\n",
       " '_auto_track_sub_layers',\n",
       " '_autocast',\n",
       " '_autographed_call',\n",
       " '_build_input_shape',\n",
       " '_call_accepts_kwargs',\n",
       " '_call_arg_was_passed',\n",
       " '_call_fn_arg_defaults',\n",
       " '_call_fn_arg_positions',\n",
       " '_call_fn_args',\n",
       " '_call_full_argspec',\n",
       " '_callable_losses',\n",
       " '_called',\n",
       " '_cast_single_input',\n",
       " '_checkpoint_dependencies',\n",
       " '_clear_losses',\n",
       " '_combiner',\n",
       " '_compute_dtype',\n",
       " '_compute_dtype_object',\n",
       " '_convert_to_ndarray',\n",
       " '_dedup_weights',\n",
       " '_default_training_arg',\n",
       " '_deferred_dependencies',\n",
       " '_dtype',\n",
       " '_dtype_defaulted_to_floatx',\n",
       " '_dtype_policy',\n",
       " '_dynamic',\n",
       " '_eager_losses',\n",
       " '_expects_mask_arg',\n",
       " '_expects_training_arg',\n",
       " '_flatten',\n",
       " '_flatten_layers',\n",
       " '_functional_construction_call',\n",
       " '_gather_children_attribute',\n",
       " '_gather_saveables_for_checkpoint',\n",
       " '_get_call_arg_value',\n",
       " '_get_dataset_iterator',\n",
       " '_get_existing_metric',\n",
       " '_get_index_lookup_class',\n",
       " '_get_input_masks',\n",
       " '_get_node_attribute_at_index',\n",
       " '_get_save_spec',\n",
       " '_get_trainable_state',\n",
       " '_get_vectorization_class',\n",
       " '_handle_activity_regularization',\n",
       " '_handle_deferred_dependencies',\n",
       " '_handle_weight_regularization',\n",
       " '_inbound_nodes',\n",
       " '_index_lookup_layer',\n",
       " '_infer_output_signature',\n",
       " '_init_call_fn_args',\n",
       " '_init_set_name',\n",
       " '_initial_weights',\n",
       " '_input_spec',\n",
       " '_is_layer',\n",
       " '_keras_api_names',\n",
       " '_keras_api_names_v1',\n",
       " '_keras_tensor_symbolic_call',\n",
       " '_layers',\n",
       " '_list_extra_dependencies_for_serialization',\n",
       " '_list_functions_for_serialization',\n",
       " '_lookup_dependency',\n",
       " '_losses',\n",
       " '_map_resources',\n",
       " '_max_tokens',\n",
       " '_maybe_build',\n",
       " '_maybe_cast_inputs',\n",
       " '_maybe_create_attribute',\n",
       " '_maybe_initialize_trackable',\n",
       " '_metrics',\n",
       " '_metrics_lock',\n",
       " '_must_restore_from_config',\n",
       " '_name',\n",
       " '_name_based_attribute_restore',\n",
       " '_name_based_restores',\n",
       " '_name_scope',\n",
       " '_ngrams',\n",
       " '_ngrams_arg',\n",
       " '_no_dependency',\n",
       " '_non_trainable_weights',\n",
       " '_obj_reference_counts',\n",
       " '_obj_reference_counts_dict',\n",
       " '_object_identifier',\n",
       " '_oov_value',\n",
       " '_outbound_nodes',\n",
       " '_output_mode',\n",
       " '_output_sequence_length',\n",
       " '_pad_to_max',\n",
       " '_preload_simple_restoration',\n",
       " '_preprocess',\n",
       " '_previously_updated',\n",
       " '_restore_from_checkpoint_position',\n",
       " '_restore_updates',\n",
       " '_saved_model_inputs_spec',\n",
       " '_self_name_based_restores',\n",
       " '_self_saveable_object_factories',\n",
       " '_self_setattr_tracking',\n",
       " '_self_unconditional_checkpoint_dependencies',\n",
       " '_self_unconditional_deferred_dependencies',\n",
       " '_self_unconditional_dependency_names',\n",
       " '_self_update_uid',\n",
       " '_set_call_arg_value',\n",
       " '_set_connectivity_metadata',\n",
       " '_set_dtype_policy',\n",
       " '_set_mask_keras_history_checked',\n",
       " '_set_mask_metadata',\n",
       " '_set_save_spec',\n",
       " '_set_state_variables',\n",
       " '_set_trainable_state',\n",
       " '_set_training_mode',\n",
       " '_setattr_tracking',\n",
       " '_should_cast_single_input',\n",
       " '_single_restoration_from_checkpoint_position',\n",
       " '_split',\n",
       " '_split_out_first_arg',\n",
       " '_standardize',\n",
       " '_stateful',\n",
       " '_supports_masking',\n",
       " '_symbolic_call',\n",
       " '_tf_api_names',\n",
       " '_tf_api_names_v1',\n",
       " '_thread_local',\n",
       " '_track_trackable',\n",
       " '_trackable_saved_model_saver',\n",
       " '_tracking_metadata',\n",
       " '_trainable',\n",
       " '_trainable_weights',\n",
       " '_unconditional_checkpoint_dependencies',\n",
       " '_unconditional_dependency_names',\n",
       " '_update_uid',\n",
       " '_updates',\n",
       " '_vectorize_layer',\n",
       " '_vocab_size',\n",
       " '_warn_about_input_casting',\n",
       " 'activity_regularizer',\n",
       " 'adapt',\n",
       " 'add_loss',\n",
       " 'add_metric',\n",
       " 'add_update',\n",
       " 'add_variable',\n",
       " 'add_weight',\n",
       " 'apply',\n",
       " 'build',\n",
       " 'built',\n",
       " 'call',\n",
       " 'compute_mask',\n",
       " 'compute_output_shape',\n",
       " 'compute_output_signature',\n",
       " 'count_params',\n",
       " 'dtype',\n",
       " 'dynamic',\n",
       " 'from_config',\n",
       " 'get_config',\n",
       " 'get_input_at',\n",
       " 'get_input_mask_at',\n",
       " 'get_input_shape_at',\n",
       " 'get_losses_for',\n",
       " 'get_output_at',\n",
       " 'get_output_mask_at',\n",
       " 'get_output_shape_at',\n",
       " 'get_updates_for',\n",
       " 'get_vocabulary',\n",
       " 'get_weights',\n",
       " 'inbound_nodes',\n",
       " 'input',\n",
       " 'input_mask',\n",
       " 'input_shape',\n",
       " 'input_spec',\n",
       " 'losses',\n",
       " 'metrics',\n",
       " 'name',\n",
       " 'name_scope',\n",
       " 'non_trainable_variables',\n",
       " 'non_trainable_weights',\n",
       " 'outbound_nodes',\n",
       " 'output',\n",
       " 'output_mask',\n",
       " 'output_shape',\n",
       " 'set_vocabulary',\n",
       " 'set_weights',\n",
       " 'state_variables',\n",
       " 'stateful',\n",
       " 'submodules',\n",
       " 'supports_masking',\n",
       " 'trainable',\n",
       " 'trainable_variables',\n",
       " 'trainable_weights',\n",
       " 'updates',\n",
       " 'variables',\n",
       " 'weights',\n",
       " 'with_name_scope']"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(vectorize_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " '[UNK]',\n",
       " 'the',\n",
       " 'of',\n",
       " 'and',\n",
       " 'in',\n",
       " 'a',\n",
       " 'to',\n",
       " 'is',\n",
       " 'as',\n",
       " 'by',\n",
       " 'on',\n",
       " 'for',\n",
       " 'with',\n",
       " 'or',\n",
       " 'was',\n",
       " 'it',\n",
       " 'that',\n",
       " 'are',\n",
       " 'from',\n",
       " 'an',\n",
       " 'be',\n",
       " 'at',\n",
       " 'which',\n",
       " 'not',\n",
       " 'has',\n",
       " 'also',\n",
       " 'have',\n",
       " 'states',\n",
       " 'its',\n",
       " 'their',\n",
       " 'united',\n",
       " 'series',\n",
       " 'this',\n",
       " 'one',\n",
       " 'first',\n",
       " 'they',\n",
       " 'but',\n",
       " 'other',\n",
       " 'film',\n",
       " 'may',\n",
       " 'new',\n",
       " 'two',\n",
       " 'his',\n",
       " 'season',\n",
       " 'after',\n",
       " 'can',\n",
       " 'world',\n",
       " 'he',\n",
       " 'been',\n",
       " 'used',\n",
       " 'all',\n",
       " 'her',\n",
       " 'most',\n",
       " 'who',\n",
       " 'when',\n",
       " 'were',\n",
       " 'only',\n",
       " 'into',\n",
       " 'such',\n",
       " 'american',\n",
       " 'time',\n",
       " 'us',\n",
       " 'than',\n",
       " 'more',\n",
       " 'state',\n",
       " 'known',\n",
       " 'some',\n",
       " 'between',\n",
       " 'if',\n",
       " 'she',\n",
       " '2018',\n",
       " 'while',\n",
       " 'had',\n",
       " '2017',\n",
       " 'there',\n",
       " 'no',\n",
       " 'since',\n",
       " 'however',\n",
       " 'being',\n",
       " 'game',\n",
       " 'years',\n",
       " 'during',\n",
       " 'cup',\n",
       " 'any',\n",
       " 'over',\n",
       " 'both',\n",
       " 'same',\n",
       " 'many',\n",
       " 'three',\n",
       " 'under',\n",
       " 'second',\n",
       " 'called',\n",
       " 'about',\n",
       " 'will',\n",
       " 'law',\n",
       " 'where',\n",
       " 'team',\n",
       " 'through',\n",
       " 'up',\n",
       " 'including',\n",
       " 'games',\n",
       " 'would',\n",
       " 'each',\n",
       " 'city',\n",
       " 'use',\n",
       " 'these',\n",
       " 'often',\n",
       " 'national',\n",
       " 'number',\n",
       " 'name',\n",
       " 'before',\n",
       " 'made',\n",
       " 'system',\n",
       " 'released',\n",
       " 'part',\n",
       " 'well',\n",
       " 'until',\n",
       " 'third',\n",
       " 'then',\n",
       " 'four',\n",
       " 'north',\n",
       " 'area',\n",
       " 'based',\n",
       " 'later',\n",
       " 'although',\n",
       " 'out',\n",
       " '2015',\n",
       " 'set',\n",
       " 'usually',\n",
       " 'south',\n",
       " 'water',\n",
       " 'television',\n",
       " 'because',\n",
       " 'within',\n",
       " '2',\n",
       " 'family',\n",
       " 'group',\n",
       " 'york',\n",
       " 'him',\n",
       " '10',\n",
       " 'company',\n",
       " 'them',\n",
       " '2016',\n",
       " 'show',\n",
       " 'year',\n",
       " 'does',\n",
       " '1',\n",
       " 'federal',\n",
       " 'due',\n",
       " 'war',\n",
       " 'player',\n",
       " 'must',\n",
       " 'last',\n",
       " 'day',\n",
       " 'high',\n",
       " 'common',\n",
       " 'written',\n",
       " 'won',\n",
       " 'june',\n",
       " 'people',\n",
       " 'original',\n",
       " 'end',\n",
       " 'ball',\n",
       " 'final',\n",
       " 'following',\n",
       " 'different',\n",
       " 'canada',\n",
       " '2014',\n",
       " 'league',\n",
       " 'found',\n",
       " 'sometimes',\n",
       " 'september',\n",
       " 'april',\n",
       " 'major',\n",
       " 'home',\n",
       " 'several',\n",
       " 'red',\n",
       " 'five',\n",
       " 'countries',\n",
       " 'around',\n",
       " 'those',\n",
       " 'public',\n",
       " 'include',\n",
       " 'place',\n",
       " 'march',\n",
       " 'xbox',\n",
       " 'body',\n",
       " 'so',\n",
       " 'fifa',\n",
       " 'october',\n",
       " 'do',\n",
       " 'best',\n",
       " 'played',\n",
       " 'form',\n",
       " 'million',\n",
       " 'right',\n",
       " 'commonly',\n",
       " 'america',\n",
       " 'air',\n",
       " 'produced',\n",
       " 'government',\n",
       " 'british',\n",
       " 'act',\n",
       " 'premiered',\n",
       " 'football',\n",
       " 'even',\n",
       " 'directed',\n",
       " 'became',\n",
       " '3',\n",
       " 'large',\n",
       " 'island',\n",
       " 'episodes',\n",
       " 'book',\n",
       " 'announced',\n",
       " 'age',\n",
       " 'still',\n",
       " 'players',\n",
       " 'kingdom',\n",
       " '2010',\n",
       " 'service',\n",
       " 'i',\n",
       " 'white',\n",
       " 'typically',\n",
       " 'located',\n",
       " 'july',\n",
       " '4',\n",
       " 'times',\n",
       " 'films',\n",
       " 'referred',\n",
       " 'own',\n",
       " 'another',\n",
       " 'small',\n",
       " 'english',\n",
       " 'without',\n",
       " 'though',\n",
       " 'species',\n",
       " 'person',\n",
       " 'like',\n",
       " 'life',\n",
       " 'story',\n",
       " 'main',\n",
       " 'largest',\n",
       " 'having',\n",
       " 'term',\n",
       " 'song',\n",
       " 'member',\n",
       " 'either',\n",
       " 'similar',\n",
       " 'per',\n",
       " 'legal',\n",
       " 'house',\n",
       " 'created',\n",
       " 'against',\n",
       " 'six',\n",
       " 'park',\n",
       " 'california',\n",
       " '2013',\n",
       " 'school',\n",
       " 'novel',\n",
       " 'light',\n",
       " 'january',\n",
       " 'court',\n",
       " 'members',\n",
       " 'long',\n",
       " '2011',\n",
       " '15',\n",
       " 'generally',\n",
       " 'total',\n",
       " 'black',\n",
       " 'back',\n",
       " 'central',\n",
       " 'along',\n",
       " 'teams',\n",
       " 'single',\n",
       " 'power',\n",
       " 'days',\n",
       " 'international',\n",
       " 'fourth',\n",
       " 'range',\n",
       " 'order',\n",
       " 'months',\n",
       " 'february',\n",
       " 'production',\n",
       " 'off',\n",
       " 'left',\n",
       " 'laws',\n",
       " 'example',\n",
       " 'began',\n",
       " '21',\n",
       " '12',\n",
       " 'west',\n",
       " 'result',\n",
       " 'renewed',\n",
       " 'period',\n",
       " 'now',\n",
       " 'force',\n",
       " 'considered',\n",
       " '8',\n",
       " 'university',\n",
       " 'november',\n",
       " 'make',\n",
       " 'm',\n",
       " '11',\n",
       " 'required',\n",
       " 'president',\n",
       " 'character',\n",
       " '18',\n",
       " 'using',\n",
       " 'published',\n",
       " 'play',\n",
       " 'line',\n",
       " 'august',\n",
       " 'received',\n",
       " 'less',\n",
       " 'early',\n",
       " 'december',\n",
       " 'carry',\n",
       " 'base',\n",
       " 'drama',\n",
       " '30',\n",
       " '2012',\n",
       " 'stars',\n",
       " 'european',\n",
       " 'title',\n",
       " 'sequel',\n",
       " 'death',\n",
       " '5',\n",
       " 'local',\n",
       " 'least',\n",
       " 'much',\n",
       " 'constitution',\n",
       " 'card',\n",
       " 'very',\n",
       " 'bank',\n",
       " 'km',\n",
       " 'episode',\n",
       " 'did',\n",
       " 'again',\n",
       " 'size',\n",
       " 'just',\n",
       " 'few',\n",
       " 'oil',\n",
       " 'named',\n",
       " 'islands',\n",
       " 'east',\n",
       " 'current',\n",
       " 'top',\n",
       " 'thus',\n",
       " 'once',\n",
       " 'official',\n",
       " 'human',\n",
       " 'england',\n",
       " 'down',\n",
       " 'country',\n",
       " 'australia',\n",
       " 'standard',\n",
       " 'special',\n",
       " 'free',\n",
       " 'century',\n",
       " 'available',\n",
       " '6',\n",
       " '20',\n",
       " 'western',\n",
       " 'see',\n",
       " 'seasons',\n",
       " 'relationship',\n",
       " 'history',\n",
       " 'version',\n",
       " 'return',\n",
       " 'originally',\n",
       " 'go',\n",
       " 'become',\n",
       " '16',\n",
       " 'together',\n",
       " 'association',\n",
       " 'win',\n",
       " 'sold',\n",
       " 'separate',\n",
       " 'point',\n",
       " 'never',\n",
       " 'king',\n",
       " 'case',\n",
       " 'video',\n",
       " 'sea',\n",
       " 'list',\n",
       " '2008',\n",
       " 'seven',\n",
       " 'run',\n",
       " 'record',\n",
       " 'field',\n",
       " 'eight',\n",
       " 'dead',\n",
       " 'san',\n",
       " 'rights',\n",
       " 'making',\n",
       " 'europe',\n",
       " 'de',\n",
       " 'among',\n",
       " 'developed',\n",
       " '50',\n",
       " '2006',\n",
       " 'type',\n",
       " 'studios',\n",
       " 'real',\n",
       " 'how',\n",
       " 'fifth',\n",
       " 'blue',\n",
       " 'various',\n",
       " 'rules',\n",
       " 'open',\n",
       " 'held',\n",
       " 'currently',\n",
       " 'could',\n",
       " '7',\n",
       " '2009',\n",
       " 'union',\n",
       " 'texas',\n",
       " 'southern',\n",
       " 'parts',\n",
       " 'northern',\n",
       " 'live',\n",
       " 'lead',\n",
       " 'hand',\n",
       " 'former',\n",
       " 'areas',\n",
       " 'work',\n",
       " 'said',\n",
       " 'ireland',\n",
       " 'includes',\n",
       " 'great',\n",
       " 'franchise',\n",
       " 'every',\n",
       " 'center',\n",
       " 'side',\n",
       " 'population',\n",
       " 'military',\n",
       " 'john',\n",
       " 'events',\n",
       " 'development',\n",
       " '24',\n",
       " 'others',\n",
       " 'music',\n",
       " 'love',\n",
       " 'london',\n",
       " 'level',\n",
       " 'given',\n",
       " 'food',\n",
       " 'except',\n",
       " 'division',\n",
       " 'speed',\n",
       " 'republic',\n",
       " 'degree',\n",
       " 'color',\n",
       " 'building',\n",
       " 'below',\n",
       " 'approximately',\n",
       " 'vehicle',\n",
       " 'low',\n",
       " 'control',\n",
       " 'cannot',\n",
       " '13',\n",
       " 'uses',\n",
       " 'uk',\n",
       " 'role',\n",
       " 'names',\n",
       " 'mexico',\n",
       " 'get',\n",
       " 'finals',\n",
       " 'aired',\n",
       " 'throughout',\n",
       " 'language',\n",
       " 'goal',\n",
       " 'general',\n",
       " 'feet',\n",
       " 'chain',\n",
       " 'river',\n",
       " 'refers',\n",
       " 'officially',\n",
       " 'network',\n",
       " 'mother',\n",
       " 'michael',\n",
       " 'license',\n",
       " 'led',\n",
       " 'head',\n",
       " 'green',\n",
       " 'energy',\n",
       " 'winning',\n",
       " 'value',\n",
       " 'street',\n",
       " 'square',\n",
       " 'pressure',\n",
       " 'police',\n",
       " 'lower',\n",
       " 'instead',\n",
       " 'france',\n",
       " 'depending',\n",
       " 'county',\n",
       " 'certain',\n",
       " 'trophy']"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorize_layer.get_vocabulary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vectorize_layer.get_vocabulary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'Death from laughter is a rare form of death, usually resulting from cardiac arrest or asphyxiation, caused by a fit of laughter. Instances of death by laughter have been recorded from the times of ancient Greece to the modern day.'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(dataset['validation'].map(lambda items: items['passage']).take(1))).numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(40,), dtype=int64, numpy=\n",
       "array([326,  19,   1,   8,   6,   1, 194,   3, 326, 129,   1,  19,   1,\n",
       "         1,  14,   1,   1,  10,   6,   1,   3,   1,   1,   3, 326,  10,\n",
       "         1,  27,  49,   1,  19,   2, 227,   3,   1,   1,   7,   2,   1,\n",
       "       154])>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorize_layer(next(iter(dataset['validation'].map(lambda items: items['passage']).take(1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([b'[UNK]', b'', b'certain', b'county', b'depending', b'france',\n",
       "        b'instead', b'police', b'square', b'street', b'energy', b'green',\n",
       "        b'head', b'led', b'license', b'mother', b'network', b'officially',\n",
       "        b'refers', b'river', b'language', b'throughout', b'aired', b'get',\n",
       "        b'uk', b'13', b'control', b'approximately', b'building', b'color',\n",
       "        b'degree', b'republic', b'speed', b'division', b'except', b'food',\n",
       "        b'level', b'london', b'love', b'john', b'given', b'population',\n",
       "        b'side', b'franchise', b'ireland', b'said', b'great', b'work',\n",
       "        b'hand', b'lead', b'northern', b'southern', b'texas', b'7',\n",
       "        b'could', b'open', b'various', b'blue', b'fifth', b'studios',\n",
       "        b'developed', b'includes', b'11', b'rights', b'trophy',\n",
       "        b'national', b'dead', b'18', b'sea', b'case', b'never', b'point',\n",
       "        b'sold', b'are', b'part', b'association', b'see', b'together',\n",
       "        b'list', b'union', b'order', b'16', b'become', b'will', b'go',\n",
       "        b'relationship', b'history', b'seven', b'20', b'general', b'eight',\n",
       "        b'include', b'6', b'game', b'de', b'available', b'feet', b'free',\n",
       "        b'standard', b'england', b'others', b'both', b'once', b'thus',\n",
       "        b'members', b'version', b'type', b'series', b'current', b'cannot',\n",
       "        b'five', b'directed', b'east', b'following', b'named', b'oil',\n",
       "        b'again', b'over', b'did', b'light', b'or', b'bank', b'card',\n",
       "        b'person', b'constitution', b'million', b'least', b'5', b'sequel',\n",
       "        b'title', b'stars', b'episode', b'2012', b'carry', b'december',\n",
       "        b'rules', b'50', b'early', b'often', b'less', b'when', b'received',\n",
       "        b'seasons', b'currently', b'line', b'august', b'published',\n",
       "        b'their', b'president', b'using', b'would', b'm', b'music',\n",
       "        b'make', b'down', b'november', b'value', b'considered', b'few',\n",
       "        b'2006', b'force', b'novel', b'renewed', b'day', b'result',\n",
       "        b'pressure', b'xbox', b'west', b'long', b'began', b'goal',\n",
       "        b'example', b'much', b'laws', b'no', b'2008', b'drama', b'major',\n",
       "        b'off', b'world', b'later', b'production', b'how', b'months',\n",
       "        b'chain', b'this', b'fourth', b'international', b'days', b'power',\n",
       "        b'single', b'along', b'central', b'size', b'back', b'typically',\n",
       "        b'park', b'total', b'generally', b'15', b'court', b'january',\n",
       "        b'names', b'2011', b'2013', b'left', b'large', b'six', b'against',\n",
       "        b'created', b'house', b'per', b'february', b'member', b'field',\n",
       "        b'country', b'term', b'having', b'many', b'story', b'species',\n",
       "        b'these', b'though', b'english', b'small', b'films', b'every',\n",
       "        b'that', b'times', b'san', b'play', b'i', b'states', b'2010',\n",
       "        b'kingdom', b'white', b'book', b'island', b'3', b'held', b'became',\n",
       "        b'referred', b'even', b'it', b'premiered', b'british', b'its',\n",
       "        b'just', b'produced', b'air', b'usually', b'october', b'making',\n",
       "        b'last', b'fifa', b'still', b'video', b'so', b'body', b'areas',\n",
       "        b'more', b'special', b'due', b'official', b'former', b'largest',\n",
       "        b'place', b'public', b'into', b'since', b'although', b'year',\n",
       "        b'return', b'those', b'red', b'several', b'where', b'king',\n",
       "        b'must', b'do', b'september', b'sometimes', b'events', b'found',\n",
       "        b'located', b'player', b'she', b'league', b'different', b'24',\n",
       "        b'after', b'another', b'ball', b'end', b'original', b'there',\n",
       "        b'team', b'won', b'than', b'best', b'written', b'cup', b'war',\n",
       "        b'km', b'australia', b'local', b'western', b'federal', b'without',\n",
       "        b'season', b'common', b'1', b'been', b'show', b'them', b'company',\n",
       "        b'black', b'players', b'10', b'group', b'america', b'family', b'2',\n",
       "        b'either', b'city', b'within', b'live', b'then', b'water', b'2015',\n",
       "        b'role', b'him', b'based', b'8', b'north', b'song', b'area',\n",
       "        b'other', b'four', b'played', b'home', b'canada', b'parts',\n",
       "        b'third', b'also', b'well', b'released', b'each', b'human',\n",
       "        b'system', b'military', b'before', b'some', b'21', b'below',\n",
       "        b'games', b'own', b'through', b'school', b'2014', b'june', b'uses',\n",
       "        b'2017', b'second', b'right', b'islands', b'episodes', b'may',\n",
       "        b'new', b'does', b'same', b'and', b'european', b'age', b'football',\n",
       "        b'out', b'an', b'during', b'teams', b'being', b'one', b'service',\n",
       "        b'not', b'lower', b'until', b'europe', b'under', b'law', b'period',\n",
       "        b'form', b'center', b'while', b'like', b'television', b'set',\n",
       "        b'2018', b'only', b'three', b'number', b'century', b'time', b'is',\n",
       "        b'between', b'from', b'known', b'if', b'have', b'united', b'among',\n",
       "        b'2009', b'base', b'at', b'the', b'however', b'us', b'use',\n",
       "        b'american', b'range', b'originally', b'in', b'separate', b'who',\n",
       "        b'30', b'of', b'were', b'california', b'commonly', b'april',\n",
       "        b'finals', b'all', b'a', b'used', b'can', b'act', b'he', b'around',\n",
       "        b'final', b'winning', b'12', b'mexico', b'legal', b'her', b'july',\n",
       "        b'made', b'but', b'they', b'record', b'government', b'2016',\n",
       "        b'required', b'first', b'most', b'vehicle', b'4', b'has',\n",
       "        b'university', b'real', b'york', b'main', b'was', b'life',\n",
       "        b'about', b'character', b'low', b'his', b'countries', b'top',\n",
       "        b'similar', b'to', b'south', b'state', b'had', b'michael',\n",
       "        b'because', b'win', b'very', b'be', b'including', b'years',\n",
       "        b'with', b'march', b'which', b'name', b'for', b'two', b'film',\n",
       "        b'any', b'now', b'announced', b'high', b'run', b'called', b'by',\n",
       "        b'as', b'development', b'such', b'death', b'up', b'on', b'people'],\n",
       "       dtype=object),\n",
       " array([  1,   0, 498, 497, 496, 495, 494, 492, 490, 489, 486, 485, 484,\n",
       "        483, 482, 480, 479, 478, 477, 476, 471, 470, 469, 467, 463, 461,\n",
       "        459, 456, 454, 453, 452, 451, 450, 449, 448, 447, 445, 444, 443,\n",
       "        437, 446, 435, 434, 431, 428, 427, 430, 426, 423, 422, 420, 418,\n",
       "        417, 414, 413, 410, 408, 407, 406, 403, 399, 429, 303, 394, 499,\n",
       "        108, 392, 307, 384, 382, 380, 379, 377,  18, 115, 375, 364, 374,\n",
       "        385, 416, 280, 373, 372,  94, 371, 366, 367, 387, 362, 473, 391,\n",
       "        183, 361,  80, 397, 360, 474, 358, 356, 352, 441,  86, 349, 348,\n",
       "        263, 368, 402,  32, 346, 460, 178, 207, 345, 165, 343, 342, 338,\n",
       "         85, 337, 260,  14, 334, 332, 237, 331, 195, 329, 327, 325, 324,\n",
       "        322, 336, 321, 317, 316, 409, 400, 315, 107, 314,  55, 313, 365,\n",
       "        412, 311, 312, 309,  30, 305, 308, 102, 302, 442, 301, 353, 300,\n",
       "        488, 297, 341, 401, 296, 259, 293, 154, 292, 491, 186, 291, 264,\n",
       "        288, 472, 287, 330, 286,  76, 386, 319, 174, 284,  47, 124, 283,\n",
       "        405, 281, 475,  33, 278, 277, 276, 275, 274, 272, 271, 339, 270,\n",
       "        223, 255, 268, 267, 266, 262, 261, 465, 265, 257, 285, 210, 254,\n",
       "        253, 252, 251, 249, 282, 246, 390, 354, 244, 243,  88, 240, 236,\n",
       "        106, 235, 233, 232, 228, 432,  17, 227, 393, 310, 221,  28, 219,\n",
       "        218, 222, 213, 211, 209, 411, 208, 229, 206,  16, 204, 202,  29,\n",
       "        340, 200, 199, 129, 190, 395, 153, 189, 216, 383, 188, 187, 425,\n",
       "         64, 357, 149, 350, 424, 242, 184, 182,  58,  77, 125, 145, 369,\n",
       "        181, 177, 176,  96, 381, 152, 191, 172, 171, 438, 170, 224, 151,\n",
       "         70, 169, 166, 440,  45, 231, 163, 162, 161,  75,  97, 158,  63,\n",
       "        192, 157,  83, 150, 335, 355, 328, 363, 148, 234,  44, 156, 147,\n",
       "         49, 144, 142, 141, 269, 217, 140, 137, 198, 136, 135, 247, 104,\n",
       "        134, 421, 119, 131, 127, 464, 139, 123, 298, 121, 245, 122,  38,\n",
       "        120, 193, 175, 167, 419, 118,  26, 116, 114, 103, 351, 113, 436,\n",
       "        111,  67, 289, 455, 101, 230,  98, 258, 168, 159, 462,  74,  91,\n",
       "        196, 344, 212,  40,  41, 146,  87,   4, 323, 215, 205, 126,  20,\n",
       "         82, 273,  79,  34, 220,  24, 493, 117, 396,  90,  95, 294, 194,\n",
       "        433,  72, 238, 132, 128,  71,  57,  89, 109, 359,  61,   8,  68,\n",
       "         19,  66,  69,  27,  31, 398, 415, 318,  22,   2,  78,  62, 105,\n",
       "         60, 279, 370,   5, 378,  54, 320,   3,  56, 256, 197, 173, 468,\n",
       "         51,   6,  50,  46, 203,  48, 180, 164, 487, 290, 466, 250,  52,\n",
       "        225, 112,  37,  36, 389, 201, 143, 304,  35,  53, 457, 226,  25,\n",
       "        299, 404, 138, 241,  15, 239,  93, 306, 458,  43, 179, 347, 248,\n",
       "          7, 130,  65,  73, 481, 133, 376, 333,  21, 100,  81,  13, 185,\n",
       "         23, 110,  12,  42,  39,  84, 295, 214, 155, 388,  92,  10,   9,\n",
       "        439,  59, 326,  99,  11, 160])]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorize_layer.get_weights()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 20), dtype=int64, numpy=\n",
       "array([[326,  19,   1,   8,   6,   1, 194,   3, 326, 129,   1,  19,   1,\n",
       "          1,  14,   1,   1,  10,   6,   1],\n",
       "       [  2, 177,   1,   8,   2,  57,   1, 236,   3,   2,   1,   1,   4,\n",
       "          2, 136,   1,  16,  25,  49,   1]])>"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorize_layer_info = TextVectorization(\n",
    "    max_tokens=500,\n",
    "    standardize='lower_and_strip_punctuation',\n",
    "    split='whitespace',\n",
    "    output_mode='int',\n",
    "    output_sequence_length=20)#100\n",
    "\n",
    "vectorize_layer_info.adapt(dataset['validation'].map(lambda items: items['passage']).batch(64), reset_state=True)\n",
    "\n",
    "vectorize_layer_info(next(iter(dataset['validation'].map(lambda items: items['passage']).batch(2).take(1))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 50), dtype=float32, numpy=\n",
       "array([[1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 0., 0., 0., 1., 0., 0.,\n",
       "        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        1., 0.],\n",
       "       [1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 0., 0., 1.,\n",
       "        0., 1., 0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 1., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "        1., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorize_layer_info = TextVectorization(\n",
    "    max_tokens=50,\n",
    "    standardize='lower_and_strip_punctuation',\n",
    "    split='whitespace',\n",
    "    output_mode='binary',\n",
    "    pad_to_max_tokens=True)\n",
    "\n",
    "vectorize_layer_info.adapt(dataset['validation'].map(lambda items: items['passage']).batch(64), reset_state=True)\n",
    "\n",
    "vectorize_layer_info(next(iter(dataset['validation'].map(lambda items: items['passage']).batch(2).take(1))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 50), dtype=float32, numpy=\n",
       "array([[22.,  2.,  4.,  0.,  0.,  2.,  1.,  1.,  0.,  2.,  0.,  0.,  0.,\n",
       "         1.,  0.,  0.,  0.,  0.,  3.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.],\n",
       "       [41.,  9.,  3.,  3.,  2.,  1.,  1.,  4.,  0.,  0.,  0.,  1.,  1.,\n",
       "         0.,  0.,  2.,  0.,  1.,  0.,  0.,  0.,  0.,  2.,  1.,  1.,  0.,\n",
       "         0.,  0.,  2.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,\n",
       "         0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorize_layer_info = TextVectorization(\n",
    "    max_tokens=50,\n",
    "    standardize='lower_and_strip_punctuation',\n",
    "    split='whitespace',\n",
    "    output_mode='count',\n",
    "    pad_to_max_tokens=True)\n",
    "\n",
    "vectorize_layer_info.adapt(dataset['validation'].map(lambda items: items['passage']).batch(64), reset_state=True)\n",
    "\n",
    "vectorize_layer_info(next(iter(dataset['validation'].map(lambda items: items['passage']).batch(2).take(1))))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 50), dtype=float32, numpy=\n",
       "array([[15.245874  ,  1.4230618 ,  3.069777  ,  0.        ,  0.        ,\n",
       "         1.6252658 ,  0.8878175 ,  0.88448596,  0.        ,  2.2482414 ,\n",
       "         0.        ,  0.        ,  0.        ,  1.3620235 ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  4.27833   ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  1.8501315 ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  2.1420925 ,  0.        ],\n",
       "       [28.412766  ,  6.403778  ,  2.3023329 ,  2.3154607 ,  1.6088053 ,\n",
       "         0.8126329 ,  0.8878175 ,  3.5379438 ,  0.        ,  0.        ,\n",
       "         0.        ,  1.1812017 ,  1.2147837 ,  0.        ,  0.        ,\n",
       "         2.5331705 ,  0.        ,  1.4357373 ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  3.1437361 ,  1.7497053 ,  1.7425369 ,\n",
       "         0.        ,  0.        ,  0.        ,  3.74801   ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  1.9764019 ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  2.1564243 ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  2.1420925 ,  0.        ]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorize_layer_info = TextVectorization(\n",
    "    max_tokens=50,\n",
    "    standardize='lower_and_strip_punctuation',\n",
    "    split='whitespace',\n",
    "    output_mode='tf-idf',\n",
    "    pad_to_max_tokens=True)\n",
    "\n",
    "vectorize_layer_info.adapt(dataset['validation'].map(lambda items: items['passage']).batch(64), reset_state=True)\n",
    "\n",
    "vectorize_layer_info(next(iter(dataset['validation'].map(lambda items: items['passage']).batch(2).take(1))))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 190), dtype=int64, numpy=\n",
       "array([[436,  21,   1,   8,   6,   1, 255,   3, 436, 167,   1,  21,   1,\n",
       "          1,  16,   1,   1,  11,   6,   1,   3,   1,   1,   3, 436,  11,\n",
       "          1,  31,  64,   1,  21,   2, 294,   3,   1,   1,   7,   2,   1,\n",
       "        204,   1,   1,   1,  25,   1,   1,   1,   1,   1,   1,   1,   1,\n",
       "          1,   1,   1,   1,   1, 234,   1,   1,   1,   1,   1,   1,   1,\n",
       "          1,   1, 217,   1,   1,  72,   1,   1,   1,   1,   1,  27,   1,\n",
       "          1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
       "          1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
       "          1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
       "          1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
       "          1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
       "          1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
       "          1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
       "          1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
       "          1,   1,   1,   1,   1,   1,   1,   1]])>"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorize_layer_info = TextVectorization(\n",
    "    max_tokens=500,\n",
    "    standardize='lower_and_strip_punctuation',\n",
    "    split='whitespace',\n",
    "    ngrams=5,\n",
    "    output_mode='int',\n",
    "    output_sequence_length=None)\n",
    "\n",
    "vectorize_layer_info.adapt(dataset['validation'].map(lambda items: items['passage']).batch(64), reset_state=True)\n",
    "\n",
    "vectorize_layer_info(next(iter(dataset['validation'].map(lambda items: items['passage']).batch(1).take(1))))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=string, numpy=b'Death from laughter is a rare form of death, usually resulting from cardiac arrest or asphyxiation, caused by a fit of laughter. Instances of death by laughter have been recorded from the times of ancient Greece to the modern day.'>"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(dataset['validation'].map(lambda items: items['passage']).take(1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b' death from [UNK] is a [UNK] form of death usually [UNK] from [UNK] [UNK] or [UNK] [UNK] by a [UNK] of [UNK] [UNK] of death by [UNK] have been [UNK] from the times of [UNK] [UNK] to the [UNK] day [UNK] [UNK] [UNK] is a [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] by a [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] have been [UNK] [UNK] from the [UNK] [UNK] [UNK] [UNK] [UNK] to the [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]'"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dir(vectorize_layer_info)\n",
    "encoding = {k:v for v,k in zip(*vectorize_layer_info.get_weights())}\n",
    "uncoded = b''\n",
    "\n",
    "tmp = vectorize_layer_info(next(iter(dataset['validation'].map(lambda items: items['passage']).batch(1).take(1)))).numpy()[0]\n",
    "for token in tmp:\n",
    "    uncoded += b' '+encoding[token]\n",
    "uncoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([b'[UNK]', b'', b'become', b'the term', b'history', b'relationship',\n",
       "        b'seasons', b'see', b'20', b'available', b'free', b'standard',\n",
       "        b'within the', b'at least', b'down', b'england', b'thus', b'top',\n",
       "        b'was a', b'islands', b'oil', b'that is', b'size',\n",
       "        b'television series', b'from a', b'km', b'the ball', b'have a',\n",
       "        b'it has', b'card', b'it is a', b'used to', b'australia', b'local',\n",
       "        b'5', b'death', b'sequel', b'title', b'do not', b'stars',\n",
       "        b'the united kingdom', b'there is', b'the last', b'used in',\n",
       "        b'episode', b'2012', b'drama', b'base', b'carry', b'december',\n",
       "        b'early', b'the third', b'august', b'line', b'published', b'using',\n",
       "        b'character', b'required', b'premiered on', b'11', b'make',\n",
       "        b'november', b'considered', b'force', b'novel', b'renewed', b'day',\n",
       "        b'result', b'xbox', b'west', b'long', b'began', b'major', b'off',\n",
       "        b'world', b'later', b'production', b'months', b'order',\n",
       "        b'part of the', b'originally', b'the show', b'as an', b'days',\n",
       "        b'power', b'single', b'can', b'when the', b'the end', b'along',\n",
       "        b'central', b'back', b'into', b'since', b'referred to as',\n",
       "        b'world cup', b'typically', b'park', b'total', b'generally',\n",
       "        b'this is', b'as well', b'15', b'does', b'same', b'there are',\n",
       "        b'court', b'january', b'more than', b'with', b'the game',\n",
       "        b'the two', b'2011', b'2013', b'left', b'if the', b'large', b'six',\n",
       "        b'against', b'of the united states', b'house', b'this', b'fourth',\n",
       "        b'to', b'south', b'is also', b'per', b'between the', b'february',\n",
       "        b'member', b'country', b'term', b'having', b'many', b'story',\n",
       "        b'no', b'was released', b'constitution', b'person', b'species',\n",
       "        b'international', b'the most', b'english', b'and was',\n",
       "        b'have been', b'small', b'school', b'the new', b'referred to',\n",
       "        b'the only', b'number of', b'that', b'times', b'on a', b'play',\n",
       "        b'i', b'known as', b'kingdom', b'white', b'book', b'island', b'3',\n",
       "        b'became', b'referred', b'east', b'five', b'directed',\n",
       "        b'based on the', b'even', b'it', b'premiered', b'british', b'air',\n",
       "        b'during the', b'right', b'area', b'song', b'least', b'and a',\n",
       "        b'million', b'played', b'than', b'best', b'also known', b'last',\n",
       "        b'fifa', b'still', b'so', b'body', b'into the', b'march', b'has a',\n",
       "        b'largest', b'place', b'known as the', b'under the', b'in',\n",
       "        b'they are', b'6', b'include', b'to as', b'public', b'fifa world',\n",
       "        b'under', b'as well as', b'around', b'directed by', b'by a',\n",
       "        b'countries', b'red', b'several', b'california', b'commonly',\n",
       "        b'april', b'must', b'do', b'september', b'found', b'home',\n",
       "        b'canada', b'different', b'2014', b'less', b'often', b'may be',\n",
       "        b'bank', b'or', b'light', b'final', b'after', b'another', b'ball',\n",
       "        b'end', b'original', b'people', b'written', b'now', b'announced',\n",
       "        b'high', b'states', b'2010', b'the second', b'is not', b'if',\n",
       "        b'united kingdom', b'the world', b'cup', b'war', b'very',\n",
       "        b'one of the', b'official', b'due', b'western', b'federal',\n",
       "        b'part of', b'about', b'on the', b'been', b'show', b'them',\n",
       "        b'and is', b'company', b'being', b'in the united states', b'18',\n",
       "        b'new york', b'black', b'players', b'10', b'she', b'player',\n",
       "        b'group', b'2', b'then', b'water', b'while', b'was the',\n",
       "        b'has been', b'october', b'for the', b'usually', b'return',\n",
       "        b'those', b'although', b'year', b'2015', b'him', b'sometimes',\n",
       "        b'based', b'8', b'north', b'without', b'season', b'common', b'1',\n",
       "        b'the us', b'other', b'four', b'just', b'its', b'the original',\n",
       "        b'third', b'also', b'as the', b'well', b'won', b'team', b'are',\n",
       "        b'part', b'released', b'system', b'version', b'members', b'they',\n",
       "        b'before', b'some', b'though', b'these', b'such as', b'either',\n",
       "        b'within', b'city', b'21', b'human', b'each', b'm', b'would',\n",
       "        b'games', b'where', b'one', b'service', b'not', b'until',\n",
       "        b'based on', b'law', b'go', b'will', b'university', b'york',\n",
       "        b'of their', b'main', b'was', b'life', b'called', b'2017',\n",
       "        b'second', b'to be', b'did', b'over', b'because', b'any', b'years',\n",
       "        b'game', b'by the', b'teams', b'from the', b'the', b'however',\n",
       "        b'with a', b'for a', b'it was', b'america', b'family',\n",
       "        b'the series', b'his', b'of its', b'had', b'one of', b'is one',\n",
       "        b'can be', b'there', b'it is', b'period', b'form', b'like',\n",
       "        b'television', b'the film', b'only', b'three', b'set', b'2018',\n",
       "        b'own', b'through', b'located', b'league', b'century', b'number',\n",
       "        b'time', b'is', b'between', b'known', b'end of', b'have',\n",
       "        b'united', b'is the', b'at', b'european', b'and', b'of a', b'all',\n",
       "        b'in the united', b'us', b'in which', b'fifa world cup', b'such',\n",
       "        b'much', b'laws', b'the first', b'use', b'special', b'more',\n",
       "        b'american', b'range', b'produced', b'of', b'were', b'due to',\n",
       "        b'30', b'who', b'also known as', b'football', b'out', b'an',\n",
       "        b'during', b'with the', b'national', b'a', b'example', b'as of',\n",
       "        b'used', b'the united states', b'is an', b'united states',\n",
       "        b'the united', b'which is', b'received', b'when', b'act',\n",
       "        b'are not', b'he', b'film', b'two', b'12', b'legal', b'her',\n",
       "        b'july', b'made', b'episodes', b'new', b'may', b'4', b'has',\n",
       "        b'most', b'films', b'that the', b'the same', b'but', b'from',\n",
       "        b'it is the', b'after the', b'government', b'2016', b'first',\n",
       "        b'few', b'does not', b'named', b'following', b'once', b'both',\n",
       "        b'age', b'president', b'their', b'created', b'at the', b'similar',\n",
       "        b'state', b'is a', b'in a', b'well as', b'current', b'series',\n",
       "        b'of the united', b'as', b'which', b'an american', b'as a',\n",
       "        b'and the', b'be', b'june', b'to a', b'again', b'of the',\n",
       "        b'to the', b'including', b'name', b'for', b'in the', b'by', b'up',\n",
       "        b'on'], dtype=object),\n",
       " array([  1,   0, 499, 494, 492, 491, 490, 489, 487, 485, 483, 481, 480,\n",
       "        479, 476, 475, 471, 470, 469, 466, 464, 463, 460, 459, 455, 454,\n",
       "        453, 451, 448, 446, 444, 441, 478, 438, 437, 436, 434, 433, 432,\n",
       "        430, 429, 428, 427, 426, 456, 425, 423, 421, 420, 419, 418, 413,\n",
       "        412, 410, 408, 407, 405, 403, 402, 401, 399, 398, 395, 394, 337,\n",
       "        391, 204, 390, 244, 389, 348, 384, 228, 380,  60, 161, 379, 376,\n",
       "        375, 371, 496, 370, 422, 368, 366, 365,  59, 362, 442, 361, 359,\n",
       "        357,  75, 103, 355, 147, 287, 331, 354, 353, 351, 180, 350, 191,\n",
       "        113, 346, 345, 340, 338,  14, 335, 334, 349, 333, 381, 450, 274,\n",
       "        330, 329, 367, 327,  38, 373,   7, 168, 326, 323, 320, 377, 318,\n",
       "        477, 316, 315, 115, 312, 101, 311, 445, 308, 307, 372, 306, 303,\n",
       "        386, 217, 302, 336, 299, 297, 363, 295,  19, 294, 288, 409, 285,\n",
       "        116, 282, 286, 277, 275, 273, 272, 298, 467, 232, 271, 385, 270,\n",
       "         18, 268, 266, 261, 258, 257, 159, 317, 439, 164, 256, 254,  82,\n",
       "        253, 250, 201, 249, 280, 248, 247, 246, 243, 352, 314, 242, 417,\n",
       "        321,   5, 241, 486, 239, 341, 237, 342, 120, 240, 235, 344, 234,\n",
       "        233, 231, 230, 332, 259, 227, 198, 252, 226, 224, 229, 221, 219,\n",
       "        222, 416, 139, 216, 452,  16, 339, 215,  57, 301, 214, 213, 212,\n",
       "        211, 208, 393, 278, 206,  33, 283, 205, 202,  90, 378, 220, 109,\n",
       "        196, 447, 195, 473, 194, 488, 193, 185, 123,  41,  64, 188, 184,\n",
       "        183, 182, 105, 143, 406, 189, 356, 281, 181,  91, 197, 177, 175,\n",
       "        155, 170,  94, 245, 169, 251,  53, 167, 495, 236, 162, 190, 165,\n",
       "        179, 225, 160, 396, 157, 304,  56, 207, 192, 158,  47, 156, 461,\n",
       "         34, 343, 154,  30,  61, 152, 209, 128,  20, 151, 150, 149, 493,\n",
       "        347,  43, 145,  87, 305, 138,  95, 319, 174, 135, 387, 474, 134,\n",
       "        400, 133, 132, 127,  39, 284,  28, 153, 200, 125, 498, 124, 397,\n",
       "        178, 435, 313,  17, 310, 122,  97, 121,  93, 457, 111, 173, 110,\n",
       "        107, 106,  51, 364,  72,   2, 104, 102, 118, 100, 260, 176,  99,\n",
       "         55, 415,  96, 146, 497, 171,  98,  42, 392, 255, 309, 172, 137,\n",
       "         74, 117, 166,  92, 300, 129, 289, 223, 484, 142,  78,   8,  88,\n",
       "         86, 411,  31,  36,  54,  24, 431,   4,  81,  66, 114,  80, 449,\n",
       "        358,  76, 443, 382,  79, 136, 482,  84,  77, 374, 262,   3,  71,\n",
       "        203, 424,  69, 291, 269, 163,  22, 108,  73, 141,   6, 383, 325,\n",
       "         65,  63, 126,  45,  46, 199, 414,  70, 267, 369,  62,  48,  52,\n",
       "        388, 324,  67, 290, 148, 276,  50,  49, 293,  29,  68, 296, 140,\n",
       "        119,  44,  21, 440, 292, 264, 186,  40, 462, 265, 465, 218, 472,\n",
       "        112, 279, 404,  35, 328,  83, 322,  85,  25,  89, 238, 468,  37,\n",
       "        263,   9,  26, 360,  58,  32,  23, 210, 187, 458,  10,  27, 131,\n",
       "        144,  13,  15,  11, 130,  12])]"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorize_layer_info.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=string, numpy=b'Death from laughter is a rare form of death, usually resulting from cardiac arrest or asphyxiation, caused by a fit of laughter. Instances of death by laughter have been recorded from the times of ancient Greece to the modern day.'>"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(dataset['validation'].map(lambda items: items['passage']).take(1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(190,), dtype=int64, numpy=\n",
       "array([ 436,   21,    1,    8,    6, 1708,  255,    3,  436,  167, 1342,\n",
       "         21, 4312,    1,   16,    1, 1161,   11,    6,    1,    3,    1,\n",
       "          1,    3,  436,   11,    1,   31,   64, 1181,   21,    2,  294,\n",
       "          3, 4021,    1,    7,    2,  766,  204,    1,    1,    1,   25,\n",
       "          1,    1,  772,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "          1, 1672,  234,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "          1,  217,    1,    1,   72,    1,    1,    1,    1,    1,   27,\n",
       "       4812,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "          1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "          1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "          1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "          1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "          1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "          1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "          1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "          1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "          1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "          1,    1,    1])>"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_features = 5000\n",
    "vectorize_layer_info = TextVectorization(\n",
    "    max_tokens=max_features,\n",
    "    standardize='lower_and_strip_punctuation',\n",
    "    split='whitespace',\n",
    "    ngrams=5,\n",
    "    output_mode='int',\n",
    "    output_sequence_length=None)\n",
    "\n",
    "vectorize_layer_info.adapt(dataset['validation'].map(lambda items: items['passage']).batch(64), reset_state=True)\n",
    "\n",
    "vectorize_layer_info(next(iter(dataset['validation'].map(lambda items: items['passage']).take(1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'death from [UNK] is a rare form of death usually resulting from cardiac [UNK] or [UNK] caused by a [UNK] of [UNK] [UNK] of death by [UNK] have been recorded from the times of ancient [UNK] to the modern day [UNK] [UNK] [UNK] is a [UNK] [UNK] form of [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] caused by by a [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] have been [UNK] [UNK] from the [UNK] [UNK] [UNK] [UNK] [UNK] to the the modern [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] '"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# dir(vectorize_layer_info)\n",
    "encoding = {k:v for v,k in zip(*vectorize_layer_info.get_weights())}\n",
    "uncoded = b''\n",
    "\n",
    "tmp = vectorize_layer_info(next(iter(dataset['validation'].map(lambda items: items['passage']).batch(1).take(1))))\n",
    "for i,token in enumerate(tmp.numpy()[0]):\n",
    "    #print(i, encoding[token])\n",
    "    uncoded += encoding[token]+b' '\n",
    "uncoded\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://stackoverflow.com/questions/606191/convert-bytes-to-a-string\n",
    "len(next(iter(dataset['validation'].map(lambda items: items['passage']).take(1))).numpy().decode(\"utf-8\").split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "190"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "length = 0\n",
    "for ngram in range(5):\n",
    "    length += 40-ngram\n",
    "length    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['superfecundation refers to the fertilization',\n",
       " 'the fertilization of two separate',\n",
       " 'fertilization of two separate ova',\n",
       " 'national basketball association',\n",
       " 'heteropaternal superfecundation',\n",
       " 'government of the united states',\n",
       " 'the united states constitution',\n",
       " 'superfecundation refers to the',\n",
       " 'refers to the fertilization of',\n",
       " 'arrival to and departure from']"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(vectorize_layer_info.get_vocabulary(), key=lambda x: -len(x))[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'superfecundation' in vectorize_layer_info.get_vocabulary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential()\n",
    "model.add(vectorize_layer_info)\n",
    "# tf.one_hot?\n",
    "model.add(tf.keras.layers.Lambda(lambda inputs: tf.one_hot(inputs, depth=max_features, axis=-1)))\n",
    "model.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 190, 5000), dtype=float32, numpy=\n",
       "array([[[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 1., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 1., 0., ..., 0., 0., 0.],\n",
       "        [0., 1., 0., ..., 0., 0., 0.],\n",
       "        [0., 1., 0., ..., 0., 0., 0.]]], dtype=float32)>"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = next(iter(dataset['validation'].map(lambda items: items['passage']).batch(1).take(1)))\n",
    "model(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 190, 5000])"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(tmp).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 190), dtype=int64, numpy=\n",
       "array([[ 436,   21,    1,    8,    6, 1708,  255,    3,  436,  167, 1342,\n",
       "          21, 4312,    1,   16,    1, 1161,   11,    6,    1,    3,    1,\n",
       "           1,    3,  436,   11,    1,   31,   64, 1181,   21,    2,  294,\n",
       "           3, 4021,    1,    7,    2,  766,  204,    1,    1,    1,   25,\n",
       "           1,    1,  772,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1, 1672,  234,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,  217,    1,    1,   72,    1,    1,    1,    1,    1,   27,\n",
       "        4812,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1]])>"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorize_layer_info(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential()\n",
    "model.add(vectorize_layer_info)\n",
    "#tf.keras.layers.Embedding?\n",
    "embedding_dimension = 2\n",
    "model.add(tf.keras.layers.Embedding(input_dim=max_features, output_dim=embedding_dimension))\n",
    "model.compile()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 190, 2), dtype=float32, numpy=\n",
       "array([[[-0.00598611,  0.00015676],\n",
       "        [-0.03800913, -0.03702133],\n",
       "        [ 0.00618122, -0.01946957],\n",
       "        [-0.00406413, -0.02227722],\n",
       "        [-0.01471644, -0.03203429],\n",
       "        [ 0.0173544 , -0.04374142],\n",
       "        [-0.02140815, -0.04428954],\n",
       "        [ 0.01133432,  0.04723001],\n",
       "        [-0.00598611,  0.00015676],\n",
       "        [ 0.03628026, -0.00064509],\n",
       "        [-0.02108628, -0.04130189],\n",
       "        [-0.03800913, -0.03702133],\n",
       "        [ 0.03207003,  0.00343293],\n",
       "        [ 0.00618122, -0.01946957],\n",
       "        [ 0.04569793,  0.02067432],\n",
       "        [ 0.00618122, -0.01946957],\n",
       "        [-0.03137888,  0.04376942],\n",
       "        [-0.04146606, -0.01292599],\n",
       "        [-0.01471644, -0.03203429],\n",
       "        [ 0.00618122, -0.01946957],\n",
       "        [ 0.01133432,  0.04723001],\n",
       "        [ 0.00618122, -0.01946957],\n",
       "        [ 0.00618122, -0.01946957],\n",
       "        [ 0.01133432,  0.04723001],\n",
       "        [-0.00598611,  0.00015676],\n",
       "        [-0.04146606, -0.01292599],\n",
       "        [ 0.00618122, -0.01946957],\n",
       "        [ 0.00498197, -0.01451341],\n",
       "        [ 0.0170652 , -0.02321907],\n",
       "        [ 0.04444707,  0.03914297],\n",
       "        [-0.03800913, -0.03702133],\n",
       "        [ 0.00461543, -0.02133434],\n",
       "        [-0.03476804,  0.02077294],\n",
       "        [ 0.01133432,  0.04723001],\n",
       "        [ 0.01952403,  0.02194435],\n",
       "        [ 0.00618122, -0.01946957],\n",
       "        [ 0.00105828,  0.00551834],\n",
       "        [ 0.00461543, -0.02133434],\n",
       "        [-0.00302272,  0.00427154],\n",
       "        [-0.02937266,  0.03640679],\n",
       "        [ 0.00618122, -0.01946957],\n",
       "        [ 0.00618122, -0.01946957],\n",
       "        [ 0.00618122, -0.01946957],\n",
       "        [ 0.01020529,  0.00272284],\n",
       "        [ 0.00618122, -0.01946957],\n",
       "        [ 0.00618122, -0.01946957],\n",
       "        [ 0.0288095 ,  0.01973231],\n",
       "        [ 0.00618122, -0.01946957],\n",
       "        [ 0.00618122, -0.01946957],\n",
       "        [ 0.00618122, -0.01946957],\n",
       "        [ 0.00618122, -0.01946957],\n",
       "        [ 0.00618122, -0.01946957],\n",
       "        [ 0.00618122, -0.01946957],\n",
       "        [ 0.00618122, -0.01946957],\n",
       "        [ 0.00618122, -0.01946957],\n",
       "        [ 0.00618122, -0.01946957],\n",
       "        [ 0.0467121 , -0.01808625],\n",
       "        [-0.00165194,  0.00441259],\n",
       "        [ 0.00618122, -0.01946957],\n",
       "        [ 0.00618122, -0.01946957],\n",
       "        [ 0.00618122, -0.01946957],\n",
       "        [ 0.00618122, -0.01946957],\n",
       "        [ 0.00618122, -0.01946957],\n",
       "        [ 0.00618122, -0.01946957],\n",
       "        [ 0.00618122, -0.01946957],\n",
       "        [ 0.00618122, -0.01946957],\n",
       "        [ 0.00618122, -0.01946957],\n",
       "        [ 0.01990951, -0.0147546 ],\n",
       "        [ 0.00618122, -0.01946957],\n",
       "        [ 0.00618122, -0.01946957],\n",
       "        [-0.00889442,  0.04015506],\n",
       "        [ 0.00618122, -0.01946957],\n",
       "        [ 0.00618122, -0.01946957],\n",
       "        [ 0.00618122, -0.01946957],\n",
       "        [ 0.00618122, -0.01946957],\n",
       "        [ 0.00618122, -0.01946957],\n",
       "        [ 0.00202883,  0.04299628],\n",
       "        [-0.00132841,  0.03996447],\n",
       "        [ 0.00618122, -0.01946957],\n",
       "        [ 0.00618122, -0.01946957],\n",
       "        [ 0.00618122, -0.01946957],\n",
       "        [ 0.00618122, -0.01946957],\n",
       "        [ 0.00618122, -0.01946957],\n",
       "        [ 0.00618122, -0.01946957],\n",
       "        [ 0.00618122, -0.01946957],\n",
       "        [ 0.00618122, -0.01946957],\n",
       "        [ 0.00618122, -0.01946957],\n",
       "        [ 0.00618122, -0.01946957],\n",
       "        [ 0.00618122, -0.01946957],\n",
       "        [ 0.00618122, -0.01946957],\n",
       "        [ 0.00618122, -0.01946957],\n",
       "        [ 0.00618122, -0.01946957],\n",
       "        [ 0.00618122, -0.01946957],\n",
       "        [ 0.00618122, -0.01946957],\n",
       "        [ 0.00618122, -0.01946957],\n",
       "        [ 0.00618122, -0.01946957],\n",
       "        [ 0.00618122, -0.01946957],\n",
       "        [ 0.00618122, -0.01946957],\n",
       "        [ 0.00618122, -0.01946957],\n",
       "        [ 0.00618122, -0.01946957],\n",
       "        [ 0.00618122, -0.01946957],\n",
       "        [ 0.00618122, -0.01946957],\n",
       "        [ 0.00618122, -0.01946957],\n",
       "        [ 0.00618122, -0.01946957],\n",
       "        [ 0.00618122, -0.01946957],\n",
       "        [ 0.00618122, -0.01946957],\n",
       "        [ 0.00618122, -0.01946957],\n",
       "        [ 0.00618122, -0.01946957],\n",
       "        [ 0.00618122, -0.01946957],\n",
       "        [ 0.00618122, -0.01946957],\n",
       "        [ 0.00618122, -0.01946957],\n",
       "        [ 0.00618122, -0.01946957],\n",
       "        [ 0.00618122, -0.01946957],\n",
       "        [ 0.00618122, -0.01946957],\n",
       "        [ 0.00618122, -0.01946957],\n",
       "        [ 0.00618122, -0.01946957],\n",
       "        [ 0.00618122, -0.01946957],\n",
       "        [ 0.00618122, -0.01946957],\n",
       "        [ 0.00618122, -0.01946957],\n",
       "        [ 0.00618122, -0.01946957],\n",
       "        [ 0.00618122, -0.01946957],\n",
       "        [ 0.00618122, -0.01946957],\n",
       "        [ 0.00618122, -0.01946957],\n",
       "        [ 0.00618122, -0.01946957],\n",
       "        [ 0.00618122, -0.01946957],\n",
       "        [ 0.00618122, -0.01946957],\n",
       "        [ 0.00618122, -0.01946957],\n",
       "        [ 0.00618122, -0.01946957],\n",
       "        [ 0.00618122, -0.01946957],\n",
       "        [ 0.00618122, -0.01946957],\n",
       "        [ 0.00618122, -0.01946957],\n",
       "        [ 0.00618122, -0.01946957],\n",
       "        [ 0.00618122, -0.01946957],\n",
       "        [ 0.00618122, -0.01946957],\n",
       "        [ 0.00618122, -0.01946957],\n",
       "        [ 0.00618122, -0.01946957],\n",
       "        [ 0.00618122, -0.01946957],\n",
       "        [ 0.00618122, -0.01946957],\n",
       "        [ 0.00618122, -0.01946957],\n",
       "        [ 0.00618122, -0.01946957],\n",
       "        [ 0.00618122, -0.01946957],\n",
       "        [ 0.00618122, -0.01946957],\n",
       "        [ 0.00618122, -0.01946957],\n",
       "        [ 0.00618122, -0.01946957],\n",
       "        [ 0.00618122, -0.01946957],\n",
       "        [ 0.00618122, -0.01946957],\n",
       "        [ 0.00618122, -0.01946957],\n",
       "        [ 0.00618122, -0.01946957],\n",
       "        [ 0.00618122, -0.01946957],\n",
       "        [ 0.00618122, -0.01946957],\n",
       "        [ 0.00618122, -0.01946957],\n",
       "        [ 0.00618122, -0.01946957],\n",
       "        [ 0.00618122, -0.01946957],\n",
       "        [ 0.00618122, -0.01946957],\n",
       "        [ 0.00618122, -0.01946957],\n",
       "        [ 0.00618122, -0.01946957],\n",
       "        [ 0.00618122, -0.01946957],\n",
       "        [ 0.00618122, -0.01946957],\n",
       "        [ 0.00618122, -0.01946957],\n",
       "        [ 0.00618122, -0.01946957],\n",
       "        [ 0.00618122, -0.01946957],\n",
       "        [ 0.00618122, -0.01946957],\n",
       "        [ 0.00618122, -0.01946957],\n",
       "        [ 0.00618122, -0.01946957],\n",
       "        [ 0.00618122, -0.01946957],\n",
       "        [ 0.00618122, -0.01946957],\n",
       "        [ 0.00618122, -0.01946957],\n",
       "        [ 0.00618122, -0.01946957],\n",
       "        [ 0.00618122, -0.01946957],\n",
       "        [ 0.00618122, -0.01946957],\n",
       "        [ 0.00618122, -0.01946957],\n",
       "        [ 0.00618122, -0.01946957],\n",
       "        [ 0.00618122, -0.01946957],\n",
       "        [ 0.00618122, -0.01946957],\n",
       "        [ 0.00618122, -0.01946957],\n",
       "        [ 0.00618122, -0.01946957],\n",
       "        [ 0.00618122, -0.01946957],\n",
       "        [ 0.00618122, -0.01946957],\n",
       "        [ 0.00618122, -0.01946957],\n",
       "        [ 0.00618122, -0.01946957],\n",
       "        [ 0.00618122, -0.01946957],\n",
       "        [ 0.00618122, -0.01946957],\n",
       "        [ 0.00618122, -0.01946957],\n",
       "        [ 0.00618122, -0.01946957],\n",
       "        [ 0.00618122, -0.01946957],\n",
       "        [ 0.00618122, -0.01946957],\n",
       "        [ 0.00618122, -0.01946957],\n",
       "        [ 0.00618122, -0.01946957],\n",
       "        [ 0.00618122, -0.01946957],\n",
       "        [ 0.00618122, -0.01946957]]], dtype=float32)>"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(tmp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 380, 2), dtype=float32, numpy=\n",
       "array([[[-0.00598611,  0.00015676],\n",
       "        [-0.03800913, -0.03702133],\n",
       "        [ 0.00618122, -0.01946957],\n",
       "        ...,\n",
       "        [ 0.01546757, -0.03812512],\n",
       "        [ 0.01546757, -0.03812512],\n",
       "        [ 0.01546757, -0.03812512]],\n",
       "\n",
       "       [[ 0.00461543, -0.02133434],\n",
       "        [ 0.03143919,  0.04502324],\n",
       "        [ 0.00618122, -0.01946957],\n",
       "        ...,\n",
       "        [ 0.00618122, -0.01946957],\n",
       "        [ 0.00618122, -0.01946957],\n",
       "        [ 0.00618122, -0.01946957]]], dtype=float32)>"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = next(iter(dataset['validation'].map(lambda items: items['passage']).batch(2).take(1)))\n",
    "model(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 380), dtype=int64, numpy=\n",
       "array([[ 436,   21,    1,    8,    6, 1708,  255,    3,  436,  167, 1342,\n",
       "          21, 4312,    1,   16,    1, 1161,   11,    6,    1,    3,    1,\n",
       "           1,    3,  436,   11,    1,   31,   64, 1181,   21,    2,  294,\n",
       "           3, 4021,    1,    7,    2,  766,  204,    1,    1,    1,   25,\n",
       "           1,    1,  772,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1, 1672,  234,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,  217,    1,    1,   72,    1,    1,    1,    1,    1,   27,\n",
       "        4812,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0],\n",
       "       [   2,  231,    1,    8,    2,   74, 1151,  307,    3,    2, 1951,\n",
       "           1,    4,    2,  176,    1,   18,   29,   64,  821, 1858,    5,\n",
       "           2,    1,    4, 2442, 3948,   44,    2, 1341,    3,    1,    1,\n",
       "        1395, 2228,  815,   13,   34,    1,    1,    5,   34,  300,  176,\n",
       "           1,   26,    8,  151,    3,    2,    1,    1,  361,   14,    2,\n",
       "           1,    1,    4,    1, 3948,   52,    1,   20, 2795,   18,    8,\n",
       "          28, 2572,  820,    7,    2,    1,    1,   26,    8,    6,    1,\n",
       "           1, 3494,    1,    1,   54,  363,    1,    1, 2362,   10, 3089,\n",
       "           1,    1,   32, 1210,    1,    1,  448,  169,    1,    1,    1,\n",
       "          15,    1,    1,    1,    1,    1,  792,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1, 1188,    1,    1,    1,  928, 2042,    1,\n",
       "           1,    1,  199, 3905,  185,   10,    1,    1,    1,  593,   73,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,   42,\n",
       "         202,    1,    1, 2017,   27,    1,    1,    1,  199,   25,    1,\n",
       "           1,    1,    1,    1, 1658,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1, 1655,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1, 3904,  371,    1,    1,    1,    1, 4350,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1, 2044,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1, 4376,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1, 4971,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1]])>"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorize_layer_info(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(tf.keras.layers.Lambda(lambda inputs: tf.math.reduce_mean(inputs, axis=1)))\n",
    "# GlobalAveragePooling1D\n",
    "# https://www.tensorflow.org/tutorials/text/word_embeddings\n",
    "model.compile()          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
       "array([[ 0.01011951, -0.02656675],\n",
       "       [ 0.0050073 , -0.01399456]], dtype=float32)>"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# first try:\n",
    "# None; list -- None means full string is token; list is not a tf function\n",
    "\n",
    "# second try: https://www.tensorflow.org/api_docs/python/tf/strings/bytes_split\n",
    "# split=tf.strings.bytes_split, \n",
    "# ...almost works, but TextVectorization assumes ngrams are getting separated by space ' '\n",
    "\n",
    "# third try: https://www.tensorflow.org/datasets/api_docs/python/tfds/deprecated/text/SubwordTextEncoder\n",
    "# not going to be supported...\n",
    "\n",
    "# fourth try: there is a new subword encoder\n",
    "# https://blog.tensorflow.org/2019/06/introducing-tftext.html\n",
    "# https://dzlab.github.io/nlp/2019/12/25/tensorflow-text-intro/\n",
    "# https://www.tensorflow.org/tutorials/tensorflow_text/intro\n",
    "# ! pip install -q tensorflow-text\n",
    "import tensorflow_text as text\n",
    "#text.WordpieceTokenizer\n",
    "\n",
    "# firth try: keras preprocess\n",
    "# https://towardsdatascience.com/how-to-preprocess-character-level-text-with-keras-349065121089\n",
    "#tokenizer = tf.keras.preprocessing.text.Tokenizer(num_words=500, char_level=True, oov_token='[UNK]')\n",
    "#tokenizer.fit_on_texts(dataset['validation'].map(lambda items: items['passage']).batch(64))\n",
    "# https://stackoverflow.com/questions/61445913/how-do-i-preprocess-and-tokenize-a-tensorflow-csvdataset-inside-the-map-method\n",
    "# -- didn't pursue this because it doesn't immediately work with a TF Dataset object \n",
    "\n",
    "\n",
    "# conclusion: either the second or the fourth \n",
    "# - second IS fine -- just need to put it back together without spaces\n",
    "# - fourth IS interesting -- just need to provide the `vocab_lookup_table`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/tensorflow/text/issues/27\n",
    "# https://github.com/google-research/bert\n",
    "# https://ai.googleblog.com/2018/11/open-sourcing-bert-state-of-art-pre.html\n",
    "# https://medium.com/tensorflow/introducing-tf-text-438c8552bd5e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[PAD]',\n",
       " '[unused0]',\n",
       " '[unused1]',\n",
       " '[unused2]',\n",
       " '[unused3]',\n",
       " '[unused4]',\n",
       " '[unused5]',\n",
       " '[unused6]',\n",
       " '[unused7]',\n",
       " '[unused8]']"
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://stackoverflow.com/questions/14676265/how-to-read-a-text-file-into-a-list-or-an-array-with-python\n",
    "path = '/Users/gck8gd/Documents/courses/SYS_6016_DeepLearning/L11/'\n",
    "file = 'bert-base-uncased-vocab.txt'\n",
    "vocab_file = open(path+file, \"r\")\n",
    "vocab = vocab_file.read().split('\\n')#.readlines()\n",
    "vocab_file.close()\n",
    "vocab[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = tf.range(len(vocab), dtype=tf.int64)\n",
    "table_init = tf.lookup.KeyValueTensorInitializer(vocab, indices)\n",
    "num_oov_buckets = 1\n",
    "table = tf.lookup.StaticVocabularyTable(table_init, num_oov_buckets, lookup_key_dtype=tf.string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding = {i:token for token,i in zip(vocab, indices.numpy())}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'deaths'"
      ]
     },
     "execution_count": 352,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoding[6677]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.RaggedTensor [[6677]]>, <tf.RaggedTensor [[0]]>, <tf.RaggedTensor [[6]]>)"
      ]
     },
     "execution_count": 350,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordpiece.tokenize_with_offsets(['Deaths'.lower()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordpiece = text.WordpieceTokenizer(table)\n",
    "whitespace = text.WhitespaceTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1,), dtype=string, numpy=\n",
       "array([b'Death from laughter is a rare form of death, usually resulting from cardiac arrest or asphyxiation, caused by a fit of laughter. Instances of death by laughter have been recorded from the times of ancient Greece to the modern day.'],\n",
       "      dtype=object)>"
      ]
     },
     "execution_count": 412,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = next(iter(dataset['validation'].map(lambda items: items['passage']).batch(1).take(1)))\n",
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.RaggedTensor [[b'death', b'from', b'laughter', b'is', b'a', b'rare', b'form', b'of', b'death,', b'usually', b'resulting', b'from', b'cardiac', b'arrest', b'or', b'asphyxiation,', b'caused', b'by', b'a', b'fit', b'of', b'laughter.', b'instances', b'of', b'death', b'by', b'laughter', b'have', b'been', b'recorded', b'from', b'the', b'times', b'of', b'ancient', b'greece', b'to', b'the', b'modern', b'day.']]>,\n",
       " <tf.RaggedTensor [[0, 6, 11, 20, 23, 25, 30, 35, 38, 45, 53, 63, 68, 76, 83, 86, 100, 107, 110, 112, 116, 119, 129, 139, 142, 148, 151, 160, 165, 170, 179, 184, 188, 194, 197, 205, 212, 215, 219, 226]]>,\n",
       " <tf.RaggedTensor [[5, 10, 19, 22, 24, 29, 34, 37, 44, 52, 62, 67, 75, 82, 85, 99, 106, 109, 111, 115, 118, 128, 138, 141, 147, 150, 159, 164, 169, 178, 183, 187, 193, 196, 204, 211, 214, 218, 225, 230]]>)"
      ]
     },
     "execution_count": 413,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "whitespace.tokenize_with_offsets(tf.strings.lower(tmp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.RaggedTensor [[[2331], [2013], [7239], [2003], [1037], [4678], [2433], [1997], [2331, 29623], [2788], [4525], [2013], [15050], [6545], [2030], [2004, 21281, 14787, 3508, 29623], [3303], [2011], [1037], [4906], [1997], [7239, 29625], [12107], [1997], [2331], [2011], [7239], [2031], [2042], [2680], [2013], [1996], [2335], [1997], [3418], [5483], [2000], [1996], [2715], [2154, 29625]]]>,\n",
       " <tf.RaggedTensor [[[0], [0], [0], [0], [0], [0], [0], [0], [0, 5], [0], [0], [0], [0], [0], [0], [0, 2, 5, 8, 12], [0], [0], [0], [0], [0], [0, 8], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0, 3]]]>,\n",
       " <tf.RaggedTensor [[[5], [4], [8], [2], [1], [4], [4], [2], [5, 6], [7], [9], [4], [7], [6], [2], [2, 5, 8, 12, 13], [6], [2], [1], [3], [2], [8, 9], [9], [2], [5], [2], [8], [4], [4], [8], [4], [3], [5], [2], [7], [6], [2], [3], [6], [3, 4]]]>)"
      ]
     },
     "execution_count": 414,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp2 = whitespace.tokenize_with_offsets(tf.strings.lower(tmp))\n",
    "wordpiece.tokenize_with_offsets(tmp2[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.RaggedTensor [[2331, 2013, 7239, 2003, 1037, 4678, 2433, 1997, 2331, 29623, 2788, 4525, 2013, 15050, 6545, 2030, 2004, 21281, 14787, 3508, 29623, 3303, 2011, 1037, 4906, 1997, 7239, 29625, 12107, 1997, 2331, 2011, 7239, 2031, 2042, 2680, 2013, 1996, 2335, 1997, 3418, 5483, 2000, 1996, 2715, 2154, 29625]]>,\n",
       " <tf.RaggedTensor [[0, 6, 11, 20, 23, 25, 30, 35, 38, 43, 45, 53, 63, 68, 76, 83, 86, 88, 91, 94, 98, 100, 107, 110, 112, 116, 119, 127, 129, 139, 142, 148, 151, 160, 165, 170, 179, 184, 188, 194, 197, 205, 212, 215, 219, 226, 229]]>,\n",
       " <tf.RaggedTensor [[10, 14, 27, 24, 25, 33, 38, 39, 49, 50, 59, 71, 71, 82, 88, 87, 101, 104, 107, 111, 112, 112, 111, 112, 118, 120, 136, 137, 147, 143, 152, 152, 167, 168, 173, 186, 187, 190, 198, 198, 211, 217, 216, 221, 231, 233, 234]]>)"
      ]
     },
     "execution_count": 408,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://github.com/tensorflow/text/issues/155\n",
    "\n",
    "@tf.function\n",
    "def wp_tokenizer(x): \n",
    "    wp = wordpiece.tokenize_with_offsets(x[0])\n",
    "    return (wp[0].merge_dims(-2, -1), \n",
    "           (wp[1]+tf.expand_dims(x[1], -1)).merge_dims(-2, -1), \n",
    "           (wp[2]+tf.expand_dims(x[2], -1)).merge_dims(-2, -1))\n",
    "\n",
    "wp_tokenizer(tmp2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.RaggedTensor [[2331, 2013, 7239, 2003, 1037, 4678, 2433, 1997, 2331, 29623, 2788, 4525, 2013, 15050, 6545, 2030, 2004, 21281, 14787, 3508, 29623, 3303, 2011, 1037, 4906, 1997, 7239, 29625, 12107, 1997, 2331, 2011, 7239, 2031, 2042, 2680, 2013, 1996, 2335, 1997, 3418, 5483, 2000, 1996, 2715, 2154, 29625]]>,\n",
       " <tf.RaggedTensor [[0, 6, 11, 20, 23, 25, 30, 35, 38, 43, 45, 53, 63, 68, 76, 83, 86, 88, 91, 94, 98, 100, 107, 110, 112, 116, 119, 127, 129, 139, 142, 148, 151, 160, 165, 170, 179, 184, 188, 194, 197, 205, 212, 215, 219, 226, 229]]>,\n",
       " <tf.RaggedTensor [[10, 14, 27, 24, 25, 33, 38, 39, 49, 50, 59, 71, 71, 82, 88, 87, 101, 104, 107, 111, 112, 112, 111, 112, 118, 120, 136, 137, 147, 143, 152, 152, 167, 168, 173, 186, 187, 190, 198, 198, 211, 217, 216, 221, 231, 233, 234]]>)"
      ]
     },
     "execution_count": 421,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordpiece_layer_info = lambda item: wp_tokenizer(whitespace.tokenize_with_offsets(tf.strings.lower(item)))\n",
    "\n",
    "tmp = wordpiece_layer_info(next(iter(dataset['validation'].map(lambda items: items['passage']).batch(1).take(1))))\n",
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2331,  2013,  7239,  2003,  1037,  4678,  2433,  1997,  2331,\n",
       "       29623,  2788,  4525,  2013, 15050,  6545,  2030,  2004, 21281,\n",
       "       14787,  3508, 29623,  3303,  2011,  1037,  4906,  1997,  7239,\n",
       "       29625, 12107,  1997,  2331,  2011,  7239,  2031,  2042,  2680,\n",
       "        2013,  1996,  2335,  1997,  3418,  5483,  2000,  1996,  2715,\n",
       "        2154, 29625])"
      ]
     },
     "execution_count": 425,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp[0][0].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'death from laughter is a rare form of death ##, usually resulting from cardiac arrest or as ##phy ##xia ##tion ##, caused by a fit of laughter ##. instances of death by laughter have been recorded from the times of ancient greece to the modern day ##. '"
      ]
     },
     "execution_count": 428,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uncoded = ''\n",
    "for token in tmp[0][0].numpy():\n",
    "    uncoded += encoding[token]+' '\n",
    "uncoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'death from laughter is a rare form of death, usually resulting from cardiac arrest or asphyxiation, caused by a fit of laughter. instances of death by laughter have been recorded from the times of ancient greece to the modern day. '"
      ]
     },
     "execution_count": 430,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uncoded.replace(' ##', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.RaggedTensor [[2331, 2013, 7239, 2003, 1037, 4678, 2433, 1997, 2331, 29623, 2788, 4525, 2013, 15050, 6545, 2030, 2004, 21281, 14787, 3508, 29623, 3303, 2011, 1037, 4906, 1997, 7239, 29625, 12107, 1997, 2331, 2011, 7239, 2031, 2042, 2680, 2013, 1996, 2335, 1997, 3418, 5483, 2000, 1996, 2715, 2154, 29625]]>,\n",
       " <tf.RaggedTensor [[0, 6, 11, 20, 23, 25, 30, 35, 38, 43, 45, 53, 63, 68, 76, 83, 86, 88, 91, 94, 98, 100, 107, 110, 112, 116, 119, 127, 129, 139, 142, 148, 151, 160, 165, 170, 179, 184, 188, 194, 197, 205, 212, 215, 219, 226, 229]]>,\n",
       " <tf.RaggedTensor [[10, 14, 27, 24, 25, 33, 38, 39, 49, 50, 59, 71, 71, 82, 88, 87, 101, 104, 107, 111, 112, 112, 111, 112, 118, 120, 136, 137, 147, 143, 152, 152, 167, 168, 173, 186, 187, 190, 198, 198, 211, 217, 216, 221, 231, 233, 234]]>)"
      ]
     },
     "execution_count": 432,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.RaggedTensor [[2331, 2013, 7239, 2003, 1037, 4678, 2433, 1997, 2331, 29623, 2788, 4525, 2013, 15050, 6545, 2030, 2004, 21281, 14787, 3508, 29623, 3303, 2011, 1037, 4906, 1997, 7239, 29625, 12107, 1997, 2331, 2011, 7239, 2031, 2042, 2680, 2013, 1996, 2335, 1997, 3418, 5483, 2000, 1996, 2715, 2154, 29625], [1996, 2417, 25462, 2003, 1996, 2069, 2542, 2427, 1997, 1996, 3562, 9932, 7630, 7946, 1998, 1996, 2155, 9932, 7630, 14615, 6679, 29625, 2009, 2038, 2042, 3130, 2872, 1999, 1996, 10958, 21408, 2239, 1998, 4562, 2945, 29623, 2021, 1996, 3463, 1997, 23192, 4106, 3073, 2844, 2490, 2005, 2049, 27691, 5579, 1999, 2049, 2219, 2155, 29623, 9932, 7630, 14615, 6679, 29623, 2029, 2003, 2112, 1997, 1996, 24169, 2442, 18349, 5178, 2050, 29623, 2247, 2007, 1996, 29268, 29623, 10958, 21408, 2239, 1998, 15315, 16814, 2945, 29625, 2048, 11056, 2024, 3858, 29625, 2009, 2003, 2025, 4876, 3141, 2000, 1996, 5016, 25462, 29623, 2029, 2003, 1037, 15191, 24471, 5332, 2094, 29625]]>,\n",
       " <tf.RaggedTensor [[0, 6, 11, 20, 23, 25, 30, 35, 38, 43, 45, 53, 63, 68, 76, 83, 86, 88, 91, 94, 98, 100, 107, 110, 112, 116, 119, 127, 129, 139, 142, 148, 151, 160, 165, 170, 179, 184, 188, 194, 197, 205, 212, 215, 219, 226, 229], [0, 4, 8, 14, 17, 21, 26, 33, 41, 44, 48, 54, 56, 58, 62, 66, 70, 77, 79, 81, 84, 86, 88, 91, 95, 100, 111, 118, 121, 125, 127, 130, 133, 137, 142, 150, 152, 156, 160, 168, 171, 184, 193, 201, 208, 216, 220, 224, 234, 249, 252, 256, 260, 266, 268, 270, 272, 275, 277, 279, 285, 288, 293, 296, 300, 312, 316, 319, 322, 323, 325, 331, 336, 340, 346, 348, 350, 353, 356, 360, 362, 366, 374, 376, 380, 391, 395, 405, 407, 410, 413, 417, 425, 433, 436, 440, 446, 451, 453, 459, 462, 464, 470, 472, 474, 475]]>,\n",
       " <tf.RaggedTensor [[10, 14, 27, 24, 25, 33, 38, 39, 49, 50, 59, 71, 71, 82, 88, 87, 101, 104, 107, 111, 112, 112, 111, 112, 118, 120, 136, 137, 147, 143, 152, 152, 167, 168, 173, 186, 187, 190, 198, 198, 211, 217, 216, 221, 231, 233, 234], [6, 10, 18, 18, 23, 29, 38, 47, 45, 50, 58, 63, 65, 68, 68, 72, 82, 89, 91, 94, 96, 97, 92, 97, 103, 120, 123, 122, 127, 134, 137, 139, 139, 145, 159, 160, 158, 162, 174, 172, 195, 200, 207, 213, 222, 222, 226, 242, 262, 253, 258, 262, 273, 274, 280, 282, 285, 287, 288, 289, 289, 296, 297, 302, 322, 328, 331, 334, 335, 336, 335, 339, 342, 353, 354, 357, 360, 362, 362, 367, 370, 383, 384, 382, 400, 397, 416, 417, 411, 414, 419, 431, 439, 437, 442, 450, 457, 458, 463, 463, 464, 474, 478, 480, 481, 482]]>)"
      ]
     },
     "execution_count": 447,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = wordpiece_layer_info(next(iter(dataset['validation'].map(lambda items: items['passage']).batch(2).take(1))))\n",
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(47, 106)"
      ]
     },
     "execution_count": 437,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tmp[0][0]),len(tmp[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 200), dtype=int64, numpy=\n",
       "array([[ 2331,  2013,  7239,  2003,  1037,  4678,  2433,  1997,  2331,\n",
       "        29623,  2788,  4525,  2013, 15050,  6545,  2030,  2004, 21281,\n",
       "        14787,  3508, 29623,  3303,  2011,  1037,  4906,  1997,  7239,\n",
       "        29625, 12107,  1997,  2331,  2011,  7239,  2031,  2042,  2680,\n",
       "         2013,  1996,  2335,  1997,  3418,  5483,  2000,  1996,  2715,\n",
       "         2154, 29625,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0],\n",
       "       [ 1996,  2417, 25462,  2003,  1996,  2069,  2542,  2427,  1997,\n",
       "         1996,  3562,  9932,  7630,  7946,  1998,  1996,  2155,  9932,\n",
       "         7630, 14615,  6679, 29625,  2009,  2038,  2042,  3130,  2872,\n",
       "         1999,  1996, 10958, 21408,  2239,  1998,  4562,  2945, 29623,\n",
       "         2021,  1996,  3463,  1997, 23192,  4106,  3073,  2844,  2490,\n",
       "         2005,  2049, 27691,  5579,  1999,  2049,  2219,  2155, 29623,\n",
       "         9932,  7630, 14615,  6679, 29623,  2029,  2003,  2112,  1997,\n",
       "         1996, 24169,  2442, 18349,  5178,  2050, 29623,  2247,  2007,\n",
       "         1996, 29268, 29623, 10958, 21408,  2239,  1998, 15315, 16814,\n",
       "         2945, 29625,  2048, 11056,  2024,  3858, 29625,  2009,  2003,\n",
       "         2025,  4876,  3141,  2000,  1996,  5016, 25462, 29623,  2029,\n",
       "         2003,  1037, 15191, 24471,  5332,  2094, 29625,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0]])>"
      ]
     },
     "execution_count": 438,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://github.com/tensorflow/tensorflow/issues/34793\n",
    "tmp[0].to_tensor(shape=[None, 200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 2, 200), dtype=int64, numpy=\n",
       "array([[[ 2331,  2013,  7239, ...,     0,     0,     0],\n",
       "        [ 1996,  2417, 25462, ...,     0,     0,     0]],\n",
       "\n",
       "       [[    0,     6,    11, ...,     0,     0,     0],\n",
       "        [    0,     4,     8, ...,     0,     0,     0]],\n",
       "\n",
       "       [[   10,    14,    27, ...,     0,     0,     0],\n",
       "        [    6,    10,    18, ...,     0,     0,     0]]])>"
      ]
     },
     "execution_count": 455,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://www.tensorflow.org/api_docs/python/tf/stack\n",
    "tf.stack(tmp).to_tensor(shape=[3, None, max_length])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 2, 200), dtype=int64, numpy=\n",
       "array([[[ 2331,  2013,  7239, ...,     0,     0,     0],\n",
       "        [ 1996,  2417, 25462, ...,     0,     0,     0]],\n",
       "\n",
       "       [[    0,     6,    11, ...,     0,     0,     0],\n",
       "        [    0,     4,     8, ...,     0,     0,     0]],\n",
       "\n",
       "       [[   10,    14,    27, ...,     0,     0,     0],\n",
       "        [    6,    10,    18, ...,     0,     0,     0]]])>"
      ]
     },
     "execution_count": 527,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential()\n",
    "max_sentence_length = 200\n",
    "model.add(tf.keras.layers.Lambda(lambda inputs: tf.stack(wordpiece_layer_info(inputs))))\n",
    "model.add(tf.keras.layers.Lambda(lambda inputs: inputs.to_tensor(shape=[3, None, max_sentence_length])))\n",
    "\n",
    "model.compile()\n",
    "\n",
    "model(next(iter(dataset['validation'].map(lambda items: items['passage']).batch(2))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(2, 200, 2), dtype=float32, numpy=\n",
       " array([[[-4.75030318e-02, -5.32386452e-03],\n",
       "         [ 3.43444608e-02,  4.94687892e-02],\n",
       "         [-3.33179608e-02, -1.03637949e-02],\n",
       "         [ 2.81322114e-02,  3.03698815e-02],\n",
       "         [ 1.70968659e-02,  2.61659883e-02],\n",
       "         [ 3.74656804e-02,  4.16744985e-02],\n",
       "         [-1.70720704e-02, -2.48060375e-03],\n",
       "         [ 4.65816259e-03,  4.02890779e-02],\n",
       "         [-4.75030318e-02, -5.32386452e-03],\n",
       "         [ 2.10616700e-02,  1.59046538e-02],\n",
       "         [ 1.68559887e-02,  2.06917264e-02],\n",
       "         [-3.18077095e-02,  8.44141096e-03],\n",
       "         [ 3.43444608e-02,  4.94687892e-02],\n",
       "         [ 2.60192789e-02, -1.24155171e-02],\n",
       "         [-2.75135394e-02,  3.38361412e-03],\n",
       "         [ 2.83235349e-02,  3.81581858e-03],\n",
       "         [-5.52136824e-03,  3.02712582e-02],\n",
       "         [-4.83170412e-02, -6.99973106e-03],\n",
       "         [ 4.44329269e-02, -3.17970291e-02],\n",
       "         [-4.39970382e-02, -1.09329820e-02],\n",
       "         [ 2.10616700e-02,  1.59046538e-02],\n",
       "         [-2.74858121e-02, -1.92494746e-02],\n",
       "         [ 4.96894605e-02,  3.32022794e-02],\n",
       "         [ 1.70968659e-02,  2.61659883e-02],\n",
       "         [ 2.17555501e-02, -4.29250486e-02],\n",
       "         [ 4.65816259e-03,  4.02890779e-02],\n",
       "         [-3.33179608e-02, -1.03637949e-02],\n",
       "         [-7.20894337e-03, -3.50251794e-05],\n",
       "         [ 3.60642411e-02, -3.39309797e-02],\n",
       "         [ 4.65816259e-03,  4.02890779e-02],\n",
       "         [-4.75030318e-02, -5.32386452e-03],\n",
       "         [ 4.96894605e-02,  3.32022794e-02],\n",
       "         [-3.33179608e-02, -1.03637949e-02],\n",
       "         [ 4.69125770e-02, -1.81974396e-02],\n",
       "         [ 2.27452405e-02,  1.85302608e-02],\n",
       "         [-2.65242103e-02, -3.61867435e-02],\n",
       "         [ 3.43444608e-02,  4.94687892e-02],\n",
       "         [ 1.65448226e-02, -1.80187821e-02],\n",
       "         [-1.96193941e-02,  4.87486385e-02],\n",
       "         [ 4.65816259e-03,  4.02890779e-02],\n",
       "         [-4.35956568e-03,  4.67000641e-02],\n",
       "         [-1.21351704e-02,  4.09578159e-03],\n",
       "         [-9.67494398e-03, -4.14367765e-03],\n",
       "         [ 1.65448226e-02, -1.80187821e-02],\n",
       "         [ 1.21840350e-02,  2.27903016e-02],\n",
       "         [ 2.66116299e-02,  4.07925956e-02],\n",
       "         [-7.20894337e-03, -3.50251794e-05],\n",
       "         [ 2.89794542e-02,  4.97876294e-02],\n",
       "         [ 2.89794542e-02,  4.97876294e-02],\n",
       "         [ 2.89794542e-02,  4.97876294e-02],\n",
       "         [ 2.89794542e-02,  4.97876294e-02],\n",
       "         [ 2.89794542e-02,  4.97876294e-02],\n",
       "         [ 2.89794542e-02,  4.97876294e-02],\n",
       "         [ 2.89794542e-02,  4.97876294e-02],\n",
       "         [ 2.89794542e-02,  4.97876294e-02],\n",
       "         [ 2.89794542e-02,  4.97876294e-02],\n",
       "         [ 2.89794542e-02,  4.97876294e-02],\n",
       "         [ 2.89794542e-02,  4.97876294e-02],\n",
       "         [ 2.89794542e-02,  4.97876294e-02],\n",
       "         [ 2.89794542e-02,  4.97876294e-02],\n",
       "         [ 2.89794542e-02,  4.97876294e-02],\n",
       "         [ 2.89794542e-02,  4.97876294e-02],\n",
       "         [ 2.89794542e-02,  4.97876294e-02],\n",
       "         [ 2.89794542e-02,  4.97876294e-02],\n",
       "         [ 2.89794542e-02,  4.97876294e-02],\n",
       "         [ 2.89794542e-02,  4.97876294e-02],\n",
       "         [ 2.89794542e-02,  4.97876294e-02],\n",
       "         [ 2.89794542e-02,  4.97876294e-02],\n",
       "         [ 2.89794542e-02,  4.97876294e-02],\n",
       "         [ 2.89794542e-02,  4.97876294e-02],\n",
       "         [ 2.89794542e-02,  4.97876294e-02],\n",
       "         [ 2.89794542e-02,  4.97876294e-02],\n",
       "         [ 2.89794542e-02,  4.97876294e-02],\n",
       "         [ 2.89794542e-02,  4.97876294e-02],\n",
       "         [ 2.89794542e-02,  4.97876294e-02],\n",
       "         [ 2.89794542e-02,  4.97876294e-02],\n",
       "         [ 2.89794542e-02,  4.97876294e-02],\n",
       "         [ 2.89794542e-02,  4.97876294e-02],\n",
       "         [ 2.89794542e-02,  4.97876294e-02],\n",
       "         [ 2.89794542e-02,  4.97876294e-02],\n",
       "         [ 2.89794542e-02,  4.97876294e-02],\n",
       "         [ 2.89794542e-02,  4.97876294e-02],\n",
       "         [ 2.89794542e-02,  4.97876294e-02],\n",
       "         [ 2.89794542e-02,  4.97876294e-02],\n",
       "         [ 2.89794542e-02,  4.97876294e-02],\n",
       "         [ 2.89794542e-02,  4.97876294e-02],\n",
       "         [ 2.89794542e-02,  4.97876294e-02],\n",
       "         [ 2.89794542e-02,  4.97876294e-02],\n",
       "         [ 2.89794542e-02,  4.97876294e-02],\n",
       "         [ 2.89794542e-02,  4.97876294e-02],\n",
       "         [ 2.89794542e-02,  4.97876294e-02],\n",
       "         [ 2.89794542e-02,  4.97876294e-02],\n",
       "         [ 2.89794542e-02,  4.97876294e-02],\n",
       "         [ 2.89794542e-02,  4.97876294e-02],\n",
       "         [ 2.89794542e-02,  4.97876294e-02],\n",
       "         [ 2.89794542e-02,  4.97876294e-02],\n",
       "         [ 2.89794542e-02,  4.97876294e-02],\n",
       "         [ 2.89794542e-02,  4.97876294e-02],\n",
       "         [ 2.89794542e-02,  4.97876294e-02],\n",
       "         [ 2.89794542e-02,  4.97876294e-02],\n",
       "         [ 2.89794542e-02,  4.97876294e-02],\n",
       "         [ 2.89794542e-02,  4.97876294e-02],\n",
       "         [ 2.89794542e-02,  4.97876294e-02],\n",
       "         [ 2.89794542e-02,  4.97876294e-02],\n",
       "         [ 2.89794542e-02,  4.97876294e-02],\n",
       "         [ 2.89794542e-02,  4.97876294e-02],\n",
       "         [ 2.89794542e-02,  4.97876294e-02],\n",
       "         [ 2.89794542e-02,  4.97876294e-02],\n",
       "         [ 2.89794542e-02,  4.97876294e-02],\n",
       "         [ 2.89794542e-02,  4.97876294e-02],\n",
       "         [ 2.89794542e-02,  4.97876294e-02],\n",
       "         [ 2.89794542e-02,  4.97876294e-02],\n",
       "         [ 2.89794542e-02,  4.97876294e-02],\n",
       "         [ 2.89794542e-02,  4.97876294e-02],\n",
       "         [ 2.89794542e-02,  4.97876294e-02],\n",
       "         [ 2.89794542e-02,  4.97876294e-02],\n",
       "         [ 2.89794542e-02,  4.97876294e-02],\n",
       "         [ 2.89794542e-02,  4.97876294e-02],\n",
       "         [ 2.89794542e-02,  4.97876294e-02],\n",
       "         [ 2.89794542e-02,  4.97876294e-02],\n",
       "         [ 2.89794542e-02,  4.97876294e-02],\n",
       "         [ 2.89794542e-02,  4.97876294e-02],\n",
       "         [ 2.89794542e-02,  4.97876294e-02],\n",
       "         [ 2.89794542e-02,  4.97876294e-02],\n",
       "         [ 2.89794542e-02,  4.97876294e-02],\n",
       "         [ 2.89794542e-02,  4.97876294e-02],\n",
       "         [ 2.89794542e-02,  4.97876294e-02],\n",
       "         [ 2.89794542e-02,  4.97876294e-02],\n",
       "         [ 2.89794542e-02,  4.97876294e-02],\n",
       "         [ 2.89794542e-02,  4.97876294e-02],\n",
       "         [ 2.89794542e-02,  4.97876294e-02],\n",
       "         [ 2.89794542e-02,  4.97876294e-02],\n",
       "         [ 2.89794542e-02,  4.97876294e-02],\n",
       "         [ 2.89794542e-02,  4.97876294e-02],\n",
       "         [ 2.89794542e-02,  4.97876294e-02],\n",
       "         [ 2.89794542e-02,  4.97876294e-02],\n",
       "         [ 2.89794542e-02,  4.97876294e-02],\n",
       "         [ 2.89794542e-02,  4.97876294e-02],\n",
       "         [ 2.89794542e-02,  4.97876294e-02],\n",
       "         [ 2.89794542e-02,  4.97876294e-02],\n",
       "         [ 2.89794542e-02,  4.97876294e-02],\n",
       "         [ 2.89794542e-02,  4.97876294e-02],\n",
       "         [ 2.89794542e-02,  4.97876294e-02],\n",
       "         [ 2.89794542e-02,  4.97876294e-02],\n",
       "         [ 2.89794542e-02,  4.97876294e-02],\n",
       "         [ 2.89794542e-02,  4.97876294e-02],\n",
       "         [ 2.89794542e-02,  4.97876294e-02],\n",
       "         [ 2.89794542e-02,  4.97876294e-02],\n",
       "         [ 2.89794542e-02,  4.97876294e-02],\n",
       "         [ 2.89794542e-02,  4.97876294e-02],\n",
       "         [ 2.89794542e-02,  4.97876294e-02],\n",
       "         [ 2.89794542e-02,  4.97876294e-02],\n",
       "         [ 2.89794542e-02,  4.97876294e-02],\n",
       "         [ 2.89794542e-02,  4.97876294e-02],\n",
       "         [ 2.89794542e-02,  4.97876294e-02],\n",
       "         [ 2.89794542e-02,  4.97876294e-02],\n",
       "         [ 2.89794542e-02,  4.97876294e-02],\n",
       "         [ 2.89794542e-02,  4.97876294e-02],\n",
       "         [ 2.89794542e-02,  4.97876294e-02],\n",
       "         [ 2.89794542e-02,  4.97876294e-02],\n",
       "         [ 2.89794542e-02,  4.97876294e-02],\n",
       "         [ 2.89794542e-02,  4.97876294e-02],\n",
       "         [ 2.89794542e-02,  4.97876294e-02],\n",
       "         [ 2.89794542e-02,  4.97876294e-02],\n",
       "         [ 2.89794542e-02,  4.97876294e-02],\n",
       "         [ 2.89794542e-02,  4.97876294e-02],\n",
       "         [ 2.89794542e-02,  4.97876294e-02],\n",
       "         [ 2.89794542e-02,  4.97876294e-02],\n",
       "         [ 2.89794542e-02,  4.97876294e-02],\n",
       "         [ 2.89794542e-02,  4.97876294e-02],\n",
       "         [ 2.89794542e-02,  4.97876294e-02],\n",
       "         [ 2.89794542e-02,  4.97876294e-02],\n",
       "         [ 2.89794542e-02,  4.97876294e-02],\n",
       "         [ 2.89794542e-02,  4.97876294e-02],\n",
       "         [ 2.89794542e-02,  4.97876294e-02],\n",
       "         [ 2.89794542e-02,  4.97876294e-02],\n",
       "         [ 2.89794542e-02,  4.97876294e-02],\n",
       "         [ 2.89794542e-02,  4.97876294e-02],\n",
       "         [ 2.89794542e-02,  4.97876294e-02],\n",
       "         [ 2.89794542e-02,  4.97876294e-02],\n",
       "         [ 2.89794542e-02,  4.97876294e-02],\n",
       "         [ 2.89794542e-02,  4.97876294e-02],\n",
       "         [ 2.89794542e-02,  4.97876294e-02],\n",
       "         [ 2.89794542e-02,  4.97876294e-02],\n",
       "         [ 2.89794542e-02,  4.97876294e-02],\n",
       "         [ 2.89794542e-02,  4.97876294e-02],\n",
       "         [ 2.89794542e-02,  4.97876294e-02],\n",
       "         [ 2.89794542e-02,  4.97876294e-02],\n",
       "         [ 2.89794542e-02,  4.97876294e-02],\n",
       "         [ 2.89794542e-02,  4.97876294e-02],\n",
       "         [ 2.89794542e-02,  4.97876294e-02],\n",
       "         [ 2.89794542e-02,  4.97876294e-02],\n",
       "         [ 2.89794542e-02,  4.97876294e-02],\n",
       "         [ 2.89794542e-02,  4.97876294e-02],\n",
       "         [ 2.89794542e-02,  4.97876294e-02],\n",
       "         [ 2.89794542e-02,  4.97876294e-02],\n",
       "         [ 2.89794542e-02,  4.97876294e-02],\n",
       "         [ 2.89794542e-02,  4.97876294e-02],\n",
       "         [ 2.89794542e-02,  4.97876294e-02],\n",
       "         [ 2.89794542e-02,  4.97876294e-02]],\n",
       " \n",
       "        [[ 1.65448226e-02, -1.80187821e-02],\n",
       "         [-7.31758028e-03, -4.00560610e-02],\n",
       "         [-3.93491983e-02, -4.03267033e-02],\n",
       "         [ 2.81322114e-02,  3.03698815e-02],\n",
       "         [ 1.65448226e-02, -1.80187821e-02],\n",
       "         [-1.43092163e-02,  4.19423319e-02],\n",
       "         [-2.88285017e-02, -3.15261967e-02],\n",
       "         [ 2.09512003e-02, -2.34166533e-03],\n",
       "         [ 4.65816259e-03,  4.02890779e-02],\n",
       "         [ 1.65448226e-02, -1.80187821e-02],\n",
       "         [-1.28053799e-02, -4.72147726e-02],\n",
       "         [-3.60394120e-02,  4.17392366e-02],\n",
       "         [-1.72996409e-02,  3.08155082e-02],\n",
       "         [ 2.94821300e-02, -2.57178545e-02],\n",
       "         [-4.10060398e-02, -1.03301033e-02],\n",
       "         [ 1.65448226e-02, -1.80187821e-02],\n",
       "         [-6.44153357e-03,  8.72881338e-03],\n",
       "         [-3.60394120e-02,  4.17392366e-02],\n",
       "         [-1.72996409e-02,  3.08155082e-02],\n",
       "         [-2.39566322e-02,  2.44626068e-02],\n",
       "         [ 2.46097706e-02,  8.80733877e-03],\n",
       "         [-7.20894337e-03, -3.50251794e-05],\n",
       "         [ 4.55480926e-02,  1.00278035e-02],\n",
       "         [ 1.74332149e-02, -2.94031743e-02],\n",
       "         [ 2.27452405e-02,  1.85302608e-02],\n",
       "         [-2.41898056e-02, -6.21706247e-03],\n",
       "         [ 1.77875645e-02,  9.07968357e-03],\n",
       "         [ 2.23324560e-02, -2.69232988e-02],\n",
       "         [ 1.65448226e-02, -1.80187821e-02],\n",
       "         [-5.52671030e-03,  3.45766060e-02],\n",
       "         [ 3.91967222e-03, -3.38146314e-02],\n",
       "         [-4.77907546e-02, -4.11457643e-02],\n",
       "         [-4.10060398e-02, -1.03301033e-02],\n",
       "         [ 4.38217632e-02, -2.89609190e-02],\n",
       "         [ 3.49038951e-02,  7.91691616e-03],\n",
       "         [ 2.10616700e-02,  1.59046538e-02],\n",
       "         [-3.53168361e-02,  4.82785217e-02],\n",
       "         [ 1.65448226e-02, -1.80187821e-02],\n",
       "         [ 8.43886286e-03, -4.83353063e-03],\n",
       "         [ 4.65816259e-03,  4.02890779e-02],\n",
       "         [ 1.96877457e-02,  2.18172334e-02],\n",
       "         [ 4.15871851e-02,  2.17558406e-02],\n",
       "         [ 6.38424233e-03,  3.72911580e-02],\n",
       "         [ 3.78136151e-02,  1.76175274e-02],\n",
       "         [ 3.77242081e-02, -5.58328629e-03],\n",
       "         [ 2.80839466e-02, -2.97417492e-03],\n",
       "         [-4.90650795e-02, -2.13780291e-02],\n",
       "         [ 6.63380697e-03,  1.16840824e-02],\n",
       "         [-3.95868532e-02, -1.43126138e-02],\n",
       "         [ 2.23324560e-02, -2.69232988e-02],\n",
       "         [-4.90650795e-02, -2.13780291e-02],\n",
       "         [ 1.02047548e-02,  4.74873520e-02],\n",
       "         [-6.44153357e-03,  8.72881338e-03],\n",
       "         [ 2.10616700e-02,  1.59046538e-02],\n",
       "         [-3.60394120e-02,  4.17392366e-02],\n",
       "         [-1.72996409e-02,  3.08155082e-02],\n",
       "         [-2.39566322e-02,  2.44626068e-02],\n",
       "         [ 2.46097706e-02,  8.80733877e-03],\n",
       "         [ 2.10616700e-02,  1.59046538e-02],\n",
       "         [-3.27077657e-02,  3.47357877e-02],\n",
       "         [ 2.81322114e-02,  3.03698815e-02],\n",
       "         [ 1.17663145e-02, -1.38944387e-03],\n",
       "         [ 4.65816259e-03,  4.02890779e-02],\n",
       "         [ 1.65448226e-02, -1.80187821e-02],\n",
       "         [ 9.66650248e-03,  3.90945114e-02],\n",
       "         [-7.00119883e-03, -4.76623438e-02],\n",
       "         [ 9.78479534e-03,  8.66830349e-04],\n",
       "         [ 3.60301472e-02, -1.79995187e-02],\n",
       "         [ 4.46877517e-02, -8.19257647e-03],\n",
       "         [ 2.10616700e-02,  1.59046538e-02],\n",
       "         [-1.13470182e-02,  2.82429159e-04],\n",
       "         [ 2.29509212e-02, -2.60684248e-02],\n",
       "         [ 1.65448226e-02, -1.80187821e-02],\n",
       "         [-4.74275276e-03, -3.06669604e-02],\n",
       "         [ 2.10616700e-02,  1.59046538e-02],\n",
       "         [-5.52671030e-03,  3.45766060e-02],\n",
       "         [ 3.91967222e-03, -3.38146314e-02],\n",
       "         [-4.77907546e-02, -4.11457643e-02],\n",
       "         [-4.10060398e-02, -1.03301033e-02],\n",
       "         [ 2.74568833e-02, -1.60999298e-02],\n",
       "         [ 3.20311300e-02, -4.37505357e-02],\n",
       "         [ 3.49038951e-02,  7.91691616e-03],\n",
       "         [-7.20894337e-03, -3.50251794e-05],\n",
       "         [-4.70932238e-02, -2.15391163e-02],\n",
       "         [-3.55564430e-03, -2.55763773e-02],\n",
       "         [-3.79270315e-03,  2.45399736e-02],\n",
       "         [ 1.38259269e-02, -4.34363969e-02],\n",
       "         [-7.20894337e-03, -3.50251794e-05],\n",
       "         [ 4.55480926e-02,  1.00278035e-02],\n",
       "         [ 2.81322114e-02,  3.03698815e-02],\n",
       "         [-2.54176501e-02, -2.34410763e-02],\n",
       "         [ 6.98127598e-03, -6.63211197e-03],\n",
       "         [-3.83366458e-02, -3.93077955e-02],\n",
       "         [-9.67494398e-03, -4.14367765e-03],\n",
       "         [ 1.65448226e-02, -1.80187821e-02],\n",
       "         [ 1.15862265e-02,  3.97631042e-02],\n",
       "         [-3.93491983e-02, -4.03267033e-02],\n",
       "         [ 2.10616700e-02,  1.59046538e-02],\n",
       "         [-3.27077657e-02,  3.47357877e-02],\n",
       "         [ 2.81322114e-02,  3.03698815e-02],\n",
       "         [ 1.70968659e-02,  2.61659883e-02],\n",
       "         [ 4.07761000e-02,  4.80279587e-02],\n",
       "         [-3.43714505e-02, -3.09579726e-02],\n",
       "         [ 3.52112204e-03,  4.27579917e-02],\n",
       "         [-3.73949893e-02, -3.39192040e-02],\n",
       "         [-7.20894337e-03, -3.50251794e-05],\n",
       "         [ 2.89794542e-02,  4.97876294e-02],\n",
       "         [ 2.89794542e-02,  4.97876294e-02],\n",
       "         [ 2.89794542e-02,  4.97876294e-02],\n",
       "         [ 2.89794542e-02,  4.97876294e-02],\n",
       "         [ 2.89794542e-02,  4.97876294e-02],\n",
       "         [ 2.89794542e-02,  4.97876294e-02],\n",
       "         [ 2.89794542e-02,  4.97876294e-02],\n",
       "         [ 2.89794542e-02,  4.97876294e-02],\n",
       "         [ 2.89794542e-02,  4.97876294e-02],\n",
       "         [ 2.89794542e-02,  4.97876294e-02],\n",
       "         [ 2.89794542e-02,  4.97876294e-02],\n",
       "         [ 2.89794542e-02,  4.97876294e-02],\n",
       "         [ 2.89794542e-02,  4.97876294e-02],\n",
       "         [ 2.89794542e-02,  4.97876294e-02],\n",
       "         [ 2.89794542e-02,  4.97876294e-02],\n",
       "         [ 2.89794542e-02,  4.97876294e-02],\n",
       "         [ 2.89794542e-02,  4.97876294e-02],\n",
       "         [ 2.89794542e-02,  4.97876294e-02],\n",
       "         [ 2.89794542e-02,  4.97876294e-02],\n",
       "         [ 2.89794542e-02,  4.97876294e-02],\n",
       "         [ 2.89794542e-02,  4.97876294e-02],\n",
       "         [ 2.89794542e-02,  4.97876294e-02],\n",
       "         [ 2.89794542e-02,  4.97876294e-02],\n",
       "         [ 2.89794542e-02,  4.97876294e-02],\n",
       "         [ 2.89794542e-02,  4.97876294e-02],\n",
       "         [ 2.89794542e-02,  4.97876294e-02],\n",
       "         [ 2.89794542e-02,  4.97876294e-02],\n",
       "         [ 2.89794542e-02,  4.97876294e-02],\n",
       "         [ 2.89794542e-02,  4.97876294e-02],\n",
       "         [ 2.89794542e-02,  4.97876294e-02],\n",
       "         [ 2.89794542e-02,  4.97876294e-02],\n",
       "         [ 2.89794542e-02,  4.97876294e-02],\n",
       "         [ 2.89794542e-02,  4.97876294e-02],\n",
       "         [ 2.89794542e-02,  4.97876294e-02],\n",
       "         [ 2.89794542e-02,  4.97876294e-02],\n",
       "         [ 2.89794542e-02,  4.97876294e-02],\n",
       "         [ 2.89794542e-02,  4.97876294e-02],\n",
       "         [ 2.89794542e-02,  4.97876294e-02],\n",
       "         [ 2.89794542e-02,  4.97876294e-02],\n",
       "         [ 2.89794542e-02,  4.97876294e-02],\n",
       "         [ 2.89794542e-02,  4.97876294e-02],\n",
       "         [ 2.89794542e-02,  4.97876294e-02],\n",
       "         [ 2.89794542e-02,  4.97876294e-02],\n",
       "         [ 2.89794542e-02,  4.97876294e-02],\n",
       "         [ 2.89794542e-02,  4.97876294e-02],\n",
       "         [ 2.89794542e-02,  4.97876294e-02],\n",
       "         [ 2.89794542e-02,  4.97876294e-02],\n",
       "         [ 2.89794542e-02,  4.97876294e-02],\n",
       "         [ 2.89794542e-02,  4.97876294e-02],\n",
       "         [ 2.89794542e-02,  4.97876294e-02],\n",
       "         [ 2.89794542e-02,  4.97876294e-02],\n",
       "         [ 2.89794542e-02,  4.97876294e-02],\n",
       "         [ 2.89794542e-02,  4.97876294e-02],\n",
       "         [ 2.89794542e-02,  4.97876294e-02],\n",
       "         [ 2.89794542e-02,  4.97876294e-02],\n",
       "         [ 2.89794542e-02,  4.97876294e-02],\n",
       "         [ 2.89794542e-02,  4.97876294e-02],\n",
       "         [ 2.89794542e-02,  4.97876294e-02],\n",
       "         [ 2.89794542e-02,  4.97876294e-02],\n",
       "         [ 2.89794542e-02,  4.97876294e-02],\n",
       "         [ 2.89794542e-02,  4.97876294e-02],\n",
       "         [ 2.89794542e-02,  4.97876294e-02],\n",
       "         [ 2.89794542e-02,  4.97876294e-02],\n",
       "         [ 2.89794542e-02,  4.97876294e-02],\n",
       "         [ 2.89794542e-02,  4.97876294e-02],\n",
       "         [ 2.89794542e-02,  4.97876294e-02],\n",
       "         [ 2.89794542e-02,  4.97876294e-02],\n",
       "         [ 2.89794542e-02,  4.97876294e-02],\n",
       "         [ 2.89794542e-02,  4.97876294e-02],\n",
       "         [ 2.89794542e-02,  4.97876294e-02],\n",
       "         [ 2.89794542e-02,  4.97876294e-02],\n",
       "         [ 2.89794542e-02,  4.97876294e-02],\n",
       "         [ 2.89794542e-02,  4.97876294e-02],\n",
       "         [ 2.89794542e-02,  4.97876294e-02],\n",
       "         [ 2.89794542e-02,  4.97876294e-02],\n",
       "         [ 2.89794542e-02,  4.97876294e-02],\n",
       "         [ 2.89794542e-02,  4.97876294e-02],\n",
       "         [ 2.89794542e-02,  4.97876294e-02],\n",
       "         [ 2.89794542e-02,  4.97876294e-02],\n",
       "         [ 2.89794542e-02,  4.97876294e-02],\n",
       "         [ 2.89794542e-02,  4.97876294e-02],\n",
       "         [ 2.89794542e-02,  4.97876294e-02],\n",
       "         [ 2.89794542e-02,  4.97876294e-02],\n",
       "         [ 2.89794542e-02,  4.97876294e-02],\n",
       "         [ 2.89794542e-02,  4.97876294e-02],\n",
       "         [ 2.89794542e-02,  4.97876294e-02],\n",
       "         [ 2.89794542e-02,  4.97876294e-02],\n",
       "         [ 2.89794542e-02,  4.97876294e-02],\n",
       "         [ 2.89794542e-02,  4.97876294e-02],\n",
       "         [ 2.89794542e-02,  4.97876294e-02],\n",
       "         [ 2.89794542e-02,  4.97876294e-02],\n",
       "         [ 2.89794542e-02,  4.97876294e-02],\n",
       "         [ 2.89794542e-02,  4.97876294e-02],\n",
       "         [ 2.89794542e-02,  4.97876294e-02]]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(2, 2, 200), dtype=int64, numpy=\n",
       " array([[[  0,   6,  11,  20,  23,  25,  30,  35,  38,  43,  45,  53,\n",
       "           63,  68,  76,  83,  86,  88,  91,  94,  98, 100, 107, 110,\n",
       "          112, 116, 119, 127, 129, 139, 142, 148, 151, 160, 165, 170,\n",
       "          179, 184, 188, 194, 197, 205, 212, 215, 219, 226, 229,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   4,   8,  14,  17,  21,  26,  33,  41,  44,  48,  54,\n",
       "           56,  58,  62,  66,  70,  77,  79,  81,  84,  86,  88,  91,\n",
       "           95, 100, 111, 118, 121, 125, 127, 130, 133, 137, 142, 150,\n",
       "          152, 156, 160, 168, 171, 184, 193, 201, 208, 216, 220, 224,\n",
       "          234, 249, 252, 256, 260, 266, 268, 270, 272, 275, 277, 279,\n",
       "          285, 288, 293, 296, 300, 312, 316, 319, 322, 323, 325, 331,\n",
       "          336, 340, 346, 348, 350, 353, 356, 360, 362, 366, 374, 376,\n",
       "          380, 391, 395, 405, 407, 410, 413, 417, 425, 433, 436, 440,\n",
       "          446, 451, 453, 459, 462, 464, 470, 472, 474, 475,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0]],\n",
       " \n",
       "        [[ 10,  14,  27,  24,  25,  33,  38,  39,  49,  50,  59,  71,\n",
       "           71,  82,  88,  87, 101, 104, 107, 111, 112, 112, 111, 112,\n",
       "          118, 120, 136, 137, 147, 143, 152, 152, 167, 168, 173, 186,\n",
       "          187, 190, 198, 198, 211, 217, 216, 221, 231, 233, 234,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  6,  10,  18,  18,  23,  29,  38,  47,  45,  50,  58,  63,\n",
       "           65,  68,  68,  72,  82,  89,  91,  94,  96,  97,  92,  97,\n",
       "          103, 120, 123, 122, 127, 134, 137, 139, 139, 145, 159, 160,\n",
       "          158, 162, 174, 172, 195, 200, 207, 213, 222, 222, 226, 242,\n",
       "          262, 253, 258, 262, 273, 274, 280, 282, 285, 287, 288, 289,\n",
       "          289, 296, 297, 302, 322, 328, 331, 334, 335, 336, 335, 339,\n",
       "          342, 353, 354, 357, 360, 362, 362, 367, 370, 383, 384, 382,\n",
       "          400, 397, 416, 417, 411, 414, 419, 431, 439, 437, 442, 450,\n",
       "          457, 458, 463, 463, 464, 474, 478, 480, 481, 482,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0]]])>]"
      ]
     },
     "execution_count": 539,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://www.tensorflow.org/api_docs/python/tf/slice\n",
    "words = tf.keras.layers.Lambda(lambda inputs: inputs[0,:,:])(model.outputs[0])\n",
    "embedding_dimension = 2\n",
    "words_embedded = tf.keras.layers.Embedding(input_dim=len(vocab), output_dim=embedding_dimension)(words)\n",
    "\n",
    "locations = tf.keras.layers.Lambda(lambda inputs: inputs[1:,:,:])(model.outputs[0])\n",
    "\n",
    "#https://github.com/keras-team/keras/issues/3557\n",
    "wp_model = tf.keras.Model(inputs=model.inputs, outputs=[words_embedded,locations])\n",
    "\n",
    "wp_model(next(iter(dataset['validation'].map(lambda items: items['passage']).batch(2))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_8\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "lambda_81_input (InputLayer)    [(2,)]               0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_81 (Lambda)              (3, None, None)      0           lambda_81_input[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_82 (Lambda)              (3, None, 200)       0           lambda_81[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_92 (Lambda)              (None, 200)          0           lambda_82[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "embedding_6 (Embedding)         (None, 200, 2)       61046       lambda_92[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_93 (Lambda)              (2, None, 200)       0           lambda_82[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 61,046\n",
      "Trainable params: 61,046\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "wp_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 542,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "plot_model(wp_model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
